{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8de4bbaf",
   "metadata": {},
   "source": [
    "# LSTM - FastText\n",
    "\n",
    "- ASAD Dataset\n",
    "- ROS balanced\n",
    "- LSTM 1, 2 and 3 Layers\n",
    "- Cell: 64\n",
    "- Learning-rate: 0.001\n",
    "- Embedding: FastText dim 300"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f9aa808",
   "metadata": {},
   "source": [
    "## Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "41167290",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.pyplot as plt\n",
    "import csv\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.layers import Dense,Flatten,Embedding,Activation, Dropout\n",
    "from tensorflow.keras.models import Sequential\n",
    "from keras.layers import LSTM\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from keras import layers\n",
    "from tensorflow.keras.layers import GlobalMaxPooling1D\n",
    "from keras.layers import Bidirectional\n",
    "from keras.callbacks import *\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from scipy import spatial\n",
    "from gensim.utils import simple_preprocess\n",
    "from keras.preprocessing import sequence\n",
    "from keras.utils.vis_utils import plot_model\n",
    "from keras.models import load_model\n",
    "import tensorflow as tf\n",
    "from imblearn.over_sampling import SMOTE, RandomOverSampler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4af0f4bf",
   "metadata": {},
   "source": [
    "## Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2e6d554a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1221875106206638080</td>\n",
       "      <td>والله الأرقام سيكون مخيب للآمال الأهلي قدها بر...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1221884257490042887</td>\n",
       "      <td>الزعل بيغير ملامحك بيغير نظرة العين بيغير شكلك...</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1226422627436310528</td>\n",
       "      <td>الحب الحقيقي اقتسام شخص أخر أقرب احلام مستغانمي</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1221880820815798277</td>\n",
       "      <td>النهضة فتيل</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1221884400377499651</td>\n",
       "      <td>حباً ايران بقدر ماهو نكايه بترامب وحزبه</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>1221882259139067911</td>\n",
       "      <td>ليه اسوم حياتي غيرت وانا اعرف</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>1221881289881550848</td>\n",
       "      <td>هههه ضحكت حالة نفسية سعيده</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>1227326811652026368</td>\n",
       "      <td>الحمدلله حضنت امي الحقيقية تعرفون شنو شعور تتر...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>1221882556548816896</td>\n",
       "      <td>توني ادري ان قناة اسمها يمدح السوق الا اللي رب...</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>1221883443467952128</td>\n",
       "      <td>عدلت شعري وطلع يهبل وربي صحيت بكره مو كويس لاد...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     id                                               text  \\\n",
       "0   1221875106206638080  والله الأرقام سيكون مخيب للآمال الأهلي قدها بر...   \n",
       "1   1221884257490042887  الزعل بيغير ملامحك بيغير نظرة العين بيغير شكلك...   \n",
       "2   1226422627436310528    الحب الحقيقي اقتسام شخص أخر أقرب احلام مستغانمي   \n",
       "3   1221880820815798277                                        النهضة فتيل   \n",
       "4   1221884400377499651            حباً ايران بقدر ماهو نكايه بترامب وحزبه   \n",
       "..                  ...                                                ...   \n",
       "95  1221882259139067911                      ليه اسوم حياتي غيرت وانا اعرف   \n",
       "96  1221881289881550848                         هههه ضحكت حالة نفسية سعيده   \n",
       "97  1227326811652026368  الحمدلله حضنت امي الحقيقية تعرفون شنو شعور تتر...   \n",
       "98  1221882556548816896  توني ادري ان قناة اسمها يمدح السوق الا اللي رب...   \n",
       "99  1221883443467952128  عدلت شعري وطلع يهبل وربي صحيت بكره مو كويس لاد...   \n",
       "\n",
       "   sentiment  \n",
       "0   Positive  \n",
       "1    Neutral  \n",
       "2   Positive  \n",
       "3   Positive  \n",
       "4    Neutral  \n",
       "..       ...  \n",
       "95   Neutral  \n",
       "96  Positive  \n",
       "97  Positive  \n",
       "98   Neutral  \n",
       "99  Positive  \n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file='../complete_training_all_punctuation_cleaning_stopword.csv'\n",
    "data = pd.read_csv(file,header=0, delimiter=\"\\t\",encoding='utf-8')\n",
    "data.text=data.text.astype(str)\n",
    "data.head(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ef00ad37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(53289, 3)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e127dab0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Neutral     36082\n",
       "Negative     8674\n",
       "Positive     8533\n",
       "Name: sentiment, dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = data[['id', 'sentiment']]\n",
    "labels.sentiment.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "beb1a55a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Negative', 'Neutral', 'Positive']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classes = sorted(labels.sentiment.unique())\n",
    "classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1690888f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[8674, 36082, 8533]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfs = []\n",
    "for sentiment in classes:\n",
    "    df_temp = data.where(data.sentiment == sentiment)\n",
    "    df_temp.dropna(axis=0, inplace=True)\n",
    "    dfs.append(df_temp)\n",
    "ls = [len(df) for df in dfs]\n",
    "ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "57e42330",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 216x216 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(3, 3))\n",
    "plt.pie(ls, labels=classes);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca798d2b",
   "metadata": {},
   "source": [
    "## Augmented data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "66abca3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# new_dfs = [pd.concat([df]*int(max(ls)/len(df)), ignore_index=True) \n",
    "#            for df in dfs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "23946681",
   "metadata": {},
   "outputs": [],
   "source": [
    "# new_ls = [len(df) for df in new_dfs]\n",
    "# new_ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6115ee9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.figure(figsize=(3, 3))\n",
    "# plt.pie(new_ls, labels=classes);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ceceeec4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data = pd.concat(new_dfs, ignore_index=True)\n",
    "# labels = data[['id','text', 'sentiment']]\n",
    "# classes = sorted(labels.sentiment.unique())\n",
    "# classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5fb678d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1221875106206638080</td>\n",
       "      <td>والله الأرقام سيكون مخيب للآمال الأهلي قدها بر...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1221884257490042887</td>\n",
       "      <td>الزعل بيغير ملامحك بيغير نظرة العين بيغير شكلك...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1226422627436310528</td>\n",
       "      <td>الحب الحقيقي اقتسام شخص أخر أقرب احلام مستغانمي</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1221880820815798277</td>\n",
       "      <td>النهضة فتيل</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1221884400377499651</td>\n",
       "      <td>حباً ايران بقدر ماهو نكايه بترامب وحزبه</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>1221882259139067911</td>\n",
       "      <td>ليه اسوم حياتي غيرت وانا اعرف</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>1221881289881550848</td>\n",
       "      <td>هههه ضحكت حالة نفسية سعيده</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>1227326811652026368</td>\n",
       "      <td>الحمدلله حضنت امي الحقيقية تعرفون شنو شعور تتر...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>1221882556548816896</td>\n",
       "      <td>توني ادري ان قناة اسمها يمدح السوق الا اللي رب...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>1221883443467952128</td>\n",
       "      <td>عدلت شعري وطلع يهبل وربي صحيت بكره مو كويس لاد...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     id                                               text  \\\n",
       "0   1221875106206638080  والله الأرقام سيكون مخيب للآمال الأهلي قدها بر...   \n",
       "1   1221884257490042887  الزعل بيغير ملامحك بيغير نظرة العين بيغير شكلك...   \n",
       "2   1226422627436310528    الحب الحقيقي اقتسام شخص أخر أقرب احلام مستغانمي   \n",
       "3   1221880820815798277                                        النهضة فتيل   \n",
       "4   1221884400377499651            حباً ايران بقدر ماهو نكايه بترامب وحزبه   \n",
       "..                  ...                                                ...   \n",
       "95  1221882259139067911                      ليه اسوم حياتي غيرت وانا اعرف   \n",
       "96  1221881289881550848                         هههه ضحكت حالة نفسية سعيده   \n",
       "97  1227326811652026368  الحمدلله حضنت امي الحقيقية تعرفون شنو شعور تتر...   \n",
       "98  1221882556548816896  توني ادري ان قناة اسمها يمدح السوق الا اللي رب...   \n",
       "99  1221883443467952128  عدلت شعري وطلع يهبل وربي صحيت بكره مو كويس لاد...   \n",
       "\n",
       "    sentiment  \n",
       "0           1  \n",
       "1           0  \n",
       "2           1  \n",
       "3           1  \n",
       "4           0  \n",
       "..        ...  \n",
       "95          0  \n",
       "96          1  \n",
       "97          1  \n",
       "98          0  \n",
       "99          1  \n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"sentiment\"].value_counts()\n",
    "cleanup_nums = {\"sentiment\":     {\"Neutral\": 0,\"Negative\":2, \"Positive\": 1,}}\n",
    "data = data.replace(cleanup_nums)\n",
    "data.head(100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2817bafa",
   "metadata": {},
   "source": [
    "## Convert to Numeric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e7e0930e",
   "metadata": {},
   "outputs": [],
   "source": [
    "maxSeqLength=30\n",
    "\n",
    "#conversion to list and then displaying the list\n",
    "text = data['text'].tolist()\n",
    "\n",
    "#tokenizer to read all the words present in our dtaset\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(text)\n",
    "\n",
    "#declaring the vocab_size\n",
    "size_of_vocabulary  = len(tokenizer.word_index) + 1\n",
    "\n",
    "#conversion to numerical formats\n",
    "encoded_text = tokenizer.texts_to_sequences(text)\n",
    "max_length = maxSeqLength\n",
    "X = sequence.pad_sequences(encoded_text, maxlen=max_length, padding='post')\n",
    "y = data['sentiment']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f20939e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(86596, 30) (86596,)\n",
      "(21650, 30) (21650,)\n"
     ]
    }
   ],
   "source": [
    "# ROS\n",
    "ros = RandomOverSampler(random_state=42)\n",
    "X, y = ros.fit_resample(X, y)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state = 42, test_size = 0.2, stratify = y)\n",
    "\n",
    "print(X_train.shape, y_train.shape)\n",
    "print(X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75331113",
   "metadata": {},
   "source": [
    "## FastText Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "62715e99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 6min 13s, sys: 3.47 s, total: 6min 17s\n",
      "Wall time: 6min 17s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from gensim.models import KeyedVectors\n",
    "ar_model = KeyedVectors.load_word2vec_format(\"../cc.ar.300.vec\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d7adf56e",
   "metadata": {},
   "outputs": [],
   "source": [
    "words_not_found = []\n",
    "embedding_dim = 300  \n",
    "embedding_matrix = np.zeros((size_of_vocabulary, embedding_dim))\n",
    "for word, i in tokenizer.word_index.items():\n",
    "    try:\n",
    "        embedding_vector = ar_model.get_vector(word)\n",
    "    except KeyError:\n",
    "        embedding_vector = None\n",
    "    if embedding_vector is not None:\n",
    "        embedding_matrix[i] = embedding_vector\n",
    "    else:\n",
    "        words_not_found.append(word)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ccaa5d8",
   "metadata": {},
   "source": [
    "## LSTM 1 Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "adf02023",
   "metadata": {},
   "outputs": [],
   "source": [
    "UNITS = 64\n",
    "lr = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "5e40602f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, 30, 300)           31476300  \n",
      "_________________________________________________________________\n",
      "lstm (LSTM)                  (None, 30, 64)            93440     \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d (Global (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 3)                 195       \n",
      "=================================================================\n",
      "Total params: 31,574,095\n",
      "Trainable params: 97,795\n",
      "Non-trainable params: 31,476,300\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model1=Sequential()\n",
    "model1.add(Embedding(size_of_vocabulary,embedding_dim,weights=[embedding_matrix],input_length=max_length,trainable=False))\n",
    "\n",
    "#Lstm layer\n",
    "model1.add(LSTM(UNITS,return_sequences=True,dropout=0.5))\n",
    "\n",
    "#Global Maxpooling\n",
    "model1.add(GlobalMaxPooling1D())\n",
    "\n",
    "#Dense Layer\n",
    "model1.add(Dense(UNITS, activation='relu'))\n",
    "\n",
    "#Output layer 3 class\n",
    "model1.add(Dense(3,activation='softmax')) \n",
    "\n",
    "model1.compile(optimizer=Adam(learning_rate = lr), loss = 'sparse_categorical_crossentropy', metrics = ['acc']) \n",
    "print(model1.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2441816a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "1083/1083 [==============================] - 12s 10ms/step - loss: 0.8467 - acc: 0.6086 - val_loss: 0.7460 - val_acc: 0.6734\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.67344, saving model to best_model_f1.h5\n",
      "Epoch 2/200\n",
      "1083/1083 [==============================] - 11s 10ms/step - loss: 0.7722 - acc: 0.6498 - val_loss: 0.7064 - val_acc: 0.6911\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.67344 to 0.69111, saving model to best_model_f1.h5\n",
      "Epoch 3/200\n",
      "1083/1083 [==============================] - 11s 10ms/step - loss: 0.7428 - acc: 0.6673 - val_loss: 0.6797 - val_acc: 0.7092\n",
      "\n",
      "Epoch 00003: val_acc improved from 0.69111 to 0.70918, saving model to best_model_f1.h5\n",
      "Epoch 4/200\n",
      "1083/1083 [==============================] - 11s 10ms/step - loss: 0.7147 - acc: 0.6836 - val_loss: 0.6529 - val_acc: 0.7245\n",
      "\n",
      "Epoch 00004: val_acc improved from 0.70918 to 0.72448, saving model to best_model_f1.h5\n",
      "Epoch 5/200\n",
      "1083/1083 [==============================] - 11s 10ms/step - loss: 0.6939 - acc: 0.6951 - val_loss: 0.6376 - val_acc: 0.7278\n",
      "\n",
      "Epoch 00005: val_acc improved from 0.72448 to 0.72777, saving model to best_model_f1.h5\n",
      "Epoch 6/200\n",
      "1083/1083 [==============================] - 11s 10ms/step - loss: 0.6758 - acc: 0.7062 - val_loss: 0.6289 - val_acc: 0.7330\n",
      "\n",
      "Epoch 00006: val_acc improved from 0.72777 to 0.73303, saving model to best_model_f1.h5\n",
      "Epoch 7/200\n",
      "1083/1083 [==============================] - 11s 10ms/step - loss: 0.6622 - acc: 0.7114 - val_loss: 0.6154 - val_acc: 0.7405\n",
      "\n",
      "Epoch 00007: val_acc improved from 0.73303 to 0.74047, saving model to best_model_f1.h5\n",
      "Epoch 8/200\n",
      "1083/1083 [==============================] - 11s 10ms/step - loss: 0.6436 - acc: 0.7215 - val_loss: 0.5904 - val_acc: 0.7525\n",
      "\n",
      "Epoch 00008: val_acc improved from 0.74047 to 0.75248, saving model to best_model_f1.h5\n",
      "Epoch 9/200\n",
      "1083/1083 [==============================] - 11s 10ms/step - loss: 0.6334 - acc: 0.7267 - val_loss: 0.5763 - val_acc: 0.7582\n",
      "\n",
      "Epoch 00009: val_acc improved from 0.75248 to 0.75820, saving model to best_model_f1.h5\n",
      "Epoch 10/200\n",
      "1083/1083 [==============================] - 11s 10ms/step - loss: 0.6225 - acc: 0.7318 - val_loss: 0.5690 - val_acc: 0.7645\n",
      "\n",
      "Epoch 00010: val_acc improved from 0.75820 to 0.76449, saving model to best_model_f1.h5\n",
      "Epoch 11/200\n",
      "1083/1083 [==============================] - 11s 10ms/step - loss: 0.6130 - acc: 0.7352 - val_loss: 0.5744 - val_acc: 0.7595\n",
      "\n",
      "Epoch 00011: val_acc did not improve from 0.76449\n",
      "Epoch 12/200\n",
      "1083/1083 [==============================] - 11s 10ms/step - loss: 0.6032 - acc: 0.7433 - val_loss: 0.5516 - val_acc: 0.7729\n",
      "\n",
      "Epoch 00012: val_acc improved from 0.76449 to 0.77286, saving model to best_model_f1.h5\n",
      "Epoch 13/200\n",
      "1083/1083 [==============================] - 11s 10ms/step - loss: 0.5933 - acc: 0.7467 - val_loss: 0.5417 - val_acc: 0.7759\n",
      "\n",
      "Epoch 00013: val_acc improved from 0.77286 to 0.77587, saving model to best_model_f1.h5\n",
      "Epoch 14/200\n",
      "1083/1083 [==============================] - 11s 10ms/step - loss: 0.5866 - acc: 0.7490 - val_loss: 0.5312 - val_acc: 0.7831\n",
      "\n",
      "Epoch 00014: val_acc improved from 0.77587 to 0.78308, saving model to best_model_f1.h5\n",
      "Epoch 15/200\n",
      "1083/1083 [==============================] - 11s 10ms/step - loss: 0.5765 - acc: 0.7554 - val_loss: 0.5267 - val_acc: 0.7860\n",
      "\n",
      "Epoch 00015: val_acc improved from 0.78308 to 0.78597, saving model to best_model_f1.h5\n",
      "Epoch 16/200\n",
      "1083/1083 [==============================] - 11s 10ms/step - loss: 0.5717 - acc: 0.7571 - val_loss: 0.5159 - val_acc: 0.7935\n",
      "\n",
      "Epoch 00016: val_acc improved from 0.78597 to 0.79353, saving model to best_model_f1.h5\n",
      "Epoch 17/200\n",
      "1083/1083 [==============================] - 11s 10ms/step - loss: 0.5642 - acc: 0.7624 - val_loss: 0.5142 - val_acc: 0.7911\n",
      "\n",
      "Epoch 00017: val_acc did not improve from 0.79353\n",
      "Epoch 18/200\n",
      "1083/1083 [==============================] - 11s 10ms/step - loss: 0.5562 - acc: 0.7647 - val_loss: 0.5075 - val_acc: 0.7944\n",
      "\n",
      "Epoch 00018: val_acc improved from 0.79353 to 0.79440, saving model to best_model_f1.h5\n",
      "Epoch 19/200\n",
      "1083/1083 [==============================] - 11s 10ms/step - loss: 0.5544 - acc: 0.7657 - val_loss: 0.5011 - val_acc: 0.7969\n",
      "\n",
      "Epoch 00019: val_acc improved from 0.79440 to 0.79688, saving model to best_model_f1.h5\n",
      "Epoch 20/200\n",
      "1083/1083 [==============================] - 11s 10ms/step - loss: 0.5467 - acc: 0.7707 - val_loss: 0.4916 - val_acc: 0.8016\n",
      "\n",
      "Epoch 00020: val_acc improved from 0.79688 to 0.80156, saving model to best_model_f1.h5\n",
      "Epoch 21/200\n",
      "1083/1083 [==============================] - 11s 10ms/step - loss: 0.5417 - acc: 0.7708 - val_loss: 0.4880 - val_acc: 0.8005\n",
      "\n",
      "Epoch 00021: val_acc did not improve from 0.80156\n",
      "Epoch 22/200\n",
      "1083/1083 [==============================] - 11s 10ms/step - loss: 0.5352 - acc: 0.7756 - val_loss: 0.4816 - val_acc: 0.8076\n",
      "\n",
      "Epoch 00022: val_acc improved from 0.80156 to 0.80762, saving model to best_model_f1.h5\n",
      "Epoch 23/200\n",
      "1083/1083 [==============================] - 11s 10ms/step - loss: 0.5320 - acc: 0.7747 - val_loss: 0.4829 - val_acc: 0.8035\n",
      "\n",
      "Epoch 00023: val_acc did not improve from 0.80762\n",
      "Epoch 24/200\n",
      "1083/1083 [==============================] - 11s 10ms/step - loss: 0.5264 - acc: 0.7796 - val_loss: 0.4904 - val_acc: 0.8038\n",
      "\n",
      "Epoch 00024: val_acc did not improve from 0.80762\n",
      "Epoch 25/200\n",
      "1083/1083 [==============================] - 11s 10ms/step - loss: 0.5239 - acc: 0.7780 - val_loss: 0.4800 - val_acc: 0.8061\n",
      "\n",
      "Epoch 00025: val_acc did not improve from 0.80762\n",
      "Epoch 26/200\n",
      "1083/1083 [==============================] - 11s 10ms/step - loss: 0.5178 - acc: 0.7832 - val_loss: 0.4638 - val_acc: 0.8155\n",
      "\n",
      "Epoch 00026: val_acc improved from 0.80762 to 0.81547, saving model to best_model_f1.h5\n",
      "Epoch 27/200\n",
      "1083/1083 [==============================] - 11s 10ms/step - loss: 0.5161 - acc: 0.7837 - val_loss: 0.4638 - val_acc: 0.8137\n",
      "\n",
      "Epoch 00027: val_acc did not improve from 0.81547\n",
      "Epoch 28/200\n",
      "1083/1083 [==============================] - 11s 10ms/step - loss: 0.5098 - acc: 0.7870 - val_loss: 0.4588 - val_acc: 0.8162\n",
      "\n",
      "Epoch 00028: val_acc improved from 0.81547 to 0.81617, saving model to best_model_f1.h5\n",
      "Epoch 29/200\n",
      "1083/1083 [==============================] - 11s 10ms/step - loss: 0.5080 - acc: 0.7887 - val_loss: 0.4644 - val_acc: 0.8120\n",
      "\n",
      "Epoch 00029: val_acc did not improve from 0.81617\n",
      "Epoch 30/200\n",
      "1083/1083 [==============================] - 11s 10ms/step - loss: 0.5035 - acc: 0.7892 - val_loss: 0.4693 - val_acc: 0.8133\n",
      "\n",
      "Epoch 00030: val_acc did not improve from 0.81617\n",
      "Epoch 31/200\n",
      "1083/1083 [==============================] - 11s 10ms/step - loss: 0.5010 - acc: 0.7915 - val_loss: 0.4561 - val_acc: 0.8174\n",
      "\n",
      "Epoch 00031: val_acc improved from 0.81617 to 0.81738, saving model to best_model_f1.h5\n",
      "Epoch 32/200\n",
      "1083/1083 [==============================] - 11s 10ms/step - loss: 0.4989 - acc: 0.7928 - val_loss: 0.4492 - val_acc: 0.8179\n",
      "\n",
      "Epoch 00032: val_acc improved from 0.81738 to 0.81790, saving model to best_model_f1.h5\n",
      "Epoch 33/200\n",
      "1083/1083 [==============================] - 11s 10ms/step - loss: 0.4937 - acc: 0.7942 - val_loss: 0.4434 - val_acc: 0.8233\n",
      "\n",
      "Epoch 00033: val_acc improved from 0.81790 to 0.82333, saving model to best_model_f1.h5\n",
      "Epoch 34/200\n",
      "1083/1083 [==============================] - 11s 10ms/step - loss: 0.4934 - acc: 0.7945 - val_loss: 0.4483 - val_acc: 0.8199\n",
      "\n",
      "Epoch 00034: val_acc did not improve from 0.82333\n",
      "Epoch 35/200\n",
      "1083/1083 [==============================] - 11s 10ms/step - loss: 0.4887 - acc: 0.7975 - val_loss: 0.4413 - val_acc: 0.8230\n",
      "\n",
      "Epoch 00035: val_acc did not improve from 0.82333\n",
      "Epoch 36/200\n",
      "1083/1083 [==============================] - 11s 10ms/step - loss: 0.4848 - acc: 0.7986 - val_loss: 0.4368 - val_acc: 0.8272\n",
      "\n",
      "Epoch 00036: val_acc improved from 0.82333 to 0.82719, saving model to best_model_f1.h5\n",
      "Epoch 37/200\n",
      "1083/1083 [==============================] - 11s 10ms/step - loss: 0.4808 - acc: 0.7999 - val_loss: 0.4332 - val_acc: 0.8284\n",
      "\n",
      "Epoch 00037: val_acc improved from 0.82719 to 0.82841, saving model to best_model_f1.h5\n",
      "Epoch 38/200\n",
      "1083/1083 [==============================] - 11s 10ms/step - loss: 0.4778 - acc: 0.8011 - val_loss: 0.4296 - val_acc: 0.8317\n",
      "\n",
      "Epoch 00038: val_acc improved from 0.82841 to 0.83170, saving model to best_model_f1.h5\n",
      "Epoch 39/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1083/1083 [==============================] - 11s 10ms/step - loss: 0.4805 - acc: 0.7991 - val_loss: 0.4299 - val_acc: 0.8298\n",
      "\n",
      "Epoch 00039: val_acc did not improve from 0.83170\n",
      "Epoch 40/200\n",
      "1083/1083 [==============================] - 11s 10ms/step - loss: 0.4704 - acc: 0.8074 - val_loss: 0.4313 - val_acc: 0.8320\n",
      "\n",
      "Epoch 00040: val_acc improved from 0.83170 to 0.83204, saving model to best_model_f1.h5\n",
      "Epoch 41/200\n",
      "1083/1083 [==============================] - 11s 10ms/step - loss: 0.4743 - acc: 0.8053 - val_loss: 0.4273 - val_acc: 0.8318\n",
      "\n",
      "Epoch 00041: val_acc did not improve from 0.83204\n",
      "Epoch 42/200\n",
      "1083/1083 [==============================] - 11s 10ms/step - loss: 0.4689 - acc: 0.8079 - val_loss: 0.4240 - val_acc: 0.8334\n",
      "\n",
      "Epoch 00042: val_acc improved from 0.83204 to 0.83343, saving model to best_model_f1.h5\n",
      "Epoch 43/200\n",
      "1083/1083 [==============================] - 11s 10ms/step - loss: 0.4717 - acc: 0.8044 - val_loss: 0.4210 - val_acc: 0.8341\n",
      "\n",
      "Epoch 00043: val_acc improved from 0.83343 to 0.83406, saving model to best_model_f1.h5\n",
      "Epoch 44/200\n",
      "1083/1083 [==============================] - 11s 10ms/step - loss: 0.4652 - acc: 0.8075 - val_loss: 0.4211 - val_acc: 0.8352\n",
      "\n",
      "Epoch 00044: val_acc improved from 0.83406 to 0.83516, saving model to best_model_f1.h5\n",
      "Epoch 45/200\n",
      "1083/1083 [==============================] - 11s 10ms/step - loss: 0.4642 - acc: 0.8105 - val_loss: 0.4190 - val_acc: 0.8360\n",
      "\n",
      "Epoch 00045: val_acc improved from 0.83516 to 0.83603, saving model to best_model_f1.h5\n",
      "Epoch 46/200\n",
      "1083/1083 [==============================] - 11s 10ms/step - loss: 0.4652 - acc: 0.8070 - val_loss: 0.4224 - val_acc: 0.8339\n",
      "\n",
      "Epoch 00046: val_acc did not improve from 0.83603\n",
      "Epoch 47/200\n",
      "1083/1083 [==============================] - 11s 10ms/step - loss: 0.4644 - acc: 0.8079 - val_loss: 0.4123 - val_acc: 0.8349\n",
      "\n",
      "Epoch 00047: val_acc did not improve from 0.83603\n",
      "Epoch 48/200\n",
      "1083/1083 [==============================] - 11s 10ms/step - loss: 0.4573 - acc: 0.8108 - val_loss: 0.4199 - val_acc: 0.8355\n",
      "\n",
      "Epoch 00048: val_acc did not improve from 0.83603\n",
      "Epoch 49/200\n",
      "1083/1083 [==============================] - 11s 10ms/step - loss: 0.4577 - acc: 0.8112 - val_loss: 0.4093 - val_acc: 0.8378\n",
      "\n",
      "Epoch 00049: val_acc improved from 0.83603 to 0.83776, saving model to best_model_f1.h5\n",
      "Epoch 50/200\n",
      "1083/1083 [==============================] - 11s 10ms/step - loss: 0.4549 - acc: 0.8124 - val_loss: 0.4018 - val_acc: 0.8428\n",
      "\n",
      "Epoch 00050: val_acc improved from 0.83776 to 0.84284, saving model to best_model_f1.h5\n",
      "Epoch 51/200\n",
      "1083/1083 [==============================] - 11s 10ms/step - loss: 0.4529 - acc: 0.8136 - val_loss: 0.4111 - val_acc: 0.8402\n",
      "\n",
      "Epoch 00051: val_acc did not improve from 0.84284\n",
      "Epoch 52/200\n",
      "1083/1083 [==============================] - 11s 10ms/step - loss: 0.4535 - acc: 0.8123 - val_loss: 0.4061 - val_acc: 0.8401\n",
      "\n",
      "Epoch 00052: val_acc did not improve from 0.84284\n",
      "Epoch 53/200\n",
      "1083/1083 [==============================] - 11s 10ms/step - loss: 0.4494 - acc: 0.8149 - val_loss: 0.4089 - val_acc: 0.8408\n",
      "\n",
      "Epoch 00053: val_acc did not improve from 0.84284\n",
      "Epoch 54/200\n",
      "1083/1083 [==============================] - 11s 10ms/step - loss: 0.4484 - acc: 0.8156 - val_loss: 0.4123 - val_acc: 0.8367\n",
      "\n",
      "Epoch 00054: val_acc did not improve from 0.84284\n",
      "Epoch 55/200\n",
      "1083/1083 [==============================] - 11s 10ms/step - loss: 0.4471 - acc: 0.8158 - val_loss: 0.4063 - val_acc: 0.8407\n",
      "\n",
      "Epoch 00055: val_acc did not improve from 0.84284\n",
      "Epoch 56/200\n",
      "1083/1083 [==============================] - 11s 10ms/step - loss: 0.4431 - acc: 0.8197 - val_loss: 0.4010 - val_acc: 0.8404\n",
      "\n",
      "Epoch 00056: val_acc did not improve from 0.84284\n",
      "Epoch 57/200\n",
      "1083/1083 [==============================] - 11s 10ms/step - loss: 0.4429 - acc: 0.8196 - val_loss: 0.4045 - val_acc: 0.8398\n",
      "\n",
      "Epoch 00057: val_acc did not improve from 0.84284\n",
      "Epoch 58/200\n",
      "1083/1083 [==============================] - 11s 10ms/step - loss: 0.4405 - acc: 0.8193 - val_loss: 0.3909 - val_acc: 0.8487\n",
      "\n",
      "Epoch 00058: val_acc improved from 0.84284 to 0.84867, saving model to best_model_f1.h5\n",
      "Epoch 59/200\n",
      "1083/1083 [==============================] - 11s 10ms/step - loss: 0.4377 - acc: 0.8192 - val_loss: 0.3990 - val_acc: 0.8430\n",
      "\n",
      "Epoch 00059: val_acc did not improve from 0.84867\n",
      "Epoch 60/200\n",
      "1083/1083 [==============================] - 11s 10ms/step - loss: 0.4391 - acc: 0.8191 - val_loss: 0.3919 - val_acc: 0.8492\n",
      "\n",
      "Epoch 00060: val_acc improved from 0.84867 to 0.84925, saving model to best_model_f1.h5\n",
      "Epoch 61/200\n",
      "1083/1083 [==============================] - 11s 10ms/step - loss: 0.4392 - acc: 0.8199 - val_loss: 0.3993 - val_acc: 0.8445\n",
      "\n",
      "Epoch 00061: val_acc did not improve from 0.84925\n",
      "Epoch 62/200\n",
      "1083/1083 [==============================] - 11s 10ms/step - loss: 0.4397 - acc: 0.8172 - val_loss: 0.3905 - val_acc: 0.8490\n",
      "\n",
      "Epoch 00062: val_acc did not improve from 0.84925\n",
      "Epoch 63/200\n",
      "1083/1083 [==============================] - 11s 10ms/step - loss: 0.4358 - acc: 0.8213 - val_loss: 0.4037 - val_acc: 0.8409\n",
      "\n",
      "Epoch 00063: val_acc did not improve from 0.84925\n",
      "Epoch 64/200\n",
      "1083/1083 [==============================] - 11s 10ms/step - loss: 0.4360 - acc: 0.8196 - val_loss: 0.3928 - val_acc: 0.8474\n",
      "\n",
      "Epoch 00064: val_acc did not improve from 0.84925\n",
      "Epoch 65/200\n",
      "1083/1083 [==============================] - 11s 10ms/step - loss: 0.4329 - acc: 0.8238 - val_loss: 0.3967 - val_acc: 0.8468\n",
      "\n",
      "Epoch 00065: val_acc did not improve from 0.84925\n",
      "Epoch 66/200\n",
      "1083/1083 [==============================] - 11s 10ms/step - loss: 0.4323 - acc: 0.8242 - val_loss: 0.3874 - val_acc: 0.8482\n",
      "\n",
      "Epoch 00066: val_acc did not improve from 0.84925\n",
      "Epoch 67/200\n",
      "1083/1083 [==============================] - 11s 10ms/step - loss: 0.4300 - acc: 0.8230 - val_loss: 0.3929 - val_acc: 0.8494\n",
      "\n",
      "Epoch 00067: val_acc improved from 0.84925 to 0.84942, saving model to best_model_f1.h5\n",
      "Epoch 68/200\n",
      "1083/1083 [==============================] - 11s 10ms/step - loss: 0.4273 - acc: 0.8260 - val_loss: 0.3894 - val_acc: 0.8473\n",
      "\n",
      "Epoch 00068: val_acc did not improve from 0.84942\n",
      "Epoch 69/200\n",
      "1083/1083 [==============================] - 11s 10ms/step - loss: 0.4263 - acc: 0.8249 - val_loss: 0.3885 - val_acc: 0.8490\n",
      "\n",
      "Epoch 00069: val_acc did not improve from 0.84942\n",
      "Epoch 70/200\n",
      "1083/1083 [==============================] - 11s 10ms/step - loss: 0.4273 - acc: 0.8254 - val_loss: 0.3853 - val_acc: 0.8514\n",
      "\n",
      "Epoch 00070: val_acc improved from 0.84942 to 0.85144, saving model to best_model_f1.h5\n",
      "Epoch 71/200\n",
      "1083/1083 [==============================] - 11s 10ms/step - loss: 0.4300 - acc: 0.8221 - val_loss: 0.3875 - val_acc: 0.8477\n",
      "\n",
      "Epoch 00071: val_acc did not improve from 0.85144\n",
      "Epoch 72/200\n",
      "1083/1083 [==============================] - 11s 10ms/step - loss: 0.4276 - acc: 0.8250 - val_loss: 0.3987 - val_acc: 0.8432\n",
      "\n",
      "Epoch 00072: val_acc did not improve from 0.85144\n",
      "Epoch 73/200\n",
      "1083/1083 [==============================] - 11s 10ms/step - loss: 0.4224 - acc: 0.8276 - val_loss: 0.3754 - val_acc: 0.8565\n",
      "\n",
      "Epoch 00073: val_acc improved from 0.85144 to 0.85647, saving model to best_model_f1.h5\n",
      "Epoch 74/200\n",
      "1083/1083 [==============================] - 11s 10ms/step - loss: 0.4223 - acc: 0.8271 - val_loss: 0.3901 - val_acc: 0.8486\n",
      "\n",
      "Epoch 00074: val_acc did not improve from 0.85647\n",
      "Epoch 75/200\n",
      "1083/1083 [==============================] - 11s 10ms/step - loss: 0.4193 - acc: 0.8289 - val_loss: 0.3784 - val_acc: 0.8538\n",
      "\n",
      "Epoch 00075: val_acc did not improve from 0.85647\n",
      "Epoch 76/200\n",
      "1083/1083 [==============================] - 11s 10ms/step - loss: 0.4203 - acc: 0.8288 - val_loss: 0.3798 - val_acc: 0.8546\n",
      "\n",
      "Epoch 00076: val_acc did not improve from 0.85647\n",
      "Epoch 77/200\n",
      "1083/1083 [==============================] - 11s 10ms/step - loss: 0.4183 - acc: 0.8292 - val_loss: 0.3868 - val_acc: 0.8491\n",
      "\n",
      "Epoch 00077: val_acc did not improve from 0.85647\n",
      "Epoch 78/200\n",
      "1083/1083 [==============================] - 11s 10ms/step - loss: 0.4182 - acc: 0.8295 - val_loss: 0.3824 - val_acc: 0.8524\n",
      "\n",
      "Epoch 00078: val_acc did not improve from 0.85647\n",
      "Epoch 79/200\n",
      "1083/1083 [==============================] - 11s 10ms/step - loss: 0.4175 - acc: 0.8294 - val_loss: 0.3878 - val_acc: 0.8491\n",
      "\n",
      "Epoch 00079: val_acc did not improve from 0.85647\n",
      "Epoch 80/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1083/1083 [==============================] - 11s 10ms/step - loss: 0.4164 - acc: 0.8298 - val_loss: 0.3762 - val_acc: 0.8550\n",
      "\n",
      "Epoch 00080: val_acc did not improve from 0.85647\n",
      "Epoch 81/200\n",
      "1083/1083 [==============================] - 11s 10ms/step - loss: 0.4160 - acc: 0.8288 - val_loss: 0.3735 - val_acc: 0.8546\n",
      "\n",
      "Epoch 00081: val_acc did not improve from 0.85647\n",
      "Epoch 82/200\n",
      "1083/1083 [==============================] - 11s 10ms/step - loss: 0.4144 - acc: 0.8314 - val_loss: 0.3676 - val_acc: 0.8590\n",
      "\n",
      "Epoch 00082: val_acc improved from 0.85647 to 0.85901, saving model to best_model_f1.h5\n",
      "Epoch 83/200\n",
      "1083/1083 [==============================] - 11s 10ms/step - loss: 0.4172 - acc: 0.8290 - val_loss: 0.3840 - val_acc: 0.8514\n",
      "\n",
      "Epoch 00083: val_acc did not improve from 0.85901\n",
      "Epoch 84/200\n",
      "1083/1083 [==============================] - 11s 10ms/step - loss: 0.4109 - acc: 0.8319 - val_loss: 0.3752 - val_acc: 0.8562\n",
      "\n",
      "Epoch 00084: val_acc did not improve from 0.85901\n",
      "Epoch 85/200\n",
      "1083/1083 [==============================] - 11s 10ms/step - loss: 0.4116 - acc: 0.8314 - val_loss: 0.3824 - val_acc: 0.8518\n",
      "\n",
      "Epoch 00085: val_acc did not improve from 0.85901\n",
      "Epoch 86/200\n",
      "1083/1083 [==============================] - 11s 10ms/step - loss: 0.4129 - acc: 0.8327 - val_loss: 0.3719 - val_acc: 0.8568\n",
      "\n",
      "Epoch 00086: val_acc did not improve from 0.85901\n",
      "Epoch 87/200\n",
      "1083/1083 [==============================] - 11s 10ms/step - loss: 0.4122 - acc: 0.8322 - val_loss: 0.3836 - val_acc: 0.8515\n",
      "\n",
      "Epoch 00087: val_acc did not improve from 0.85901\n",
      "Epoch 88/200\n",
      "1083/1083 [==============================] - 11s 10ms/step - loss: 0.4112 - acc: 0.8333 - val_loss: 0.3745 - val_acc: 0.8540\n",
      "\n",
      "Epoch 00088: val_acc did not improve from 0.85901\n",
      "Epoch 89/200\n",
      "1083/1083 [==============================] - 11s 10ms/step - loss: 0.4083 - acc: 0.8347 - val_loss: 0.3670 - val_acc: 0.8622\n",
      "\n",
      "Epoch 00089: val_acc improved from 0.85901 to 0.86218, saving model to best_model_f1.h5\n",
      "Epoch 90/200\n",
      "1083/1083 [==============================] - 11s 10ms/step - loss: 0.4061 - acc: 0.8341 - val_loss: 0.3624 - val_acc: 0.8620\n",
      "\n",
      "Epoch 00090: val_acc did not improve from 0.86218\n",
      "Epoch 91/200\n",
      "1083/1083 [==============================] - 11s 10ms/step - loss: 0.4082 - acc: 0.8330 - val_loss: 0.3699 - val_acc: 0.8567\n",
      "\n",
      "Epoch 00091: val_acc did not improve from 0.86218\n",
      "Epoch 92/200\n",
      "1083/1083 [==============================] - 11s 10ms/step - loss: 0.4065 - acc: 0.8331 - val_loss: 0.3686 - val_acc: 0.8605\n",
      "\n",
      "Epoch 00092: val_acc did not improve from 0.86218\n",
      "Epoch 93/200\n",
      "1083/1083 [==============================] - 11s 10ms/step - loss: 0.4036 - acc: 0.8349 - val_loss: 0.3731 - val_acc: 0.8558\n",
      "\n",
      "Epoch 00093: val_acc did not improve from 0.86218\n",
      "Epoch 94/200\n",
      "1083/1083 [==============================] - 11s 10ms/step - loss: 0.4063 - acc: 0.8341 - val_loss: 0.3696 - val_acc: 0.8557\n",
      "\n",
      "Epoch 00094: val_acc did not improve from 0.86218\n",
      "Epoch 95/200\n",
      "1083/1083 [==============================] - 11s 10ms/step - loss: 0.4025 - acc: 0.8375 - val_loss: 0.3785 - val_acc: 0.8539\n",
      "\n",
      "Epoch 00095: val_acc did not improve from 0.86218\n",
      "Epoch 96/200\n",
      "1083/1083 [==============================] - 11s 10ms/step - loss: 0.4024 - acc: 0.8358 - val_loss: 0.3553 - val_acc: 0.8651\n",
      "\n",
      "Epoch 00096: val_acc improved from 0.86218 to 0.86513, saving model to best_model_f1.h5\n",
      "Epoch 97/200\n",
      "1083/1083 [==============================] - 11s 10ms/step - loss: 0.4030 - acc: 0.8351 - val_loss: 0.3656 - val_acc: 0.8593\n",
      "\n",
      "Epoch 00097: val_acc did not improve from 0.86513\n",
      "Epoch 98/200\n",
      "1083/1083 [==============================] - 11s 10ms/step - loss: 0.4021 - acc: 0.8366 - val_loss: 0.3701 - val_acc: 0.8565\n",
      "\n",
      "Epoch 00098: val_acc did not improve from 0.86513\n",
      "Epoch 99/200\n",
      "1083/1083 [==============================] - 11s 10ms/step - loss: 0.4047 - acc: 0.8345 - val_loss: 0.3737 - val_acc: 0.8557\n",
      "\n",
      "Epoch 00099: val_acc did not improve from 0.86513\n",
      "Epoch 100/200\n",
      "1083/1083 [==============================] - 11s 10ms/step - loss: 0.4040 - acc: 0.8340 - val_loss: 0.3657 - val_acc: 0.8594\n",
      "\n",
      "Epoch 00100: val_acc did not improve from 0.86513\n",
      "Epoch 101/200\n",
      "1083/1083 [==============================] - 11s 10ms/step - loss: 0.3995 - acc: 0.8391 - val_loss: 0.3718 - val_acc: 0.8579\n",
      "\n",
      "Epoch 00101: val_acc did not improve from 0.86513\n",
      "Epoch 102/200\n",
      "1083/1083 [==============================] - 11s 10ms/step - loss: 0.3976 - acc: 0.8374 - val_loss: 0.3574 - val_acc: 0.8633\n",
      "\n",
      "Epoch 00102: val_acc did not improve from 0.86513\n",
      "Epoch 103/200\n",
      "1083/1083 [==============================] - 11s 10ms/step - loss: 0.3975 - acc: 0.8384 - val_loss: 0.3855 - val_acc: 0.8483\n",
      "\n",
      "Epoch 00103: val_acc did not improve from 0.86513\n",
      "Epoch 104/200\n",
      "1083/1083 [==============================] - 11s 10ms/step - loss: 0.4030 - acc: 0.8376 - val_loss: 0.3633 - val_acc: 0.8594\n",
      "\n",
      "Epoch 00104: val_acc did not improve from 0.86513\n",
      "Epoch 105/200\n",
      "1083/1083 [==============================] - 11s 10ms/step - loss: 0.4021 - acc: 0.8374 - val_loss: 0.3691 - val_acc: 0.8581\n",
      "\n",
      "Epoch 00105: val_acc did not improve from 0.86513\n",
      "Epoch 106/200\n",
      "1083/1083 [==============================] - 11s 10ms/step - loss: 0.3989 - acc: 0.8375 - val_loss: 0.3556 - val_acc: 0.8644\n",
      "\n",
      "Epoch 00106: val_acc did not improve from 0.86513\n",
      "Epoch 107/200\n",
      "1083/1083 [==============================] - 11s 10ms/step - loss: 0.3934 - acc: 0.8396 - val_loss: 0.3616 - val_acc: 0.8624\n",
      "\n",
      "Epoch 00107: val_acc did not improve from 0.86513\n",
      "Epoch 108/200\n",
      "1083/1083 [==============================] - 11s 10ms/step - loss: 0.3951 - acc: 0.8393 - val_loss: 0.3630 - val_acc: 0.8611\n",
      "\n",
      "Epoch 00108: val_acc did not improve from 0.86513\n",
      "Epoch 109/200\n",
      "1083/1083 [==============================] - 11s 10ms/step - loss: 0.3931 - acc: 0.8410 - val_loss: 0.3568 - val_acc: 0.8640\n",
      "\n",
      "Epoch 00109: val_acc did not improve from 0.86513\n",
      "Epoch 110/200\n",
      "1083/1083 [==============================] - 11s 10ms/step - loss: 0.3965 - acc: 0.8395 - val_loss: 0.3647 - val_acc: 0.8608\n",
      "\n",
      "Epoch 00110: val_acc did not improve from 0.86513\n",
      "Epoch 111/200\n",
      "1083/1083 [==============================] - 11s 10ms/step - loss: 0.3944 - acc: 0.8393 - val_loss: 0.3518 - val_acc: 0.8668\n",
      "\n",
      "Epoch 00111: val_acc improved from 0.86513 to 0.86680, saving model to best_model_f1.h5\n",
      "Epoch 112/200\n",
      "1083/1083 [==============================] - 11s 10ms/step - loss: 0.3925 - acc: 0.8401 - val_loss: 0.3706 - val_acc: 0.8588\n",
      "\n",
      "Epoch 00112: val_acc did not improve from 0.86680\n",
      "Epoch 113/200\n",
      "1083/1083 [==============================] - 11s 10ms/step - loss: 0.3938 - acc: 0.8407 - val_loss: 0.3620 - val_acc: 0.8627\n",
      "\n",
      "Epoch 00113: val_acc did not improve from 0.86680\n",
      "Epoch 114/200\n",
      "1083/1083 [==============================] - 11s 10ms/step - loss: 0.3929 - acc: 0.8412 - val_loss: 0.3540 - val_acc: 0.8637\n",
      "\n",
      "Epoch 00114: val_acc did not improve from 0.86680\n",
      "Epoch 115/200\n",
      "1083/1083 [==============================] - 11s 10ms/step - loss: 0.3935 - acc: 0.8406 - val_loss: 0.3574 - val_acc: 0.8638\n",
      "\n",
      "Epoch 00115: val_acc did not improve from 0.86680\n",
      "Epoch 116/200\n",
      "1083/1083 [==============================] - 11s 10ms/step - loss: 0.3902 - acc: 0.8419 - val_loss: 0.3589 - val_acc: 0.8633\n",
      "\n",
      "Epoch 00116: val_acc did not improve from 0.86680\n",
      "Epoch 117/200\n",
      "1083/1083 [==============================] - 11s 10ms/step - loss: 0.3931 - acc: 0.8418 - val_loss: 0.3525 - val_acc: 0.8649\n",
      "\n",
      "Epoch 00117: val_acc did not improve from 0.86680\n",
      "Epoch 118/200\n",
      "1083/1083 [==============================] - 11s 10ms/step - loss: 0.3897 - acc: 0.8417 - val_loss: 0.3534 - val_acc: 0.8654\n",
      "\n",
      "Epoch 00118: val_acc did not improve from 0.86680\n",
      "Epoch 119/200\n",
      "1083/1083 [==============================] - 11s 10ms/step - loss: 0.3909 - acc: 0.8402 - val_loss: 0.3727 - val_acc: 0.8578\n",
      "\n",
      "Epoch 00119: val_acc did not improve from 0.86680\n",
      "Epoch 120/200\n",
      "1083/1083 [==============================] - 11s 10ms/step - loss: 0.3882 - acc: 0.8438 - val_loss: 0.3751 - val_acc: 0.8559\n",
      "\n",
      "Epoch 00120: val_acc did not improve from 0.86680\n",
      "Epoch 121/200\n",
      "1083/1083 [==============================] - 11s 10ms/step - loss: 0.3875 - acc: 0.8425 - val_loss: 0.3546 - val_acc: 0.8647\n",
      "\n",
      "Epoch 00121: val_acc did not improve from 0.86680\n",
      "Epoch 122/200\n",
      "1083/1083 [==============================] - 11s 10ms/step - loss: 0.3865 - acc: 0.8430 - val_loss: 0.3509 - val_acc: 0.8655\n",
      "\n",
      "Epoch 00122: val_acc did not improve from 0.86680\n",
      "Epoch 123/200\n",
      "1083/1083 [==============================] - 11s 10ms/step - loss: 0.3868 - acc: 0.8419 - val_loss: 0.3574 - val_acc: 0.8639\n",
      "\n",
      "Epoch 00123: val_acc did not improve from 0.86680\n",
      "Epoch 124/200\n",
      "1083/1083 [==============================] - 11s 10ms/step - loss: 0.3879 - acc: 0.8425 - val_loss: 0.3555 - val_acc: 0.8668\n",
      "\n",
      "Epoch 00124: val_acc did not improve from 0.86680\n",
      "Epoch 125/200\n",
      "1083/1083 [==============================] - 11s 10ms/step - loss: 0.3858 - acc: 0.8432 - val_loss: 0.3600 - val_acc: 0.8648\n",
      "\n",
      "Epoch 00125: val_acc did not improve from 0.86680\n",
      "Epoch 126/200\n",
      "1083/1083 [==============================] - 11s 10ms/step - loss: 0.3847 - acc: 0.8438 - val_loss: 0.3499 - val_acc: 0.8667\n",
      "\n",
      "Epoch 00126: val_acc did not improve from 0.86680\n",
      "Epoch 127/200\n",
      "1083/1083 [==============================] - 11s 10ms/step - loss: 0.3846 - acc: 0.8444 - val_loss: 0.3634 - val_acc: 0.8625\n",
      "\n",
      "Epoch 00127: val_acc did not improve from 0.86680\n",
      "Epoch 128/200\n",
      "1083/1083 [==============================] - 11s 10ms/step - loss: 0.3850 - acc: 0.8447 - val_loss: 0.3728 - val_acc: 0.8572\n",
      "\n",
      "Epoch 00128: val_acc did not improve from 0.86680\n",
      "Epoch 129/200\n",
      "1083/1083 [==============================] - 11s 10ms/step - loss: 0.3846 - acc: 0.8435 - val_loss: 0.3567 - val_acc: 0.8645\n",
      "\n",
      "Epoch 00129: val_acc did not improve from 0.86680\n",
      "Epoch 130/200\n",
      "1083/1083 [==============================] - 11s 10ms/step - loss: 0.3824 - acc: 0.8444 - val_loss: 0.3572 - val_acc: 0.8654\n",
      "\n",
      "Epoch 00130: val_acc did not improve from 0.86680\n",
      "Epoch 131/200\n",
      "1083/1083 [==============================] - 11s 10ms/step - loss: 0.3841 - acc: 0.8433 - val_loss: 0.3638 - val_acc: 0.8611\n",
      "\n",
      "Epoch 00131: val_acc did not improve from 0.86680\n",
      "Epoch 132/200\n",
      "1083/1083 [==============================] - 11s 10ms/step - loss: 0.3853 - acc: 0.8447 - val_loss: 0.3547 - val_acc: 0.8661\n",
      "\n",
      "Epoch 00132: val_acc did not improve from 0.86680\n",
      "Epoch 133/200\n",
      "1083/1083 [==============================] - 11s 10ms/step - loss: 0.3818 - acc: 0.8443 - val_loss: 0.3566 - val_acc: 0.8656\n",
      "\n",
      "Epoch 00133: val_acc did not improve from 0.86680\n",
      "Epoch 134/200\n",
      "1083/1083 [==============================] - 11s 10ms/step - loss: 0.3793 - acc: 0.8442 - val_loss: 0.3525 - val_acc: 0.8667\n",
      "\n",
      "Epoch 00134: val_acc did not improve from 0.86680\n",
      "Epoch 135/200\n",
      "1083/1083 [==============================] - 11s 10ms/step - loss: 0.3811 - acc: 0.8460 - val_loss: 0.3671 - val_acc: 0.8620\n",
      "\n",
      "Epoch 00135: val_acc did not improve from 0.86680\n",
      "Epoch 136/200\n",
      "1083/1083 [==============================] - 11s 10ms/step - loss: 0.3811 - acc: 0.8452 - val_loss: 0.3568 - val_acc: 0.8652\n",
      "\n",
      "Epoch 00136: val_acc did not improve from 0.86680\n",
      "Epoch 137/200\n",
      "1083/1083 [==============================] - 11s 10ms/step - loss: 0.3830 - acc: 0.8458 - val_loss: 0.3542 - val_acc: 0.8676\n",
      "\n",
      "Epoch 00137: val_acc improved from 0.86680 to 0.86755, saving model to best_model_f1.h5\n",
      "Epoch 138/200\n",
      "1083/1083 [==============================] - 11s 10ms/step - loss: 0.3813 - acc: 0.8457 - val_loss: 0.3515 - val_acc: 0.8683\n",
      "\n",
      "Epoch 00138: val_acc improved from 0.86755 to 0.86830, saving model to best_model_f1.h5\n",
      "Epoch 139/200\n",
      "1083/1083 [==============================] - 11s 10ms/step - loss: 0.3851 - acc: 0.8442 - val_loss: 0.3696 - val_acc: 0.8609\n",
      "\n",
      "Epoch 00139: val_acc did not improve from 0.86830\n",
      "Epoch 140/200\n",
      "1083/1083 [==============================] - 11s 10ms/step - loss: 0.3823 - acc: 0.8466 - val_loss: 0.3668 - val_acc: 0.8622\n",
      "\n",
      "Epoch 00140: val_acc did not improve from 0.86830\n",
      "Epoch 141/200\n",
      "1083/1083 [==============================] - 11s 10ms/step - loss: 0.3821 - acc: 0.8443 - val_loss: 0.3490 - val_acc: 0.8659\n",
      "\n",
      "Epoch 00141: val_acc did not improve from 0.86830\n",
      "Epoch 142/200\n",
      "1083/1083 [==============================] - 11s 10ms/step - loss: 0.3798 - acc: 0.8458 - val_loss: 0.3649 - val_acc: 0.8606\n",
      "\n",
      "Epoch 00142: val_acc did not improve from 0.86830\n",
      "Epoch 143/200\n",
      "1083/1083 [==============================] - 11s 10ms/step - loss: 0.3782 - acc: 0.8477 - val_loss: 0.3490 - val_acc: 0.8690\n",
      "\n",
      "Epoch 00143: val_acc improved from 0.86830 to 0.86900, saving model to best_model_f1.h5\n",
      "Epoch 144/200\n",
      "1083/1083 [==============================] - 11s 10ms/step - loss: 0.3773 - acc: 0.8457 - val_loss: 0.3539 - val_acc: 0.8644\n",
      "\n",
      "Epoch 00144: val_acc did not improve from 0.86900\n",
      "Epoch 145/200\n",
      "1083/1083 [==============================] - 11s 10ms/step - loss: 0.3806 - acc: 0.8459 - val_loss: 0.3529 - val_acc: 0.8650\n",
      "\n",
      "Epoch 00145: val_acc did not improve from 0.86900\n",
      "Epoch 146/200\n",
      "1083/1083 [==============================] - 11s 10ms/step - loss: 0.3773 - acc: 0.8473 - val_loss: 0.3542 - val_acc: 0.8648\n",
      "\n",
      "Epoch 00146: val_acc did not improve from 0.86900\n",
      "Epoch 147/200\n",
      "1083/1083 [==============================] - 11s 10ms/step - loss: 0.3784 - acc: 0.8465 - val_loss: 0.3535 - val_acc: 0.8666\n",
      "\n",
      "Epoch 00147: val_acc did not improve from 0.86900\n",
      "Epoch 148/200\n",
      "1083/1083 [==============================] - 11s 10ms/step - loss: 0.3800 - acc: 0.8467 - val_loss: 0.3480 - val_acc: 0.8688\n",
      "\n",
      "Epoch 00148: val_acc did not improve from 0.86900\n",
      "Epoch 149/200\n",
      "1083/1083 [==============================] - 11s 10ms/step - loss: 0.3775 - acc: 0.8468 - val_loss: 0.3471 - val_acc: 0.8698\n",
      "\n",
      "Epoch 00149: val_acc improved from 0.86900 to 0.86980, saving model to best_model_f1.h5\n",
      "Epoch 150/200\n",
      "1083/1083 [==============================] - 11s 10ms/step - loss: 0.3766 - acc: 0.8491 - val_loss: 0.3578 - val_acc: 0.8624\n",
      "\n",
      "Epoch 00150: val_acc did not improve from 0.86980\n",
      "Epoch 151/200\n",
      "1083/1083 [==============================] - 11s 10ms/step - loss: 0.3767 - acc: 0.8473 - val_loss: 0.3559 - val_acc: 0.8659\n",
      "\n",
      "Epoch 00151: val_acc did not improve from 0.86980\n",
      "Epoch 152/200\n",
      "1083/1083 [==============================] - 11s 10ms/step - loss: 0.3721 - acc: 0.8480 - val_loss: 0.3639 - val_acc: 0.8602\n",
      "\n",
      "Epoch 00152: val_acc did not improve from 0.86980\n",
      "Epoch 153/200\n",
      "1083/1083 [==============================] - 11s 10ms/step - loss: 0.3754 - acc: 0.8500 - val_loss: 0.3496 - val_acc: 0.8692\n",
      "\n",
      "Epoch 00153: val_acc did not improve from 0.86980\n",
      "Epoch 154/200\n",
      "1083/1083 [==============================] - 11s 10ms/step - loss: 0.3732 - acc: 0.8491 - val_loss: 0.3568 - val_acc: 0.8652\n",
      "\n",
      "Epoch 00154: val_acc did not improve from 0.86980\n",
      "Epoch 155/200\n",
      "1083/1083 [==============================] - 11s 10ms/step - loss: 0.3766 - acc: 0.8491 - val_loss: 0.3508 - val_acc: 0.8690\n",
      "\n",
      "Epoch 00155: val_acc did not improve from 0.86980\n",
      "Epoch 156/200\n",
      "1083/1083 [==============================] - 11s 10ms/step - loss: 0.3739 - acc: 0.8492 - val_loss: 0.3497 - val_acc: 0.8691\n",
      "\n",
      "Epoch 00156: val_acc did not improve from 0.86980\n",
      "Epoch 157/200\n",
      "1083/1083 [==============================] - 11s 10ms/step - loss: 0.3746 - acc: 0.8488 - val_loss: 0.3443 - val_acc: 0.8712\n",
      "\n",
      "Epoch 00157: val_acc improved from 0.86980 to 0.87119, saving model to best_model_f1.h5\n",
      "Epoch 158/200\n",
      "1083/1083 [==============================] - 11s 10ms/step - loss: 0.3714 - acc: 0.8503 - val_loss: 0.3374 - val_acc: 0.8739\n",
      "\n",
      "Epoch 00158: val_acc improved from 0.87119 to 0.87390, saving model to best_model_f1.h5\n",
      "Epoch 159/200\n",
      "1083/1083 [==============================] - 11s 10ms/step - loss: 0.3746 - acc: 0.8476 - val_loss: 0.3531 - val_acc: 0.8646\n",
      "\n",
      "Epoch 00159: val_acc did not improve from 0.87390\n",
      "Epoch 160/200\n",
      "1083/1083 [==============================] - 11s 10ms/step - loss: 0.3728 - acc: 0.8489 - val_loss: 0.3394 - val_acc: 0.8715\n",
      "\n",
      "Epoch 00160: val_acc did not improve from 0.87390\n",
      "Epoch 161/200\n",
      "1083/1083 [==============================] - 11s 10ms/step - loss: 0.3710 - acc: 0.8497 - val_loss: 0.3518 - val_acc: 0.8675\n",
      "\n",
      "Epoch 00161: val_acc did not improve from 0.87390\n",
      "Epoch 162/200\n",
      "1083/1083 [==============================] - 11s 10ms/step - loss: 0.3701 - acc: 0.8510 - val_loss: 0.3437 - val_acc: 0.8718\n",
      "\n",
      "Epoch 00162: val_acc did not improve from 0.87390\n",
      "Epoch 163/200\n",
      "1083/1083 [==============================] - 11s 10ms/step - loss: 0.3700 - acc: 0.8497 - val_loss: 0.3613 - val_acc: 0.8621\n",
      "\n",
      "Epoch 00163: val_acc did not improve from 0.87390\n",
      "Epoch 164/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1083/1083 [==============================] - 11s 10ms/step - loss: 0.3713 - acc: 0.8499 - val_loss: 0.3503 - val_acc: 0.8670\n",
      "\n",
      "Epoch 00164: val_acc did not improve from 0.87390\n",
      "Epoch 165/200\n",
      "1083/1083 [==============================] - 11s 10ms/step - loss: 0.3722 - acc: 0.8494 - val_loss: 0.3360 - val_acc: 0.8718\n",
      "\n",
      "Epoch 00165: val_acc did not improve from 0.87390\n",
      "Epoch 166/200\n",
      "1083/1083 [==============================] - 11s 10ms/step - loss: 0.3697 - acc: 0.8515 - val_loss: 0.3416 - val_acc: 0.8697\n",
      "\n",
      "Epoch 00166: val_acc did not improve from 0.87390\n",
      "Epoch 167/200\n",
      "1083/1083 [==============================] - 11s 10ms/step - loss: 0.3721 - acc: 0.8491 - val_loss: 0.3423 - val_acc: 0.8736\n",
      "\n",
      "Epoch 00167: val_acc did not improve from 0.87390\n",
      "Epoch 168/200\n",
      "1083/1083 [==============================] - 11s 10ms/step - loss: 0.3716 - acc: 0.8520 - val_loss: 0.3607 - val_acc: 0.8628\n",
      "\n",
      "Epoch 00168: val_acc did not improve from 0.87390\n",
      "Epoch 169/200\n",
      "1083/1083 [==============================] - 11s 10ms/step - loss: 0.3703 - acc: 0.8501 - val_loss: 0.3406 - val_acc: 0.8716\n",
      "\n",
      "Epoch 00169: val_acc did not improve from 0.87390\n",
      "Epoch 170/200\n",
      "1083/1083 [==============================] - 11s 10ms/step - loss: 0.3659 - acc: 0.8529 - val_loss: 0.3598 - val_acc: 0.8624\n",
      "\n",
      "Epoch 00170: val_acc did not improve from 0.87390\n",
      "Epoch 171/200\n",
      "1083/1083 [==============================] - 11s 10ms/step - loss: 0.3696 - acc: 0.8504 - val_loss: 0.3427 - val_acc: 0.8721\n",
      "\n",
      "Epoch 00171: val_acc did not improve from 0.87390\n",
      "Epoch 172/200\n",
      "1083/1083 [==============================] - 11s 10ms/step - loss: 0.3690 - acc: 0.8507 - val_loss: 0.3493 - val_acc: 0.8678\n",
      "\n",
      "Epoch 00172: val_acc did not improve from 0.87390\n",
      "Epoch 173/200\n",
      "1083/1083 [==============================] - 11s 10ms/step - loss: 0.3701 - acc: 0.8516 - val_loss: 0.3366 - val_acc: 0.8738\n",
      "\n",
      "Epoch 00173: val_acc did not improve from 0.87390\n",
      "Epoch 174/200\n",
      "1083/1083 [==============================] - 11s 10ms/step - loss: 0.3715 - acc: 0.8497 - val_loss: 0.3446 - val_acc: 0.8723\n",
      "\n",
      "Epoch 00174: val_acc did not improve from 0.87390\n",
      "Epoch 175/200\n",
      "1083/1083 [==============================] - 11s 10ms/step - loss: 0.3688 - acc: 0.8505 - val_loss: 0.3514 - val_acc: 0.8691\n",
      "\n",
      "Epoch 00175: val_acc did not improve from 0.87390\n",
      "Epoch 176/200\n",
      "1083/1083 [==============================] - 11s 10ms/step - loss: 0.3685 - acc: 0.8501 - val_loss: 0.3333 - val_acc: 0.8753\n",
      "\n",
      "Epoch 00176: val_acc improved from 0.87390 to 0.87535, saving model to best_model_f1.h5\n",
      "Epoch 177/200\n",
      "1083/1083 [==============================] - 11s 10ms/step - loss: 0.3678 - acc: 0.8512 - val_loss: 0.3554 - val_acc: 0.8666\n",
      "\n",
      "Epoch 00177: val_acc did not improve from 0.87535\n",
      "Epoch 178/200\n",
      "1083/1083 [==============================] - 11s 10ms/step - loss: 0.3691 - acc: 0.8510 - val_loss: 0.3447 - val_acc: 0.8712\n",
      "\n",
      "Epoch 00178: val_acc did not improve from 0.87535\n",
      "Epoch 179/200\n",
      "1083/1083 [==============================] - 11s 10ms/step - loss: 0.3657 - acc: 0.8518 - val_loss: 0.3461 - val_acc: 0.8711\n",
      "\n",
      "Epoch 00179: val_acc did not improve from 0.87535\n",
      "Epoch 180/200\n",
      "1083/1083 [==============================] - 11s 10ms/step - loss: 0.3679 - acc: 0.8514 - val_loss: 0.3459 - val_acc: 0.8709\n",
      "\n",
      "Epoch 00180: val_acc did not improve from 0.87535\n",
      "Epoch 181/200\n",
      "1083/1083 [==============================] - 11s 10ms/step - loss: 0.3654 - acc: 0.8525 - val_loss: 0.3502 - val_acc: 0.8685\n",
      "\n",
      "Epoch 00181: val_acc did not improve from 0.87535\n",
      "Epoch 182/200\n",
      "1083/1083 [==============================] - 11s 10ms/step - loss: 0.3669 - acc: 0.8513 - val_loss: 0.3488 - val_acc: 0.8681\n",
      "\n",
      "Epoch 00182: val_acc did not improve from 0.87535\n",
      "Epoch 183/200\n",
      "1083/1083 [==============================] - 11s 10ms/step - loss: 0.3672 - acc: 0.8524 - val_loss: 0.3407 - val_acc: 0.8702\n",
      "\n",
      "Epoch 00183: val_acc did not improve from 0.87535\n",
      "Epoch 184/200\n",
      "1083/1083 [==============================] - 11s 10ms/step - loss: 0.3653 - acc: 0.8524 - val_loss: 0.3450 - val_acc: 0.8692\n",
      "\n",
      "Epoch 00184: val_acc did not improve from 0.87535\n",
      "Epoch 185/200\n",
      "1083/1083 [==============================] - 11s 10ms/step - loss: 0.3663 - acc: 0.8518 - val_loss: 0.3334 - val_acc: 0.8745\n",
      "\n",
      "Epoch 00185: val_acc did not improve from 0.87535\n",
      "Epoch 186/200\n",
      "1083/1083 [==============================] - 11s 10ms/step - loss: 0.3646 - acc: 0.8529 - val_loss: 0.3479 - val_acc: 0.8717\n",
      "\n",
      "Epoch 00186: val_acc did not improve from 0.87535\n",
      "Epoch 187/200\n",
      "1083/1083 [==============================] - 11s 10ms/step - loss: 0.3658 - acc: 0.8518 - val_loss: 0.3575 - val_acc: 0.8635\n",
      "\n",
      "Epoch 00187: val_acc did not improve from 0.87535\n",
      "Epoch 188/200\n",
      "1083/1083 [==============================] - 11s 10ms/step - loss: 0.3661 - acc: 0.8529 - val_loss: 0.3374 - val_acc: 0.8747\n",
      "\n",
      "Epoch 00188: val_acc did not improve from 0.87535\n",
      "Epoch 189/200\n",
      "1083/1083 [==============================] - 11s 10ms/step - loss: 0.3653 - acc: 0.8537 - val_loss: 0.3384 - val_acc: 0.8756\n",
      "\n",
      "Epoch 00189: val_acc improved from 0.87535 to 0.87558, saving model to best_model_f1.h5\n",
      "Epoch 190/200\n",
      "1083/1083 [==============================] - 11s 10ms/step - loss: 0.3629 - acc: 0.8528 - val_loss: 0.3379 - val_acc: 0.8753\n",
      "\n",
      "Epoch 00190: val_acc did not improve from 0.87558\n",
      "Epoch 191/200\n",
      "1083/1083 [==============================] - 11s 10ms/step - loss: 0.3649 - acc: 0.8527 - val_loss: 0.3376 - val_acc: 0.8725\n",
      "\n",
      "Epoch 00191: val_acc did not improve from 0.87558\n",
      "Epoch 192/200\n",
      "1083/1083 [==============================] - 11s 10ms/step - loss: 0.3644 - acc: 0.8532 - val_loss: 0.3467 - val_acc: 0.8714\n",
      "\n",
      "Epoch 00192: val_acc did not improve from 0.87558\n",
      "Epoch 193/200\n",
      "1083/1083 [==============================] - 11s 10ms/step - loss: 0.3614 - acc: 0.8550 - val_loss: 0.3365 - val_acc: 0.8766\n",
      "\n",
      "Epoch 00193: val_acc improved from 0.87558 to 0.87656, saving model to best_model_f1.h5\n",
      "Epoch 194/200\n",
      "1083/1083 [==============================] - 11s 10ms/step - loss: 0.3612 - acc: 0.8539 - val_loss: 0.3478 - val_acc: 0.8707\n",
      "\n",
      "Epoch 00194: val_acc did not improve from 0.87656\n",
      "Epoch 195/200\n",
      "1083/1083 [==============================] - 11s 10ms/step - loss: 0.3662 - acc: 0.8521 - val_loss: 0.3413 - val_acc: 0.8732\n",
      "\n",
      "Epoch 00195: val_acc did not improve from 0.87656\n",
      "Epoch 196/200\n",
      "1083/1083 [==============================] - 11s 10ms/step - loss: 0.3635 - acc: 0.8536 - val_loss: 0.3530 - val_acc: 0.8706\n",
      "\n",
      "Epoch 00196: val_acc did not improve from 0.87656\n",
      "Epoch 197/200\n",
      "1083/1083 [==============================] - 11s 10ms/step - loss: 0.3633 - acc: 0.8533 - val_loss: 0.3389 - val_acc: 0.8726\n",
      "\n",
      "Epoch 00197: val_acc did not improve from 0.87656\n",
      "Epoch 198/200\n",
      "1083/1083 [==============================] - 11s 10ms/step - loss: 0.3617 - acc: 0.8534 - val_loss: 0.3449 - val_acc: 0.8703\n",
      "\n",
      "Epoch 00198: val_acc did not improve from 0.87656\n",
      "Epoch 199/200\n",
      "1083/1083 [==============================] - 11s 10ms/step - loss: 0.3633 - acc: 0.8540 - val_loss: 0.3347 - val_acc: 0.8763\n",
      "\n",
      "Epoch 00199: val_acc did not improve from 0.87656\n",
      "Epoch 200/200\n",
      "1083/1083 [==============================] - 11s 10ms/step - loss: 0.3611 - acc: 0.8547 - val_loss: 0.3403 - val_acc: 0.8735\n",
      "\n",
      "Epoch 00200: val_acc did not improve from 0.87656\n",
      "CPU times: user 3h 16min 50s, sys: 20min 41s, total: 3h 37min 32s\n",
      "Wall time: 37min 10s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "mc1 = ModelCheckpoint('best_model_f1.h5', monitor='val_acc', mode='max', save_best_only=True,verbose=1)  \n",
    "history1 = model1.fit(X_train, y_train, batch_size=64, epochs=200, validation_split=0.2, verbose=1, callbacks=[mc1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "78008339",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('history_f1.json', 'w') as f:\n",
    "    json.dump(history1.history, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e4641c00",
   "metadata": {},
   "outputs": [],
   "source": [
    "model1.save('themodel_f1.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "976d49ed",
   "metadata": {},
   "source": [
    "## LSTM 2 Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "70acd36f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 30, 300)           31476300  \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 30, 64)            93440     \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 30, 64)            33024     \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_1 (Glob (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 3)                 195       \n",
      "=================================================================\n",
      "Total params: 31,607,119\n",
      "Trainable params: 130,819\n",
      "Non-trainable params: 31,476,300\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model2=Sequential()\n",
    "model2.add(Embedding(size_of_vocabulary,embedding_dim,weights=[embedding_matrix],input_length=max_length,trainable=False))\n",
    "\n",
    "#Lstm layer\n",
    "model2.add(LSTM(UNITS,return_sequences=True,dropout=0.5))\n",
    "model2.add(LSTM(UNITS,return_sequences=True))\n",
    "\n",
    "#Global Maxpooling\n",
    "model2.add(GlobalMaxPooling1D())\n",
    "\n",
    "#Dense Layer\n",
    "model2.add(Dense(UNITS, activation='relu'))\n",
    "\n",
    "#Output layer 3 class\n",
    "model2.add(Dense(3,activation='softmax')) \n",
    "\n",
    "model2.compile(optimizer=Adam(learning_rate = lr), loss = 'sparse_categorical_crossentropy', metrics = ['acc']) \n",
    "print(model2.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "17f9f91e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "1083/1083 [==============================] - 28s 24ms/step - loss: 0.8422 - acc: 0.6117 - val_loss: 0.7556 - val_acc: 0.6727\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.67275, saving model to best_model_f2.h5\n",
      "Epoch 2/200\n",
      "1083/1083 [==============================] - 25s 23ms/step - loss: 0.7846 - acc: 0.6435 - val_loss: 0.7214 - val_acc: 0.6830\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.67275 to 0.68297, saving model to best_model_f2.h5\n",
      "Epoch 3/200\n",
      "1083/1083 [==============================] - 25s 23ms/step - loss: 0.7570 - acc: 0.6592 - val_loss: 0.7003 - val_acc: 0.6945\n",
      "\n",
      "Epoch 00003: val_acc improved from 0.68297 to 0.69446, saving model to best_model_f2.h5\n",
      "Epoch 4/200\n",
      "1083/1083 [==============================] - 25s 23ms/step - loss: 0.7326 - acc: 0.6719 - val_loss: 0.6856 - val_acc: 0.7060\n",
      "\n",
      "Epoch 00004: val_acc improved from 0.69446 to 0.70600, saving model to best_model_f2.h5\n",
      "Epoch 5/200\n",
      "1083/1083 [==============================] - 25s 23ms/step - loss: 0.7148 - acc: 0.6820 - val_loss: 0.6615 - val_acc: 0.7168\n",
      "\n",
      "Epoch 00005: val_acc improved from 0.70600 to 0.71680, saving model to best_model_f2.h5\n",
      "Epoch 6/200\n",
      "1083/1083 [==============================] - 25s 23ms/step - loss: 0.6981 - acc: 0.6919 - val_loss: 0.6496 - val_acc: 0.7174\n",
      "\n",
      "Epoch 00006: val_acc improved from 0.71680 to 0.71744, saving model to best_model_f2.h5\n",
      "Epoch 7/200\n",
      "1083/1083 [==============================] - 25s 23ms/step - loss: 0.6844 - acc: 0.6986 - val_loss: 0.6379 - val_acc: 0.7257\n",
      "\n",
      "Epoch 00007: val_acc improved from 0.71744 to 0.72569, saving model to best_model_f2.h5\n",
      "Epoch 8/200\n",
      "1083/1083 [==============================] - 25s 23ms/step - loss: 0.6660 - acc: 0.7070 - val_loss: 0.6263 - val_acc: 0.7347\n",
      "\n",
      "Epoch 00008: val_acc improved from 0.72569 to 0.73470, saving model to best_model_f2.h5\n",
      "Epoch 9/200\n",
      "1083/1083 [==============================] - 25s 23ms/step - loss: 0.6535 - acc: 0.7155 - val_loss: 0.6159 - val_acc: 0.7365\n",
      "\n",
      "Epoch 00009: val_acc improved from 0.73470 to 0.73649, saving model to best_model_f2.h5\n",
      "Epoch 10/200\n",
      "1083/1083 [==============================] - 25s 24ms/step - loss: 0.6381 - acc: 0.7236 - val_loss: 0.5894 - val_acc: 0.7507\n",
      "\n",
      "Epoch 00010: val_acc improved from 0.73649 to 0.75069, saving model to best_model_f2.h5\n",
      "Epoch 11/200\n",
      "1083/1083 [==============================] - 25s 23ms/step - loss: 0.6261 - acc: 0.7298 - val_loss: 0.5792 - val_acc: 0.7562\n",
      "\n",
      "Epoch 00011: val_acc improved from 0.75069 to 0.75618, saving model to best_model_f2.h5\n",
      "Epoch 12/200\n",
      "1083/1083 [==============================] - 26s 24ms/step - loss: 0.6106 - acc: 0.7371 - val_loss: 0.5775 - val_acc: 0.7561\n",
      "\n",
      "Epoch 00012: val_acc did not improve from 0.75618\n",
      "Epoch 13/200\n",
      "1083/1083 [==============================] - 25s 23ms/step - loss: 0.5974 - acc: 0.7429 - val_loss: 0.5580 - val_acc: 0.7674\n",
      "\n",
      "Epoch 00013: val_acc improved from 0.75618 to 0.76744, saving model to best_model_f2.h5\n",
      "Epoch 14/200\n",
      "1083/1083 [==============================] - 25s 23ms/step - loss: 0.5863 - acc: 0.7496 - val_loss: 0.5494 - val_acc: 0.7720\n",
      "\n",
      "Epoch 00014: val_acc improved from 0.76744 to 0.77200, saving model to best_model_f2.h5\n",
      "Epoch 15/200\n",
      "1083/1083 [==============================] - 25s 23ms/step - loss: 0.5763 - acc: 0.7537 - val_loss: 0.5321 - val_acc: 0.7785\n",
      "\n",
      "Epoch 00015: val_acc improved from 0.77200 to 0.77846, saving model to best_model_f2.h5\n",
      "Epoch 16/200\n",
      "1083/1083 [==============================] - 25s 24ms/step - loss: 0.5666 - acc: 0.7580 - val_loss: 0.5294 - val_acc: 0.7828\n",
      "\n",
      "Epoch 00016: val_acc improved from 0.77846 to 0.78279, saving model to best_model_f2.h5\n",
      "Epoch 17/200\n",
      "1083/1083 [==============================] - 25s 23ms/step - loss: 0.5546 - acc: 0.7656 - val_loss: 0.5178 - val_acc: 0.7880\n",
      "\n",
      "Epoch 00017: val_acc improved from 0.78279 to 0.78805, saving model to best_model_f2.h5\n",
      "Epoch 18/200\n",
      "1083/1083 [==============================] - 25s 23ms/step - loss: 0.5482 - acc: 0.7698 - val_loss: 0.5055 - val_acc: 0.7961\n",
      "\n",
      "Epoch 00018: val_acc improved from 0.78805 to 0.79613, saving model to best_model_f2.h5\n",
      "Epoch 19/200\n",
      "1083/1083 [==============================] - 25s 23ms/step - loss: 0.5388 - acc: 0.7732 - val_loss: 0.5008 - val_acc: 0.7969\n",
      "\n",
      "Epoch 00019: val_acc improved from 0.79613 to 0.79694, saving model to best_model_f2.h5\n",
      "Epoch 20/200\n",
      "1083/1083 [==============================] - 25s 24ms/step - loss: 0.5305 - acc: 0.7751 - val_loss: 0.5012 - val_acc: 0.7979\n",
      "\n",
      "Epoch 00020: val_acc improved from 0.79694 to 0.79786, saving model to best_model_f2.h5\n",
      "Epoch 21/200\n",
      "1083/1083 [==============================] - 25s 24ms/step - loss: 0.5228 - acc: 0.7807 - val_loss: 0.4984 - val_acc: 0.7983\n",
      "\n",
      "Epoch 00021: val_acc improved from 0.79786 to 0.79833, saving model to best_model_f2.h5\n",
      "Epoch 22/200\n",
      "1083/1083 [==============================] - 25s 23ms/step - loss: 0.5179 - acc: 0.7827 - val_loss: 0.4818 - val_acc: 0.8072\n",
      "\n",
      "Epoch 00022: val_acc improved from 0.79833 to 0.80716, saving model to best_model_f2.h5\n",
      "Epoch 23/200\n",
      "1083/1083 [==============================] - 26s 24ms/step - loss: 0.5095 - acc: 0.7870 - val_loss: 0.4732 - val_acc: 0.8125\n",
      "\n",
      "Epoch 00023: val_acc improved from 0.80716 to 0.81247, saving model to best_model_f2.h5\n",
      "Epoch 24/200\n",
      "1083/1083 [==============================] - 25s 23ms/step - loss: 0.5016 - acc: 0.7903 - val_loss: 0.4673 - val_acc: 0.8143\n",
      "\n",
      "Epoch 00024: val_acc improved from 0.81247 to 0.81432, saving model to best_model_f2.h5\n",
      "Epoch 25/200\n",
      "1083/1083 [==============================] - 25s 23ms/step - loss: 0.5001 - acc: 0.7916 - val_loss: 0.4685 - val_acc: 0.8125\n",
      "\n",
      "Epoch 00025: val_acc did not improve from 0.81432\n",
      "Epoch 26/200\n",
      "1083/1083 [==============================] - 25s 23ms/step - loss: 0.4944 - acc: 0.7942 - val_loss: 0.4588 - val_acc: 0.8163\n",
      "\n",
      "Epoch 00026: val_acc improved from 0.81432 to 0.81628, saving model to best_model_f2.h5\n",
      "Epoch 27/200\n",
      "1083/1083 [==============================] - 25s 24ms/step - loss: 0.4859 - acc: 0.7976 - val_loss: 0.4603 - val_acc: 0.8155\n",
      "\n",
      "Epoch 00027: val_acc did not improve from 0.81628\n",
      "Epoch 28/200\n",
      "1083/1083 [==============================] - 25s 23ms/step - loss: 0.4812 - acc: 0.8000 - val_loss: 0.4534 - val_acc: 0.8208\n",
      "\n",
      "Epoch 00028: val_acc improved from 0.81628 to 0.82079, saving model to best_model_f2.h5\n",
      "Epoch 29/200\n",
      "1083/1083 [==============================] - 25s 23ms/step - loss: 0.4746 - acc: 0.8037 - val_loss: 0.4504 - val_acc: 0.8224\n",
      "\n",
      "Epoch 00029: val_acc improved from 0.82079 to 0.82240, saving model to best_model_f2.h5\n",
      "Epoch 30/200\n",
      "1083/1083 [==============================] - 25s 23ms/step - loss: 0.4714 - acc: 0.8044 - val_loss: 0.4403 - val_acc: 0.8282\n",
      "\n",
      "Epoch 00030: val_acc improved from 0.82240 to 0.82823, saving model to best_model_f2.h5\n",
      "Epoch 31/200\n",
      "1083/1083 [==============================] - 25s 24ms/step - loss: 0.4696 - acc: 0.8050 - val_loss: 0.4373 - val_acc: 0.8273\n",
      "\n",
      "Epoch 00031: val_acc did not improve from 0.82823\n",
      "Epoch 32/200\n",
      "1083/1083 [==============================] - 26s 24ms/step - loss: 0.4666 - acc: 0.8088 - val_loss: 0.4334 - val_acc: 0.8290\n",
      "\n",
      "Epoch 00032: val_acc improved from 0.82823 to 0.82898, saving model to best_model_f2.h5\n",
      "Epoch 33/200\n",
      "1083/1083 [==============================] - 25s 24ms/step - loss: 0.4549 - acc: 0.8120 - val_loss: 0.4345 - val_acc: 0.8297\n",
      "\n",
      "Epoch 00033: val_acc improved from 0.82898 to 0.82968, saving model to best_model_f2.h5\n",
      "Epoch 34/200\n",
      "1083/1083 [==============================] - 25s 23ms/step - loss: 0.4574 - acc: 0.8111 - val_loss: 0.4242 - val_acc: 0.8349\n",
      "\n",
      "Epoch 00034: val_acc improved from 0.82968 to 0.83487, saving model to best_model_f2.h5\n",
      "Epoch 35/200\n",
      "1083/1083 [==============================] - 26s 24ms/step - loss: 0.4471 - acc: 0.8160 - val_loss: 0.4273 - val_acc: 0.8339\n",
      "\n",
      "Epoch 00035: val_acc did not improve from 0.83487\n",
      "Epoch 36/200\n",
      "1083/1083 [==============================] - 25s 24ms/step - loss: 0.4456 - acc: 0.8168 - val_loss: 0.4222 - val_acc: 0.8333\n",
      "\n",
      "Epoch 00036: val_acc did not improve from 0.83487\n",
      "Epoch 37/200\n",
      "1083/1083 [==============================] - 25s 23ms/step - loss: 0.4447 - acc: 0.8173 - val_loss: 0.4159 - val_acc: 0.8384\n",
      "\n",
      "Epoch 00037: val_acc improved from 0.83487 to 0.83839, saving model to best_model_f2.h5\n",
      "Epoch 38/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1083/1083 [==============================] - 25s 23ms/step - loss: 0.4404 - acc: 0.8186 - val_loss: 0.4219 - val_acc: 0.8372\n",
      "\n",
      "Epoch 00038: val_acc did not improve from 0.83839\n",
      "Epoch 39/200\n",
      "1083/1083 [==============================] - 26s 24ms/step - loss: 0.4377 - acc: 0.8215 - val_loss: 0.4113 - val_acc: 0.8423\n",
      "\n",
      "Epoch 00039: val_acc improved from 0.83839 to 0.84226, saving model to best_model_f2.h5\n",
      "Epoch 40/200\n",
      "1083/1083 [==============================] - 25s 24ms/step - loss: 0.4330 - acc: 0.8213 - val_loss: 0.4092 - val_acc: 0.8434\n",
      "\n",
      "Epoch 00040: val_acc improved from 0.84226 to 0.84342, saving model to best_model_f2.h5\n",
      "Epoch 41/200\n",
      "1083/1083 [==============================] - 25s 24ms/step - loss: 0.4277 - acc: 0.8246 - val_loss: 0.3999 - val_acc: 0.8473\n",
      "\n",
      "Epoch 00041: val_acc improved from 0.84342 to 0.84729, saving model to best_model_f2.h5\n",
      "Epoch 42/200\n",
      "1083/1083 [==============================] - 25s 23ms/step - loss: 0.4251 - acc: 0.8256 - val_loss: 0.4002 - val_acc: 0.8462\n",
      "\n",
      "Epoch 00042: val_acc did not improve from 0.84729\n",
      "Epoch 43/200\n",
      "1083/1083 [==============================] - 25s 23ms/step - loss: 0.4229 - acc: 0.8268 - val_loss: 0.3979 - val_acc: 0.8455\n",
      "\n",
      "Epoch 00043: val_acc did not improve from 0.84729\n",
      "Epoch 44/200\n",
      "1083/1083 [==============================] - 25s 24ms/step - loss: 0.4192 - acc: 0.8289 - val_loss: 0.4016 - val_acc: 0.8461\n",
      "\n",
      "Epoch 00044: val_acc did not improve from 0.84729\n",
      "Epoch 45/200\n",
      "1083/1083 [==============================] - 25s 23ms/step - loss: 0.4165 - acc: 0.8290 - val_loss: 0.3900 - val_acc: 0.8507\n",
      "\n",
      "Epoch 00045: val_acc improved from 0.84729 to 0.85069, saving model to best_model_f2.h5\n",
      "Epoch 46/200\n",
      "1083/1083 [==============================] - 25s 23ms/step - loss: 0.4173 - acc: 0.8303 - val_loss: 0.3870 - val_acc: 0.8543\n",
      "\n",
      "Epoch 00046: val_acc improved from 0.85069 to 0.85433, saving model to best_model_f2.h5\n",
      "Epoch 47/200\n",
      "1083/1083 [==============================] - 25s 23ms/step - loss: 0.4122 - acc: 0.8316 - val_loss: 0.4006 - val_acc: 0.8491\n",
      "\n",
      "Epoch 00047: val_acc did not improve from 0.85433\n",
      "Epoch 48/200\n",
      "1083/1083 [==============================] - 25s 24ms/step - loss: 0.4069 - acc: 0.8347 - val_loss: 0.4066 - val_acc: 0.8456\n",
      "\n",
      "Epoch 00048: val_acc did not improve from 0.85433\n",
      "Epoch 49/200\n",
      "1083/1083 [==============================] - 25s 23ms/step - loss: 0.4077 - acc: 0.8335 - val_loss: 0.4021 - val_acc: 0.8462\n",
      "\n",
      "Epoch 00049: val_acc did not improve from 0.85433\n",
      "Epoch 50/200\n",
      "1083/1083 [==============================] - 25s 23ms/step - loss: 0.4041 - acc: 0.8349 - val_loss: 0.3828 - val_acc: 0.8546\n",
      "\n",
      "Epoch 00050: val_acc improved from 0.85433 to 0.85462, saving model to best_model_f2.h5\n",
      "Epoch 51/200\n",
      "1083/1083 [==============================] - 25s 23ms/step - loss: 0.4014 - acc: 0.8363 - val_loss: 0.3883 - val_acc: 0.8529\n",
      "\n",
      "Epoch 00051: val_acc did not improve from 0.85462\n",
      "Epoch 52/200\n",
      "1083/1083 [==============================] - 26s 24ms/step - loss: 0.4006 - acc: 0.8373 - val_loss: 0.3916 - val_acc: 0.8475\n",
      "\n",
      "Epoch 00052: val_acc did not improve from 0.85462\n",
      "Epoch 53/200\n",
      "1083/1083 [==============================] - 25s 24ms/step - loss: 0.3959 - acc: 0.8386 - val_loss: 0.3878 - val_acc: 0.8523\n",
      "\n",
      "Epoch 00053: val_acc did not improve from 0.85462\n",
      "Epoch 54/200\n",
      "1083/1083 [==============================] - 26s 24ms/step - loss: 0.3935 - acc: 0.8401 - val_loss: 0.3882 - val_acc: 0.8497\n",
      "\n",
      "Epoch 00054: val_acc did not improve from 0.85462\n",
      "Epoch 55/200\n",
      "1083/1083 [==============================] - 25s 23ms/step - loss: 0.3940 - acc: 0.8402 - val_loss: 0.3894 - val_acc: 0.8518\n",
      "\n",
      "Epoch 00055: val_acc did not improve from 0.85462\n",
      "Epoch 56/200\n",
      "1083/1083 [==============================] - 25s 23ms/step - loss: 0.3859 - acc: 0.8440 - val_loss: 0.3786 - val_acc: 0.8555\n",
      "\n",
      "Epoch 00056: val_acc improved from 0.85462 to 0.85548, saving model to best_model_f2.h5\n",
      "Epoch 57/200\n",
      "1083/1083 [==============================] - 25s 24ms/step - loss: 0.3872 - acc: 0.8433 - val_loss: 0.3809 - val_acc: 0.8553\n",
      "\n",
      "Epoch 00057: val_acc did not improve from 0.85548\n",
      "Epoch 58/200\n",
      "1083/1083 [==============================] - 25s 24ms/step - loss: 0.3850 - acc: 0.8453 - val_loss: 0.3740 - val_acc: 0.8577\n",
      "\n",
      "Epoch 00058: val_acc improved from 0.85548 to 0.85774, saving model to best_model_f2.h5\n",
      "Epoch 59/200\n",
      "1083/1083 [==============================] - 25s 23ms/step - loss: 0.3837 - acc: 0.8441 - val_loss: 0.4062 - val_acc: 0.8439\n",
      "\n",
      "Epoch 00059: val_acc did not improve from 0.85774\n",
      "Epoch 60/200\n",
      "1083/1083 [==============================] - 25s 24ms/step - loss: 0.3817 - acc: 0.8449 - val_loss: 0.3802 - val_acc: 0.8572\n",
      "\n",
      "Epoch 00060: val_acc did not improve from 0.85774\n",
      "Epoch 61/200\n",
      "1083/1083 [==============================] - 25s 24ms/step - loss: 0.3812 - acc: 0.8451 - val_loss: 0.3751 - val_acc: 0.8588\n",
      "\n",
      "Epoch 00061: val_acc improved from 0.85774 to 0.85883, saving model to best_model_f2.h5\n",
      "Epoch 62/200\n",
      "1083/1083 [==============================] - 25s 24ms/step - loss: 0.3760 - acc: 0.8483 - val_loss: 0.3874 - val_acc: 0.8524\n",
      "\n",
      "Epoch 00062: val_acc did not improve from 0.85883\n",
      "Epoch 63/200\n",
      "1083/1083 [==============================] - 25s 23ms/step - loss: 0.3783 - acc: 0.8479 - val_loss: 0.3646 - val_acc: 0.8626\n",
      "\n",
      "Epoch 00063: val_acc improved from 0.85883 to 0.86264, saving model to best_model_f2.h5\n",
      "Epoch 64/200\n",
      "1083/1083 [==============================] - 25s 24ms/step - loss: 0.3771 - acc: 0.8476 - val_loss: 0.3774 - val_acc: 0.8591\n",
      "\n",
      "Epoch 00064: val_acc did not improve from 0.86264\n",
      "Epoch 65/200\n",
      "1083/1083 [==============================] - 25s 23ms/step - loss: 0.3730 - acc: 0.8505 - val_loss: 0.3750 - val_acc: 0.8584\n",
      "\n",
      "Epoch 00065: val_acc did not improve from 0.86264\n",
      "Epoch 66/200\n",
      "1083/1083 [==============================] - 25s 24ms/step - loss: 0.3728 - acc: 0.8505 - val_loss: 0.3678 - val_acc: 0.8619\n",
      "\n",
      "Epoch 00066: val_acc did not improve from 0.86264\n",
      "Epoch 67/200\n",
      "1083/1083 [==============================] - 25s 23ms/step - loss: 0.3697 - acc: 0.8518 - val_loss: 0.3674 - val_acc: 0.8645\n",
      "\n",
      "Epoch 00067: val_acc improved from 0.86264 to 0.86449, saving model to best_model_f2.h5\n",
      "Epoch 68/200\n",
      "1083/1083 [==============================] - 25s 23ms/step - loss: 0.3681 - acc: 0.8508 - val_loss: 0.3647 - val_acc: 0.8652\n",
      "\n",
      "Epoch 00068: val_acc improved from 0.86449 to 0.86518, saving model to best_model_f2.h5\n",
      "Epoch 69/200\n",
      "1083/1083 [==============================] - 25s 23ms/step - loss: 0.3667 - acc: 0.8518 - val_loss: 0.3698 - val_acc: 0.8591\n",
      "\n",
      "Epoch 00069: val_acc did not improve from 0.86518\n",
      "Epoch 70/200\n",
      "1083/1083 [==============================] - 25s 23ms/step - loss: 0.3663 - acc: 0.8528 - val_loss: 0.3683 - val_acc: 0.8637\n",
      "\n",
      "Epoch 00070: val_acc did not improve from 0.86518\n",
      "Epoch 71/200\n",
      "1083/1083 [==============================] - 25s 24ms/step - loss: 0.3657 - acc: 0.8532 - val_loss: 0.3692 - val_acc: 0.8602\n",
      "\n",
      "Epoch 00071: val_acc did not improve from 0.86518\n",
      "Epoch 72/200\n",
      "1083/1083 [==============================] - 25s 23ms/step - loss: 0.3617 - acc: 0.8545 - val_loss: 0.3597 - val_acc: 0.8669\n",
      "\n",
      "Epoch 00072: val_acc improved from 0.86518 to 0.86686, saving model to best_model_f2.h5\n",
      "Epoch 73/200\n",
      "1083/1083 [==============================] - 25s 23ms/step - loss: 0.3599 - acc: 0.8556 - val_loss: 0.3732 - val_acc: 0.8629\n",
      "\n",
      "Epoch 00073: val_acc did not improve from 0.86686\n",
      "Epoch 74/200\n",
      "1083/1083 [==============================] - 25s 23ms/step - loss: 0.3594 - acc: 0.8548 - val_loss: 0.3621 - val_acc: 0.8652\n",
      "\n",
      "Epoch 00074: val_acc did not improve from 0.86686\n",
      "Epoch 75/200\n",
      "1083/1083 [==============================] - 26s 24ms/step - loss: 0.3535 - acc: 0.8577 - val_loss: 0.3612 - val_acc: 0.8663\n",
      "\n",
      "Epoch 00075: val_acc did not improve from 0.86686\n",
      "Epoch 76/200\n",
      "1083/1083 [==============================] - 25s 23ms/step - loss: 0.3556 - acc: 0.8572 - val_loss: 0.3674 - val_acc: 0.8628\n",
      "\n",
      "Epoch 00076: val_acc did not improve from 0.86686\n",
      "Epoch 77/200\n",
      "1083/1083 [==============================] - 25s 24ms/step - loss: 0.3558 - acc: 0.8567 - val_loss: 0.3656 - val_acc: 0.8660\n",
      "\n",
      "Epoch 00077: val_acc did not improve from 0.86686\n",
      "Epoch 78/200\n",
      "1083/1083 [==============================] - 25s 23ms/step - loss: 0.3547 - acc: 0.8569 - val_loss: 0.3637 - val_acc: 0.8662\n",
      "\n",
      "Epoch 00078: val_acc did not improve from 0.86686\n",
      "Epoch 79/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1083/1083 [==============================] - 26s 24ms/step - loss: 0.3500 - acc: 0.8599 - val_loss: 0.3559 - val_acc: 0.8706\n",
      "\n",
      "Epoch 00079: val_acc improved from 0.86686 to 0.87055, saving model to best_model_f2.h5\n",
      "Epoch 80/200\n",
      "1083/1083 [==============================] - 25s 23ms/step - loss: 0.3471 - acc: 0.8603 - val_loss: 0.3588 - val_acc: 0.8673\n",
      "\n",
      "Epoch 00080: val_acc did not improve from 0.87055\n",
      "Epoch 81/200\n",
      "1083/1083 [==============================] - 26s 24ms/step - loss: 0.3486 - acc: 0.8592 - val_loss: 0.3592 - val_acc: 0.8695\n",
      "\n",
      "Epoch 00081: val_acc did not improve from 0.87055\n",
      "Epoch 82/200\n",
      "1083/1083 [==============================] - 25s 24ms/step - loss: 0.3477 - acc: 0.8611 - val_loss: 0.3851 - val_acc: 0.8574\n",
      "\n",
      "Epoch 00082: val_acc did not improve from 0.87055\n",
      "Epoch 83/200\n",
      "1083/1083 [==============================] - 26s 24ms/step - loss: 0.3473 - acc: 0.8608 - val_loss: 0.3555 - val_acc: 0.8677\n",
      "\n",
      "Epoch 00083: val_acc did not improve from 0.87055\n",
      "Epoch 84/200\n",
      "1083/1083 [==============================] - 25s 23ms/step - loss: 0.3475 - acc: 0.8598 - val_loss: 0.3585 - val_acc: 0.8690\n",
      "\n",
      "Epoch 00084: val_acc did not improve from 0.87055\n",
      "Epoch 85/200\n",
      "1083/1083 [==============================] - 25s 24ms/step - loss: 0.3439 - acc: 0.8645 - val_loss: 0.3522 - val_acc: 0.8712\n",
      "\n",
      "Epoch 00085: val_acc improved from 0.87055 to 0.87125, saving model to best_model_f2.h5\n",
      "Epoch 86/200\n",
      "1083/1083 [==============================] - 25s 23ms/step - loss: 0.3420 - acc: 0.8633 - val_loss: 0.3604 - val_acc: 0.8689\n",
      "\n",
      "Epoch 00086: val_acc did not improve from 0.87125\n",
      "Epoch 87/200\n",
      "1083/1083 [==============================] - 25s 23ms/step - loss: 0.3437 - acc: 0.8627 - val_loss: 0.3633 - val_acc: 0.8688\n",
      "\n",
      "Epoch 00087: val_acc did not improve from 0.87125\n",
      "Epoch 88/200\n",
      "1083/1083 [==============================] - 25s 23ms/step - loss: 0.3440 - acc: 0.8616 - val_loss: 0.3420 - val_acc: 0.8746\n",
      "\n",
      "Epoch 00088: val_acc improved from 0.87125 to 0.87460, saving model to best_model_f2.h5\n",
      "Epoch 89/200\n",
      "1083/1083 [==============================] - 25s 23ms/step - loss: 0.3445 - acc: 0.8621 - val_loss: 0.3548 - val_acc: 0.8725\n",
      "\n",
      "Epoch 00089: val_acc did not improve from 0.87460\n",
      "Epoch 90/200\n",
      "1083/1083 [==============================] - 25s 24ms/step - loss: 0.3371 - acc: 0.8642 - val_loss: 0.3527 - val_acc: 0.8684\n",
      "\n",
      "Epoch 00090: val_acc did not improve from 0.87460\n",
      "Epoch 91/200\n",
      "1083/1083 [==============================] - 26s 24ms/step - loss: 0.3355 - acc: 0.8658 - val_loss: 0.3470 - val_acc: 0.8737\n",
      "\n",
      "Epoch 00091: val_acc did not improve from 0.87460\n",
      "Epoch 92/200\n",
      "1083/1083 [==============================] - 26s 24ms/step - loss: 0.3330 - acc: 0.8669 - val_loss: 0.3576 - val_acc: 0.8709\n",
      "\n",
      "Epoch 00092: val_acc did not improve from 0.87460\n",
      "Epoch 93/200\n",
      "1083/1083 [==============================] - 25s 24ms/step - loss: 0.3344 - acc: 0.8660 - val_loss: 0.3622 - val_acc: 0.8704\n",
      "\n",
      "Epoch 00093: val_acc did not improve from 0.87460\n",
      "Epoch 94/200\n",
      "1083/1083 [==============================] - 25s 23ms/step - loss: 0.3327 - acc: 0.8686 - val_loss: 0.3600 - val_acc: 0.8688\n",
      "\n",
      "Epoch 00094: val_acc did not improve from 0.87460\n",
      "Epoch 95/200\n",
      "1083/1083 [==============================] - 26s 24ms/step - loss: 0.3311 - acc: 0.8672 - val_loss: 0.3716 - val_acc: 0.8644\n",
      "\n",
      "Epoch 00095: val_acc did not improve from 0.87460\n",
      "Epoch 96/200\n",
      "1083/1083 [==============================] - 25s 24ms/step - loss: 0.3313 - acc: 0.8673 - val_loss: 0.3491 - val_acc: 0.8760\n",
      "\n",
      "Epoch 00096: val_acc improved from 0.87460 to 0.87604, saving model to best_model_f2.h5\n",
      "Epoch 97/200\n",
      "1083/1083 [==============================] - 25s 24ms/step - loss: 0.3324 - acc: 0.8663 - val_loss: 0.3477 - val_acc: 0.8724\n",
      "\n",
      "Epoch 00097: val_acc did not improve from 0.87604\n",
      "Epoch 98/200\n",
      "1083/1083 [==============================] - 25s 24ms/step - loss: 0.3282 - acc: 0.8701 - val_loss: 0.3517 - val_acc: 0.8764\n",
      "\n",
      "Epoch 00098: val_acc improved from 0.87604 to 0.87639, saving model to best_model_f2.h5\n",
      "Epoch 99/200\n",
      "1083/1083 [==============================] - 25s 23ms/step - loss: 0.3286 - acc: 0.8697 - val_loss: 0.3544 - val_acc: 0.8727\n",
      "\n",
      "Epoch 00099: val_acc did not improve from 0.87639\n",
      "Epoch 100/200\n",
      "1083/1083 [==============================] - 26s 24ms/step - loss: 0.3286 - acc: 0.8689 - val_loss: 0.3668 - val_acc: 0.8678\n",
      "\n",
      "Epoch 00100: val_acc did not improve from 0.87639\n",
      "Epoch 101/200\n",
      "1083/1083 [==============================] - 25s 23ms/step - loss: 0.3272 - acc: 0.8693 - val_loss: 0.3663 - val_acc: 0.8710\n",
      "\n",
      "Epoch 00101: val_acc did not improve from 0.87639\n",
      "Epoch 102/200\n",
      "1083/1083 [==============================] - 25s 24ms/step - loss: 0.3218 - acc: 0.8714 - val_loss: 0.3533 - val_acc: 0.8766\n",
      "\n",
      "Epoch 00102: val_acc improved from 0.87639 to 0.87662, saving model to best_model_f2.h5\n",
      "Epoch 103/200\n",
      "1083/1083 [==============================] - 25s 24ms/step - loss: 0.3232 - acc: 0.8710 - val_loss: 0.3654 - val_acc: 0.8703\n",
      "\n",
      "Epoch 00103: val_acc did not improve from 0.87662\n",
      "Epoch 104/200\n",
      "1083/1083 [==============================] - 25s 23ms/step - loss: 0.3222 - acc: 0.8718 - val_loss: 0.3559 - val_acc: 0.8729\n",
      "\n",
      "Epoch 00104: val_acc did not improve from 0.87662\n",
      "Epoch 105/200\n",
      "1083/1083 [==============================] - 25s 23ms/step - loss: 0.3276 - acc: 0.8677 - val_loss: 0.3424 - val_acc: 0.8770\n",
      "\n",
      "Epoch 00105: val_acc improved from 0.87662 to 0.87702, saving model to best_model_f2.h5\n",
      "Epoch 106/200\n",
      "1083/1083 [==============================] - 25s 24ms/step - loss: 0.3197 - acc: 0.8729 - val_loss: 0.3497 - val_acc: 0.8744\n",
      "\n",
      "Epoch 00106: val_acc did not improve from 0.87702\n",
      "Epoch 107/200\n",
      "1083/1083 [==============================] - 25s 23ms/step - loss: 0.3218 - acc: 0.8732 - val_loss: 0.3482 - val_acc: 0.8755\n",
      "\n",
      "Epoch 00107: val_acc did not improve from 0.87702\n",
      "Epoch 108/200\n",
      "1083/1083 [==============================] - 26s 24ms/step - loss: 0.3174 - acc: 0.8736 - val_loss: 0.3746 - val_acc: 0.8651\n",
      "\n",
      "Epoch 00108: val_acc did not improve from 0.87702\n",
      "Epoch 109/200\n",
      "1083/1083 [==============================] - 25s 23ms/step - loss: 0.3168 - acc: 0.8739 - val_loss: 0.3396 - val_acc: 0.8809\n",
      "\n",
      "Epoch 00109: val_acc improved from 0.87702 to 0.88095, saving model to best_model_f2.h5\n",
      "Epoch 110/200\n",
      "1083/1083 [==============================] - 25s 23ms/step - loss: 0.3157 - acc: 0.8743 - val_loss: 0.3445 - val_acc: 0.8760\n",
      "\n",
      "Epoch 00110: val_acc did not improve from 0.88095\n",
      "Epoch 111/200\n",
      "1083/1083 [==============================] - 25s 23ms/step - loss: 0.3142 - acc: 0.8747 - val_loss: 0.3483 - val_acc: 0.8764\n",
      "\n",
      "Epoch 00111: val_acc did not improve from 0.88095\n",
      "Epoch 112/200\n",
      "1083/1083 [==============================] - 26s 24ms/step - loss: 0.3130 - acc: 0.8760 - val_loss: 0.3658 - val_acc: 0.8714\n",
      "\n",
      "Epoch 00112: val_acc did not improve from 0.88095\n",
      "Epoch 113/200\n",
      "1083/1083 [==============================] - 25s 24ms/step - loss: 0.3175 - acc: 0.8734 - val_loss: 0.3566 - val_acc: 0.8714\n",
      "\n",
      "Epoch 00113: val_acc did not improve from 0.88095\n",
      "Epoch 114/200\n",
      "1083/1083 [==============================] - 25s 23ms/step - loss: 0.3121 - acc: 0.8758 - val_loss: 0.3553 - val_acc: 0.8747\n",
      "\n",
      "Epoch 00114: val_acc did not improve from 0.88095\n",
      "Epoch 115/200\n",
      "1083/1083 [==============================] - 26s 24ms/step - loss: 0.3141 - acc: 0.8757 - val_loss: 0.3532 - val_acc: 0.8745\n",
      "\n",
      "Epoch 00115: val_acc did not improve from 0.88095\n",
      "Epoch 116/200\n",
      "1083/1083 [==============================] - 26s 24ms/step - loss: 0.3127 - acc: 0.8756 - val_loss: 0.3376 - val_acc: 0.8819\n",
      "\n",
      "Epoch 00116: val_acc improved from 0.88095 to 0.88187, saving model to best_model_f2.h5\n",
      "Epoch 117/200\n",
      "1083/1083 [==============================] - 25s 24ms/step - loss: 0.3101 - acc: 0.8767 - val_loss: 0.3413 - val_acc: 0.8777\n",
      "\n",
      "Epoch 00117: val_acc did not improve from 0.88187\n",
      "Epoch 118/200\n",
      "1083/1083 [==============================] - 26s 24ms/step - loss: 0.3098 - acc: 0.8782 - val_loss: 0.3531 - val_acc: 0.8755\n",
      "\n",
      "Epoch 00118: val_acc did not improve from 0.88187\n",
      "Epoch 119/200\n",
      "1083/1083 [==============================] - 25s 24ms/step - loss: 0.3086 - acc: 0.8780 - val_loss: 0.3529 - val_acc: 0.8737\n",
      "\n",
      "Epoch 00119: val_acc did not improve from 0.88187\n",
      "Epoch 120/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1083/1083 [==============================] - 25s 24ms/step - loss: 0.3065 - acc: 0.8787 - val_loss: 0.3550 - val_acc: 0.8756\n",
      "\n",
      "Epoch 00120: val_acc did not improve from 0.88187\n",
      "Epoch 121/200\n",
      "1083/1083 [==============================] - 25s 23ms/step - loss: 0.3081 - acc: 0.8782 - val_loss: 0.3469 - val_acc: 0.8800\n",
      "\n",
      "Epoch 00121: val_acc did not improve from 0.88187\n",
      "Epoch 122/200\n",
      "1083/1083 [==============================] - 26s 24ms/step - loss: 0.3066 - acc: 0.8779 - val_loss: 0.3534 - val_acc: 0.8751\n",
      "\n",
      "Epoch 00122: val_acc did not improve from 0.88187\n",
      "Epoch 123/200\n",
      "1083/1083 [==============================] - 26s 24ms/step - loss: 0.3066 - acc: 0.8774 - val_loss: 0.3541 - val_acc: 0.8767\n",
      "\n",
      "Epoch 00123: val_acc did not improve from 0.88187\n",
      "Epoch 124/200\n",
      "1083/1083 [==============================] - 25s 23ms/step - loss: 0.3066 - acc: 0.8792 - val_loss: 0.3436 - val_acc: 0.8790\n",
      "\n",
      "Epoch 00124: val_acc did not improve from 0.88187\n",
      "Epoch 125/200\n",
      "1083/1083 [==============================] - 25s 23ms/step - loss: 0.3028 - acc: 0.8805 - val_loss: 0.3595 - val_acc: 0.8760\n",
      "\n",
      "Epoch 00125: val_acc did not improve from 0.88187\n",
      "Epoch 126/200\n",
      "1083/1083 [==============================] - 25s 24ms/step - loss: 0.3025 - acc: 0.8809 - val_loss: 0.3626 - val_acc: 0.8740\n",
      "\n",
      "Epoch 00126: val_acc did not improve from 0.88187\n",
      "Epoch 127/200\n",
      "1083/1083 [==============================] - 25s 24ms/step - loss: 0.3045 - acc: 0.8794 - val_loss: 0.3456 - val_acc: 0.8809\n",
      "\n",
      "Epoch 00127: val_acc did not improve from 0.88187\n",
      "Epoch 128/200\n",
      "1083/1083 [==============================] - 26s 24ms/step - loss: 0.3034 - acc: 0.8810 - val_loss: 0.3474 - val_acc: 0.8766\n",
      "\n",
      "Epoch 00128: val_acc did not improve from 0.88187\n",
      "Epoch 129/200\n",
      "1083/1083 [==============================] - 26s 24ms/step - loss: 0.2999 - acc: 0.8814 - val_loss: 0.3629 - val_acc: 0.8738\n",
      "\n",
      "Epoch 00129: val_acc did not improve from 0.88187\n",
      "Epoch 130/200\n",
      "1083/1083 [==============================] - 25s 24ms/step - loss: 0.3017 - acc: 0.8812 - val_loss: 0.3573 - val_acc: 0.8755\n",
      "\n",
      "Epoch 00130: val_acc did not improve from 0.88187\n",
      "Epoch 131/200\n",
      "1083/1083 [==============================] - 26s 24ms/step - loss: 0.3023 - acc: 0.8810 - val_loss: 0.3450 - val_acc: 0.8781\n",
      "\n",
      "Epoch 00131: val_acc did not improve from 0.88187\n",
      "Epoch 132/200\n",
      "1083/1083 [==============================] - 25s 24ms/step - loss: 0.3019 - acc: 0.8801 - val_loss: 0.3499 - val_acc: 0.8777\n",
      "\n",
      "Epoch 00132: val_acc did not improve from 0.88187\n",
      "Epoch 133/200\n",
      "1083/1083 [==============================] - 25s 23ms/step - loss: 0.2985 - acc: 0.8815 - val_loss: 0.3464 - val_acc: 0.8781\n",
      "\n",
      "Epoch 00133: val_acc did not improve from 0.88187\n",
      "Epoch 134/200\n",
      "1083/1083 [==============================] - 25s 23ms/step - loss: 0.2974 - acc: 0.8814 - val_loss: 0.3413 - val_acc: 0.8805\n",
      "\n",
      "Epoch 00134: val_acc did not improve from 0.88187\n",
      "Epoch 135/200\n",
      "1083/1083 [==============================] - 25s 24ms/step - loss: 0.2964 - acc: 0.8821 - val_loss: 0.3562 - val_acc: 0.8775\n",
      "\n",
      "Epoch 00135: val_acc did not improve from 0.88187\n",
      "Epoch 136/200\n",
      "1083/1083 [==============================] - 25s 23ms/step - loss: 0.2976 - acc: 0.8808 - val_loss: 0.3524 - val_acc: 0.8786\n",
      "\n",
      "Epoch 00136: val_acc did not improve from 0.88187\n",
      "Epoch 137/200\n",
      "1083/1083 [==============================] - 25s 23ms/step - loss: 0.2937 - acc: 0.8836 - val_loss: 0.3598 - val_acc: 0.8741\n",
      "\n",
      "Epoch 00137: val_acc did not improve from 0.88187\n",
      "Epoch 138/200\n",
      "1083/1083 [==============================] - 25s 23ms/step - loss: 0.2969 - acc: 0.8823 - val_loss: 0.3394 - val_acc: 0.8860\n",
      "\n",
      "Epoch 00138: val_acc improved from 0.88187 to 0.88603, saving model to best_model_f2.h5\n",
      "Epoch 139/200\n",
      "1083/1083 [==============================] - 25s 23ms/step - loss: 0.2966 - acc: 0.8828 - val_loss: 0.3628 - val_acc: 0.8754\n",
      "\n",
      "Epoch 00139: val_acc did not improve from 0.88603\n",
      "Epoch 140/200\n",
      "1083/1083 [==============================] - 25s 23ms/step - loss: 0.2954 - acc: 0.8832 - val_loss: 0.3603 - val_acc: 0.8742\n",
      "\n",
      "Epoch 00140: val_acc did not improve from 0.88603\n",
      "Epoch 141/200\n",
      "1083/1083 [==============================] - 25s 23ms/step - loss: 0.2929 - acc: 0.8840 - val_loss: 0.3525 - val_acc: 0.8785\n",
      "\n",
      "Epoch 00141: val_acc did not improve from 0.88603\n",
      "Epoch 142/200\n",
      "1083/1083 [==============================] - 25s 23ms/step - loss: 0.2948 - acc: 0.8839 - val_loss: 0.3481 - val_acc: 0.8828\n",
      "\n",
      "Epoch 00142: val_acc did not improve from 0.88603\n",
      "Epoch 143/200\n",
      "1083/1083 [==============================] - 24s 22ms/step - loss: 0.2881 - acc: 0.8860 - val_loss: 0.3530 - val_acc: 0.8804\n",
      "\n",
      "Epoch 00143: val_acc did not improve from 0.88603\n",
      "Epoch 144/200\n",
      "1083/1083 [==============================] - 19s 17ms/step - loss: 0.2905 - acc: 0.8852 - val_loss: 0.3331 - val_acc: 0.8862\n",
      "\n",
      "Epoch 00144: val_acc improved from 0.88603 to 0.88620, saving model to best_model_f2.h5\n",
      "Epoch 145/200\n",
      "1083/1083 [==============================] - 19s 17ms/step - loss: 0.2920 - acc: 0.8852 - val_loss: 0.3385 - val_acc: 0.8842\n",
      "\n",
      "Epoch 00145: val_acc did not improve from 0.88620\n",
      "Epoch 146/200\n",
      "1083/1083 [==============================] - 19s 17ms/step - loss: 0.2903 - acc: 0.8857 - val_loss: 0.3618 - val_acc: 0.8760\n",
      "\n",
      "Epoch 00146: val_acc did not improve from 0.88620\n",
      "Epoch 147/200\n",
      "1083/1083 [==============================] - 19s 17ms/step - loss: 0.2886 - acc: 0.8853 - val_loss: 0.3473 - val_acc: 0.8801\n",
      "\n",
      "Epoch 00147: val_acc did not improve from 0.88620\n",
      "Epoch 148/200\n",
      "1083/1083 [==============================] - 19s 17ms/step - loss: 0.2877 - acc: 0.8854 - val_loss: 0.3541 - val_acc: 0.8797\n",
      "\n",
      "Epoch 00148: val_acc did not improve from 0.88620\n",
      "Epoch 149/200\n",
      "1083/1083 [==============================] - 19s 17ms/step - loss: 0.2887 - acc: 0.8861 - val_loss: 0.3707 - val_acc: 0.8750\n",
      "\n",
      "Epoch 00149: val_acc did not improve from 0.88620\n",
      "Epoch 150/200\n",
      "1083/1083 [==============================] - 19s 17ms/step - loss: 0.2885 - acc: 0.8860 - val_loss: 0.3544 - val_acc: 0.8788\n",
      "\n",
      "Epoch 00150: val_acc did not improve from 0.88620\n",
      "Epoch 151/200\n",
      "1083/1083 [==============================] - 19s 17ms/step - loss: 0.2898 - acc: 0.8856 - val_loss: 0.3356 - val_acc: 0.8883\n",
      "\n",
      "Epoch 00151: val_acc improved from 0.88620 to 0.88828, saving model to best_model_f2.h5\n",
      "Epoch 152/200\n",
      "1083/1083 [==============================] - 19s 17ms/step - loss: 0.2897 - acc: 0.8847 - val_loss: 0.3583 - val_acc: 0.8781\n",
      "\n",
      "Epoch 00152: val_acc did not improve from 0.88828\n",
      "Epoch 153/200\n",
      "1083/1083 [==============================] - 19s 17ms/step - loss: 0.2840 - acc: 0.8891 - val_loss: 0.3570 - val_acc: 0.8801\n",
      "\n",
      "Epoch 00153: val_acc did not improve from 0.88828\n",
      "Epoch 154/200\n",
      "1083/1083 [==============================] - 19s 17ms/step - loss: 0.2852 - acc: 0.8879 - val_loss: 0.3784 - val_acc: 0.8729\n",
      "\n",
      "Epoch 00154: val_acc did not improve from 0.88828\n",
      "Epoch 155/200\n",
      "1083/1083 [==============================] - 19s 17ms/step - loss: 0.2886 - acc: 0.8857 - val_loss: 0.3444 - val_acc: 0.8850\n",
      "\n",
      "Epoch 00155: val_acc did not improve from 0.88828\n",
      "Epoch 156/200\n",
      "1083/1083 [==============================] - 19s 17ms/step - loss: 0.2833 - acc: 0.8879 - val_loss: 0.3427 - val_acc: 0.8838\n",
      "\n",
      "Epoch 00156: val_acc did not improve from 0.88828\n",
      "Epoch 157/200\n",
      "1083/1083 [==============================] - 19s 17ms/step - loss: 0.2854 - acc: 0.8876 - val_loss: 0.3460 - val_acc: 0.8826\n",
      "\n",
      "Epoch 00157: val_acc did not improve from 0.88828\n",
      "Epoch 158/200\n",
      "1083/1083 [==============================] - 19s 17ms/step - loss: 0.2859 - acc: 0.8865 - val_loss: 0.3719 - val_acc: 0.8760\n",
      "\n",
      "Epoch 00158: val_acc did not improve from 0.88828\n",
      "Epoch 159/200\n",
      "1083/1083 [==============================] - 19s 17ms/step - loss: 0.2813 - acc: 0.8892 - val_loss: 0.3564 - val_acc: 0.8800\n",
      "\n",
      "Epoch 00159: val_acc did not improve from 0.88828\n",
      "Epoch 160/200\n",
      "1083/1083 [==============================] - 19s 17ms/step - loss: 0.2816 - acc: 0.8898 - val_loss: 0.3441 - val_acc: 0.8839\n",
      "\n",
      "Epoch 00160: val_acc did not improve from 0.88828\n",
      "Epoch 161/200\n",
      "1083/1083 [==============================] - 19s 17ms/step - loss: 0.2840 - acc: 0.8882 - val_loss: 0.3410 - val_acc: 0.8848\n",
      "\n",
      "Epoch 00161: val_acc did not improve from 0.88828\n",
      "Epoch 162/200\n",
      "1083/1083 [==============================] - 19s 17ms/step - loss: 0.2783 - acc: 0.8903 - val_loss: 0.3418 - val_acc: 0.8824\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00162: val_acc did not improve from 0.88828\n",
      "Epoch 163/200\n",
      "1083/1083 [==============================] - 19s 17ms/step - loss: 0.2827 - acc: 0.8888 - val_loss: 0.3573 - val_acc: 0.8804\n",
      "\n",
      "Epoch 00163: val_acc did not improve from 0.88828\n",
      "Epoch 164/200\n",
      "1083/1083 [==============================] - 19s 17ms/step - loss: 0.2806 - acc: 0.8882 - val_loss: 0.3344 - val_acc: 0.8862\n",
      "\n",
      "Epoch 00164: val_acc did not improve from 0.88828\n",
      "Epoch 165/200\n",
      "1083/1083 [==============================] - 19s 17ms/step - loss: 0.2832 - acc: 0.8890 - val_loss: 0.3510 - val_acc: 0.8804\n",
      "\n",
      "Epoch 00165: val_acc did not improve from 0.88828\n",
      "Epoch 166/200\n",
      "1083/1083 [==============================] - 19s 17ms/step - loss: 0.2791 - acc: 0.8903 - val_loss: 0.3605 - val_acc: 0.8805\n",
      "\n",
      "Epoch 00166: val_acc did not improve from 0.88828\n",
      "Epoch 167/200\n",
      "1083/1083 [==============================] - 19s 17ms/step - loss: 0.2794 - acc: 0.8898 - val_loss: 0.3436 - val_acc: 0.8844\n",
      "\n",
      "Epoch 00167: val_acc did not improve from 0.88828\n",
      "Epoch 168/200\n",
      "1083/1083 [==============================] - 19s 17ms/step - loss: 0.2814 - acc: 0.8894 - val_loss: 0.3404 - val_acc: 0.8867\n",
      "\n",
      "Epoch 00168: val_acc did not improve from 0.88828\n",
      "Epoch 169/200\n",
      "1083/1083 [==============================] - 19s 17ms/step - loss: 0.2758 - acc: 0.8930 - val_loss: 0.3586 - val_acc: 0.8811\n",
      "\n",
      "Epoch 00169: val_acc did not improve from 0.88828\n",
      "Epoch 170/200\n",
      "1083/1083 [==============================] - 19s 17ms/step - loss: 0.2785 - acc: 0.8911 - val_loss: 0.3444 - val_acc: 0.8832\n",
      "\n",
      "Epoch 00170: val_acc did not improve from 0.88828\n",
      "Epoch 171/200\n",
      "1083/1083 [==============================] - 19s 17ms/step - loss: 0.2772 - acc: 0.8909 - val_loss: 0.3447 - val_acc: 0.8846\n",
      "\n",
      "Epoch 00171: val_acc did not improve from 0.88828\n",
      "Epoch 172/200\n",
      "1083/1083 [==============================] - 19s 17ms/step - loss: 0.2731 - acc: 0.8928 - val_loss: 0.3754 - val_acc: 0.8746\n",
      "\n",
      "Epoch 00172: val_acc did not improve from 0.88828\n",
      "Epoch 173/200\n",
      "1083/1083 [==============================] - 19s 17ms/step - loss: 0.2728 - acc: 0.8928 - val_loss: 0.3376 - val_acc: 0.8841\n",
      "\n",
      "Epoch 00173: val_acc did not improve from 0.88828\n",
      "Epoch 174/200\n",
      "1083/1083 [==============================] - 19s 17ms/step - loss: 0.2741 - acc: 0.8923 - val_loss: 0.3515 - val_acc: 0.8816\n",
      "\n",
      "Epoch 00174: val_acc did not improve from 0.88828\n",
      "Epoch 175/200\n",
      "1083/1083 [==============================] - 19s 17ms/step - loss: 0.2767 - acc: 0.8915 - val_loss: 0.3617 - val_acc: 0.8751\n",
      "\n",
      "Epoch 00175: val_acc did not improve from 0.88828\n",
      "Epoch 176/200\n",
      "1083/1083 [==============================] - 19s 17ms/step - loss: 0.2781 - acc: 0.8908 - val_loss: 0.3664 - val_acc: 0.8774\n",
      "\n",
      "Epoch 00176: val_acc did not improve from 0.88828\n",
      "Epoch 177/200\n",
      "1083/1083 [==============================] - 19s 17ms/step - loss: 0.2692 - acc: 0.8935 - val_loss: 0.3639 - val_acc: 0.8823\n",
      "\n",
      "Epoch 00177: val_acc did not improve from 0.88828\n",
      "Epoch 178/200\n",
      "1083/1083 [==============================] - 19s 17ms/step - loss: 0.2719 - acc: 0.8934 - val_loss: 0.3482 - val_acc: 0.8834\n",
      "\n",
      "Epoch 00178: val_acc did not improve from 0.88828\n",
      "Epoch 179/200\n",
      "1083/1083 [==============================] - 19s 17ms/step - loss: 0.2726 - acc: 0.8927 - val_loss: 0.3632 - val_acc: 0.8775\n",
      "\n",
      "Epoch 00179: val_acc did not improve from 0.88828\n",
      "Epoch 180/200\n",
      "1083/1083 [==============================] - 19s 17ms/step - loss: 0.2729 - acc: 0.8927 - val_loss: 0.3353 - val_acc: 0.8886\n",
      "\n",
      "Epoch 00180: val_acc improved from 0.88828 to 0.88857, saving model to best_model_f2.h5\n",
      "Epoch 181/200\n",
      "1083/1083 [==============================] - 19s 17ms/step - loss: 0.2708 - acc: 0.8943 - val_loss: 0.3445 - val_acc: 0.8841\n",
      "\n",
      "Epoch 00181: val_acc did not improve from 0.88857\n",
      "Epoch 182/200\n",
      "1083/1083 [==============================] - 19s 17ms/step - loss: 0.2724 - acc: 0.8925 - val_loss: 0.3540 - val_acc: 0.8779\n",
      "\n",
      "Epoch 00182: val_acc did not improve from 0.88857\n",
      "Epoch 183/200\n",
      "1083/1083 [==============================] - 19s 17ms/step - loss: 0.2680 - acc: 0.8938 - val_loss: 0.3541 - val_acc: 0.8847\n",
      "\n",
      "Epoch 00183: val_acc did not improve from 0.88857\n",
      "Epoch 184/200\n",
      "1083/1083 [==============================] - 19s 17ms/step - loss: 0.2698 - acc: 0.8945 - val_loss: 0.3583 - val_acc: 0.8809\n",
      "\n",
      "Epoch 00184: val_acc did not improve from 0.88857\n",
      "Epoch 185/200\n",
      "1083/1083 [==============================] - 19s 17ms/step - loss: 0.2677 - acc: 0.8948 - val_loss: 0.3583 - val_acc: 0.8801\n",
      "\n",
      "Epoch 00185: val_acc did not improve from 0.88857\n",
      "Epoch 186/200\n",
      "1083/1083 [==============================] - 19s 17ms/step - loss: 0.2691 - acc: 0.8950 - val_loss: 0.3651 - val_acc: 0.8800\n",
      "\n",
      "Epoch 00186: val_acc did not improve from 0.88857\n",
      "Epoch 187/200\n",
      "1083/1083 [==============================] - 19s 17ms/step - loss: 0.2738 - acc: 0.8920 - val_loss: 0.3357 - val_acc: 0.8872\n",
      "\n",
      "Epoch 00187: val_acc did not improve from 0.88857\n",
      "Epoch 188/200\n",
      "1083/1083 [==============================] - 19s 17ms/step - loss: 0.2647 - acc: 0.8956 - val_loss: 0.3719 - val_acc: 0.8781\n",
      "\n",
      "Epoch 00188: val_acc did not improve from 0.88857\n",
      "Epoch 189/200\n",
      "1083/1083 [==============================] - 19s 17ms/step - loss: 0.2688 - acc: 0.8936 - val_loss: 0.3564 - val_acc: 0.8820\n",
      "\n",
      "Epoch 00189: val_acc did not improve from 0.88857\n",
      "Epoch 190/200\n",
      "1083/1083 [==============================] - 19s 17ms/step - loss: 0.2680 - acc: 0.8942 - val_loss: 0.3553 - val_acc: 0.8820\n",
      "\n",
      "Epoch 00190: val_acc did not improve from 0.88857\n",
      "Epoch 191/200\n",
      "1083/1083 [==============================] - 19s 17ms/step - loss: 0.2679 - acc: 0.8944 - val_loss: 0.3559 - val_acc: 0.8805\n",
      "\n",
      "Epoch 00191: val_acc did not improve from 0.88857\n",
      "Epoch 192/200\n",
      "1083/1083 [==============================] - 19s 17ms/step - loss: 0.2661 - acc: 0.8947 - val_loss: 0.3435 - val_acc: 0.8850\n",
      "\n",
      "Epoch 00192: val_acc did not improve from 0.88857\n",
      "Epoch 193/200\n",
      "1083/1083 [==============================] - 19s 17ms/step - loss: 0.2695 - acc: 0.8949 - val_loss: 0.3540 - val_acc: 0.8806\n",
      "\n",
      "Epoch 00193: val_acc did not improve from 0.88857\n",
      "Epoch 194/200\n",
      "1083/1083 [==============================] - 19s 17ms/step - loss: 0.2650 - acc: 0.8970 - val_loss: 0.3335 - val_acc: 0.8889\n",
      "\n",
      "Epoch 00194: val_acc improved from 0.88857 to 0.88886, saving model to best_model_f2.h5\n",
      "Epoch 195/200\n",
      "1083/1083 [==============================] - 19s 17ms/step - loss: 0.2634 - acc: 0.8974 - val_loss: 0.3668 - val_acc: 0.8755\n",
      "\n",
      "Epoch 00195: val_acc did not improve from 0.88886\n",
      "Epoch 196/200\n",
      "1083/1083 [==============================] - 19s 17ms/step - loss: 0.2660 - acc: 0.8953 - val_loss: 0.3624 - val_acc: 0.8805\n",
      "\n",
      "Epoch 00196: val_acc did not improve from 0.88886\n",
      "Epoch 197/200\n",
      "1083/1083 [==============================] - 19s 17ms/step - loss: 0.2619 - acc: 0.8978 - val_loss: 0.3360 - val_acc: 0.8898\n",
      "\n",
      "Epoch 00197: val_acc improved from 0.88886 to 0.88978, saving model to best_model_f2.h5\n",
      "Epoch 198/200\n",
      "1083/1083 [==============================] - 19s 17ms/step - loss: 0.2634 - acc: 0.8962 - val_loss: 0.3499 - val_acc: 0.8829\n",
      "\n",
      "Epoch 00198: val_acc did not improve from 0.88978\n",
      "Epoch 199/200\n",
      "1083/1083 [==============================] - 19s 17ms/step - loss: 0.2614 - acc: 0.8974 - val_loss: 0.3869 - val_acc: 0.8718\n",
      "\n",
      "Epoch 00199: val_acc did not improve from 0.88978\n",
      "Epoch 200/200\n",
      "1083/1083 [==============================] - 19s 17ms/step - loss: 0.2648 - acc: 0.8969 - val_loss: 0.3487 - val_acc: 0.8829\n",
      "\n",
      "Epoch 00200: val_acc did not improve from 0.88978\n",
      "CPU times: user 5h 16min 47s, sys: 35min 10s, total: 5h 51min 57s\n",
      "Wall time: 1h 18min 38s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "mc2 = ModelCheckpoint('best_model_f2.h5', monitor='val_acc', mode='max', save_best_only=True,verbose=1)  \n",
    "history2 = model2.fit(X_train, y_train, batch_size=64, epochs=200, validation_split=0.2, verbose=1, callbacks=[mc2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "49f9dd18",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('history_f2.json', 'w') as f:\n",
    "    json.dump(history2.history, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "75c14eed",
   "metadata": {},
   "outputs": [],
   "source": [
    "model2.save('themodel_f2.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5929d035",
   "metadata": {},
   "source": [
    "## LSTM 3 Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "11543333",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_2 (Embedding)      (None, 30, 300)           31476300  \n",
      "_________________________________________________________________\n",
      "lstm_3 (LSTM)                (None, 30, 64)            93440     \n",
      "_________________________________________________________________\n",
      "lstm_4 (LSTM)                (None, 30, 64)            33024     \n",
      "_________________________________________________________________\n",
      "lstm_5 (LSTM)                (None, 30, 64)            33024     \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_2 (Glob (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 3)                 195       \n",
      "=================================================================\n",
      "Total params: 31,640,143\n",
      "Trainable params: 163,843\n",
      "Non-trainable params: 31,476,300\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model3=Sequential()\n",
    "model3.add(Embedding(size_of_vocabulary,embedding_dim,weights=[embedding_matrix],input_length=max_length,trainable=False))\n",
    "\n",
    "#Lstm layer\n",
    "model3.add(LSTM(UNITS,return_sequences=True,dropout=0.5))\n",
    "model3.add(LSTM(UNITS,return_sequences=True))\n",
    "model3.add(LSTM(UNITS,return_sequences=True))\n",
    "\n",
    "#Global Maxpooling\n",
    "model3.add(GlobalMaxPooling1D())\n",
    "\n",
    "#Dense Layer\n",
    "model3.add(Dense(UNITS, activation='relu'))\n",
    "\n",
    "#Output layer 3 class\n",
    "model3.add(Dense(3,activation='softmax')) \n",
    "\n",
    "model3.compile(optimizer=Adam(learning_rate = lr), loss = 'sparse_categorical_crossentropy', metrics = ['acc']) \n",
    "print(model3.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "5458db29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "1083/1083 [==============================] - 38s 33ms/step - loss: 0.8447 - acc: 0.6131 - val_loss: 0.7475 - val_acc: 0.6634\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.66339, saving model to best_model_f3.h5\n",
      "Epoch 2/200\n",
      "1083/1083 [==============================] - 35s 32ms/step - loss: 0.7884 - acc: 0.6423 - val_loss: 0.7227 - val_acc: 0.6802\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.66339 to 0.68020, saving model to best_model_f3.h5\n",
      "Epoch 3/200\n",
      "1083/1083 [==============================] - 35s 32ms/step - loss: 0.7614 - acc: 0.6579 - val_loss: 0.7127 - val_acc: 0.6903\n",
      "\n",
      "Epoch 00003: val_acc improved from 0.68020 to 0.69030, saving model to best_model_f3.h5\n",
      "Epoch 4/200\n",
      "1083/1083 [==============================] - 35s 32ms/step - loss: 0.7357 - acc: 0.6711 - val_loss: 0.6818 - val_acc: 0.7031\n",
      "\n",
      "Epoch 00004: val_acc improved from 0.69030 to 0.70306, saving model to best_model_f3.h5\n",
      "Epoch 5/200\n",
      "1083/1083 [==============================] - 35s 32ms/step - loss: 0.7196 - acc: 0.6788 - val_loss: 0.6704 - val_acc: 0.7137\n",
      "\n",
      "Epoch 00005: val_acc improved from 0.70306 to 0.71374, saving model to best_model_f3.h5\n",
      "Epoch 6/200\n",
      "1083/1083 [==============================] - 35s 32ms/step - loss: 0.7017 - acc: 0.6878 - val_loss: 0.6600 - val_acc: 0.7144\n",
      "\n",
      "Epoch 00006: val_acc improved from 0.71374 to 0.71438, saving model to best_model_f3.h5\n",
      "Epoch 7/200\n",
      "1083/1083 [==============================] - 35s 32ms/step - loss: 0.6844 - acc: 0.6979 - val_loss: 0.6433 - val_acc: 0.7267\n",
      "\n",
      "Epoch 00007: val_acc improved from 0.71438 to 0.72673, saving model to best_model_f3.h5\n",
      "Epoch 8/200\n",
      "1083/1083 [==============================] - 35s 32ms/step - loss: 0.6730 - acc: 0.7037 - val_loss: 0.6270 - val_acc: 0.7307\n",
      "\n",
      "Epoch 00008: val_acc improved from 0.72673 to 0.73066, saving model to best_model_f3.h5\n",
      "Epoch 9/200\n",
      "1083/1083 [==============================] - 35s 32ms/step - loss: 0.6555 - acc: 0.7133 - val_loss: 0.6116 - val_acc: 0.7374\n",
      "\n",
      "Epoch 00009: val_acc improved from 0.73066 to 0.73736, saving model to best_model_f3.h5\n",
      "Epoch 10/200\n",
      "1083/1083 [==============================] - 35s 32ms/step - loss: 0.6434 - acc: 0.7200 - val_loss: 0.6018 - val_acc: 0.7430\n",
      "\n",
      "Epoch 00010: val_acc improved from 0.73736 to 0.74301, saving model to best_model_f3.h5\n",
      "Epoch 11/200\n",
      "1083/1083 [==============================] - 35s 32ms/step - loss: 0.6292 - acc: 0.7256 - val_loss: 0.5856 - val_acc: 0.7535\n",
      "\n",
      "Epoch 00011: val_acc improved from 0.74301 to 0.75346, saving model to best_model_f3.h5\n",
      "Epoch 12/200\n",
      "1083/1083 [==============================] - 35s 32ms/step - loss: 0.6184 - acc: 0.7302 - val_loss: 0.5890 - val_acc: 0.7479\n",
      "\n",
      "Epoch 00012: val_acc did not improve from 0.75346\n",
      "Epoch 13/200\n",
      "1083/1083 [==============================] - 35s 32ms/step - loss: 0.6054 - acc: 0.7374 - val_loss: 0.5617 - val_acc: 0.7682\n",
      "\n",
      "Epoch 00013: val_acc improved from 0.75346 to 0.76819, saving model to best_model_f3.h5\n",
      "Epoch 14/200\n",
      "1083/1083 [==============================] - 35s 32ms/step - loss: 0.5958 - acc: 0.7427 - val_loss: 0.5593 - val_acc: 0.7679\n",
      "\n",
      "Epoch 00014: val_acc did not improve from 0.76819\n",
      "Epoch 15/200\n",
      "1083/1083 [==============================] - 35s 32ms/step - loss: 0.5827 - acc: 0.7494 - val_loss: 0.5437 - val_acc: 0.7703\n",
      "\n",
      "Epoch 00015: val_acc improved from 0.76819 to 0.77027, saving model to best_model_f3.h5\n",
      "Epoch 16/200\n",
      "1083/1083 [==============================] - 35s 32ms/step - loss: 0.5758 - acc: 0.7549 - val_loss: 0.5339 - val_acc: 0.7753\n",
      "\n",
      "Epoch 00016: val_acc improved from 0.77027 to 0.77529, saving model to best_model_f3.h5\n",
      "Epoch 17/200\n",
      "1083/1083 [==============================] - 35s 32ms/step - loss: 0.5652 - acc: 0.7592 - val_loss: 0.5284 - val_acc: 0.7812\n",
      "\n",
      "Epoch 00017: val_acc improved from 0.77529 to 0.78118, saving model to best_model_f3.h5\n",
      "Epoch 18/200\n",
      "1083/1083 [==============================] - 35s 32ms/step - loss: 0.5573 - acc: 0.7628 - val_loss: 0.5141 - val_acc: 0.7859\n",
      "\n",
      "Epoch 00018: val_acc improved from 0.78118 to 0.78591, saving model to best_model_f3.h5\n",
      "Epoch 19/200\n",
      "1083/1083 [==============================] - 35s 32ms/step - loss: 0.5474 - acc: 0.7677 - val_loss: 0.5151 - val_acc: 0.7876\n",
      "\n",
      "Epoch 00019: val_acc improved from 0.78591 to 0.78759, saving model to best_model_f3.h5\n",
      "Epoch 20/200\n",
      "1083/1083 [==============================] - 35s 32ms/step - loss: 0.5385 - acc: 0.7722 - val_loss: 0.5078 - val_acc: 0.7937\n",
      "\n",
      "Epoch 00020: val_acc improved from 0.78759 to 0.79371, saving model to best_model_f3.h5\n",
      "Epoch 21/200\n",
      "1083/1083 [==============================] - 35s 32ms/step - loss: 0.5296 - acc: 0.7768 - val_loss: 0.4956 - val_acc: 0.7957\n",
      "\n",
      "Epoch 00021: val_acc improved from 0.79371 to 0.79573, saving model to best_model_f3.h5\n",
      "Epoch 22/200\n",
      "1083/1083 [==============================] - 35s 32ms/step - loss: 0.5235 - acc: 0.7807 - val_loss: 0.5139 - val_acc: 0.7872\n",
      "\n",
      "Epoch 00022: val_acc did not improve from 0.79573\n",
      "Epoch 23/200\n",
      "1083/1083 [==============================] - 35s 32ms/step - loss: 0.5153 - acc: 0.7850 - val_loss: 0.4815 - val_acc: 0.8038\n",
      "\n",
      "Epoch 00023: val_acc improved from 0.79573 to 0.80381, saving model to best_model_f3.h5\n",
      "Epoch 24/200\n",
      "1083/1083 [==============================] - 35s 32ms/step - loss: 0.5089 - acc: 0.7870 - val_loss: 0.4787 - val_acc: 0.8059\n",
      "\n",
      "Epoch 00024: val_acc improved from 0.80381 to 0.80589, saving model to best_model_f3.h5\n",
      "Epoch 25/200\n",
      "1083/1083 [==============================] - 35s 32ms/step - loss: 0.5034 - acc: 0.7904 - val_loss: 0.4756 - val_acc: 0.8074\n",
      "\n",
      "Epoch 00025: val_acc improved from 0.80589 to 0.80745, saving model to best_model_f3.h5\n",
      "Epoch 26/200\n",
      "1083/1083 [==============================] - 35s 32ms/step - loss: 0.4983 - acc: 0.7925 - val_loss: 0.4685 - val_acc: 0.8106\n",
      "\n",
      "Epoch 00026: val_acc improved from 0.80745 to 0.81062, saving model to best_model_f3.h5\n",
      "Epoch 27/200\n",
      "1083/1083 [==============================] - 35s 32ms/step - loss: 0.4941 - acc: 0.7943 - val_loss: 0.4686 - val_acc: 0.8128\n",
      "\n",
      "Epoch 00027: val_acc improved from 0.81062 to 0.81282, saving model to best_model_f3.h5\n",
      "Epoch 28/200\n",
      "1083/1083 [==============================] - 35s 32ms/step - loss: 0.4864 - acc: 0.7978 - val_loss: 0.4527 - val_acc: 0.8206\n",
      "\n",
      "Epoch 00028: val_acc improved from 0.81282 to 0.82061, saving model to best_model_f3.h5\n",
      "Epoch 29/200\n",
      "1083/1083 [==============================] - 35s 32ms/step - loss: 0.4788 - acc: 0.8021 - val_loss: 0.4555 - val_acc: 0.8173\n",
      "\n",
      "Epoch 00029: val_acc did not improve from 0.82061\n",
      "Epoch 30/200\n",
      "1083/1083 [==============================] - 35s 32ms/step - loss: 0.4733 - acc: 0.8037 - val_loss: 0.4525 - val_acc: 0.8201\n",
      "\n",
      "Epoch 00030: val_acc did not improve from 0.82061\n",
      "Epoch 31/200\n",
      "1083/1083 [==============================] - 35s 32ms/step - loss: 0.4696 - acc: 0.8051 - val_loss: 0.4449 - val_acc: 0.8229\n",
      "\n",
      "Epoch 00031: val_acc improved from 0.82061 to 0.82292, saving model to best_model_f3.h5\n",
      "Epoch 32/200\n",
      "1083/1083 [==============================] - 35s 32ms/step - loss: 0.4675 - acc: 0.8062 - val_loss: 0.4403 - val_acc: 0.8222\n",
      "\n",
      "Epoch 00032: val_acc did not improve from 0.82292\n",
      "Epoch 33/200\n",
      "1083/1083 [==============================] - 35s 32ms/step - loss: 0.4589 - acc: 0.8096 - val_loss: 0.4328 - val_acc: 0.8277\n",
      "\n",
      "Epoch 00033: val_acc improved from 0.82292 to 0.82766, saving model to best_model_f3.h5\n",
      "Epoch 34/200\n",
      "1083/1083 [==============================] - 35s 32ms/step - loss: 0.4610 - acc: 0.8091 - val_loss: 0.4284 - val_acc: 0.8309\n",
      "\n",
      "Epoch 00034: val_acc improved from 0.82766 to 0.83095, saving model to best_model_f3.h5\n",
      "Epoch 35/200\n",
      "1083/1083 [==============================] - 35s 32ms/step - loss: 0.4502 - acc: 0.8146 - val_loss: 0.4365 - val_acc: 0.8287\n",
      "\n",
      "Epoch 00035: val_acc did not improve from 0.83095\n",
      "Epoch 36/200\n",
      "1083/1083 [==============================] - 35s 32ms/step - loss: 0.4462 - acc: 0.8177 - val_loss: 0.4297 - val_acc: 0.8290\n",
      "\n",
      "Epoch 00036: val_acc did not improve from 0.83095\n",
      "Epoch 37/200\n",
      "1083/1083 [==============================] - 35s 32ms/step - loss: 0.4409 - acc: 0.8174 - val_loss: 0.4226 - val_acc: 0.8345\n",
      "\n",
      "Epoch 00037: val_acc improved from 0.83095 to 0.83453, saving model to best_model_f3.h5\n",
      "Epoch 38/200\n",
      "1083/1083 [==============================] - 35s 32ms/step - loss: 0.4344 - acc: 0.8211 - val_loss: 0.4202 - val_acc: 0.8363\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00038: val_acc improved from 0.83453 to 0.83632, saving model to best_model_f3.h5\n",
      "Epoch 39/200\n",
      "1083/1083 [==============================] - 35s 32ms/step - loss: 0.4362 - acc: 0.8221 - val_loss: 0.4173 - val_acc: 0.8330\n",
      "\n",
      "Epoch 00039: val_acc did not improve from 0.83632\n",
      "Epoch 40/200\n",
      "1083/1083 [==============================] - 35s 32ms/step - loss: 0.4286 - acc: 0.8246 - val_loss: 0.4095 - val_acc: 0.8402\n",
      "\n",
      "Epoch 00040: val_acc improved from 0.83632 to 0.84024, saving model to best_model_f3.h5\n",
      "Epoch 41/200\n",
      "1083/1083 [==============================] - 35s 32ms/step - loss: 0.4235 - acc: 0.8270 - val_loss: 0.4121 - val_acc: 0.8404\n",
      "\n",
      "Epoch 00041: val_acc improved from 0.84024 to 0.84036, saving model to best_model_f3.h5\n",
      "Epoch 42/200\n",
      "1083/1083 [==============================] - 35s 32ms/step - loss: 0.4226 - acc: 0.8250 - val_loss: 0.4125 - val_acc: 0.8408\n",
      "\n",
      "Epoch 00042: val_acc improved from 0.84036 to 0.84076, saving model to best_model_f3.h5\n",
      "Epoch 43/200\n",
      "1083/1083 [==============================] - 35s 32ms/step - loss: 0.4192 - acc: 0.8305 - val_loss: 0.4071 - val_acc: 0.8427\n",
      "\n",
      "Epoch 00043: val_acc improved from 0.84076 to 0.84267, saving model to best_model_f3.h5\n",
      "Epoch 44/200\n",
      "1083/1083 [==============================] - 35s 32ms/step - loss: 0.4178 - acc: 0.8308 - val_loss: 0.3973 - val_acc: 0.8468\n",
      "\n",
      "Epoch 00044: val_acc improved from 0.84267 to 0.84677, saving model to best_model_f3.h5\n",
      "Epoch 45/200\n",
      "1083/1083 [==============================] - 35s 32ms/step - loss: 0.4126 - acc: 0.8315 - val_loss: 0.4041 - val_acc: 0.8417\n",
      "\n",
      "Epoch 00045: val_acc did not improve from 0.84677\n",
      "Epoch 46/200\n",
      "1083/1083 [==============================] - 35s 32ms/step - loss: 0.4109 - acc: 0.8315 - val_loss: 0.3996 - val_acc: 0.8464\n",
      "\n",
      "Epoch 00046: val_acc did not improve from 0.84677\n",
      "Epoch 47/200\n",
      "1083/1083 [==============================] - 35s 32ms/step - loss: 0.4061 - acc: 0.8352 - val_loss: 0.3961 - val_acc: 0.8453\n",
      "\n",
      "Epoch 00047: val_acc did not improve from 0.84677\n",
      "Epoch 48/200\n",
      "1083/1083 [==============================] - 35s 32ms/step - loss: 0.4040 - acc: 0.8337 - val_loss: 0.3899 - val_acc: 0.8500\n",
      "\n",
      "Epoch 00048: val_acc improved from 0.84677 to 0.85000, saving model to best_model_f3.h5\n",
      "Epoch 49/200\n",
      "1083/1083 [==============================] - 35s 32ms/step - loss: 0.4009 - acc: 0.8371 - val_loss: 0.3977 - val_acc: 0.8474\n",
      "\n",
      "Epoch 00049: val_acc did not improve from 0.85000\n",
      "Epoch 50/200\n",
      "1083/1083 [==============================] - 35s 32ms/step - loss: 0.3965 - acc: 0.8390 - val_loss: 0.3966 - val_acc: 0.8469\n",
      "\n",
      "Epoch 00050: val_acc did not improve from 0.85000\n",
      "Epoch 51/200\n",
      "1083/1083 [==============================] - 35s 32ms/step - loss: 0.3950 - acc: 0.8402 - val_loss: 0.3813 - val_acc: 0.8549\n",
      "\n",
      "Epoch 00051: val_acc improved from 0.85000 to 0.85491, saving model to best_model_f3.h5\n",
      "Epoch 52/200\n",
      "1083/1083 [==============================] - 35s 32ms/step - loss: 0.3935 - acc: 0.8381 - val_loss: 0.3996 - val_acc: 0.8475\n",
      "\n",
      "Epoch 00052: val_acc did not improve from 0.85491\n",
      "Epoch 53/200\n",
      "1083/1083 [==============================] - 35s 32ms/step - loss: 0.3889 - acc: 0.8413 - val_loss: 0.3794 - val_acc: 0.8577\n",
      "\n",
      "Epoch 00053: val_acc improved from 0.85491 to 0.85774, saving model to best_model_f3.h5\n",
      "Epoch 54/200\n",
      "1083/1083 [==============================] - 35s 33ms/step - loss: 0.3862 - acc: 0.8426 - val_loss: 0.3797 - val_acc: 0.8555\n",
      "\n",
      "Epoch 00054: val_acc did not improve from 0.85774\n",
      "Epoch 55/200\n",
      "1083/1083 [==============================] - 35s 32ms/step - loss: 0.3844 - acc: 0.8440 - val_loss: 0.3785 - val_acc: 0.8580\n",
      "\n",
      "Epoch 00055: val_acc improved from 0.85774 to 0.85803, saving model to best_model_f3.h5\n",
      "Epoch 56/200\n",
      "1083/1083 [==============================] - 35s 32ms/step - loss: 0.3814 - acc: 0.8469 - val_loss: 0.3852 - val_acc: 0.8553\n",
      "\n",
      "Epoch 00056: val_acc did not improve from 0.85803\n",
      "Epoch 57/200\n",
      "1083/1083 [==============================] - 35s 32ms/step - loss: 0.3781 - acc: 0.8462 - val_loss: 0.3732 - val_acc: 0.8594\n",
      "\n",
      "Epoch 00057: val_acc improved from 0.85803 to 0.85935, saving model to best_model_f3.h5\n",
      "Epoch 58/200\n",
      "1083/1083 [==============================] - 35s 32ms/step - loss: 0.3751 - acc: 0.8478 - val_loss: 0.3836 - val_acc: 0.8532\n",
      "\n",
      "Epoch 00058: val_acc did not improve from 0.85935\n",
      "Epoch 59/200\n",
      "1083/1083 [==============================] - 35s 32ms/step - loss: 0.3736 - acc: 0.8483 - val_loss: 0.3845 - val_acc: 0.8570\n",
      "\n",
      "Epoch 00059: val_acc did not improve from 0.85935\n",
      "Epoch 60/200\n",
      "1083/1083 [==============================] - 35s 33ms/step - loss: 0.3714 - acc: 0.8505 - val_loss: 0.3784 - val_acc: 0.8579\n",
      "\n",
      "Epoch 00060: val_acc did not improve from 0.85935\n",
      "Epoch 61/200\n",
      "1083/1083 [==============================] - 35s 32ms/step - loss: 0.3682 - acc: 0.8517 - val_loss: 0.3673 - val_acc: 0.8626\n",
      "\n",
      "Epoch 00061: val_acc improved from 0.85935 to 0.86259, saving model to best_model_f3.h5\n",
      "Epoch 62/200\n",
      "1083/1083 [==============================] - 35s 32ms/step - loss: 0.3643 - acc: 0.8511 - val_loss: 0.3740 - val_acc: 0.8588\n",
      "\n",
      "Epoch 00062: val_acc did not improve from 0.86259\n",
      "Epoch 63/200\n",
      "1083/1083 [==============================] - 35s 32ms/step - loss: 0.3653 - acc: 0.8520 - val_loss: 0.3743 - val_acc: 0.8607\n",
      "\n",
      "Epoch 00063: val_acc did not improve from 0.86259\n",
      "Epoch 64/200\n",
      "1083/1083 [==============================] - 35s 32ms/step - loss: 0.3626 - acc: 0.8543 - val_loss: 0.3868 - val_acc: 0.8557\n",
      "\n",
      "Epoch 00064: val_acc did not improve from 0.86259\n",
      "Epoch 65/200\n",
      "1083/1083 [==============================] - 35s 32ms/step - loss: 0.3624 - acc: 0.8533 - val_loss: 0.3636 - val_acc: 0.8648\n",
      "\n",
      "Epoch 00065: val_acc improved from 0.86259 to 0.86478, saving model to best_model_f3.h5\n",
      "Epoch 66/200\n",
      "1083/1083 [==============================] - 35s 33ms/step - loss: 0.3549 - acc: 0.8569 - val_loss: 0.3633 - val_acc: 0.8657\n",
      "\n",
      "Epoch 00066: val_acc improved from 0.86478 to 0.86570, saving model to best_model_f3.h5\n",
      "Epoch 67/200\n",
      "1083/1083 [==============================] - 35s 32ms/step - loss: 0.3550 - acc: 0.8559 - val_loss: 0.3571 - val_acc: 0.8675\n",
      "\n",
      "Epoch 00067: val_acc improved from 0.86570 to 0.86749, saving model to best_model_f3.h5\n",
      "Epoch 68/200\n",
      "1083/1083 [==============================] - 35s 32ms/step - loss: 0.3505 - acc: 0.8591 - val_loss: 0.3577 - val_acc: 0.8674\n",
      "\n",
      "Epoch 00068: val_acc did not improve from 0.86749\n",
      "Epoch 69/200\n",
      "1083/1083 [==============================] - 35s 32ms/step - loss: 0.3512 - acc: 0.8566 - val_loss: 0.3602 - val_acc: 0.8651\n",
      "\n",
      "Epoch 00069: val_acc did not improve from 0.86749\n",
      "Epoch 70/200\n",
      "1083/1083 [==============================] - 35s 32ms/step - loss: 0.3508 - acc: 0.8599 - val_loss: 0.3678 - val_acc: 0.8626\n",
      "\n",
      "Epoch 00070: val_acc did not improve from 0.86749\n",
      "Epoch 71/200\n",
      "1083/1083 [==============================] - 35s 32ms/step - loss: 0.3468 - acc: 0.8602 - val_loss: 0.3712 - val_acc: 0.8631\n",
      "\n",
      "Epoch 00071: val_acc did not improve from 0.86749\n",
      "Epoch 72/200\n",
      "1083/1083 [==============================] - 35s 32ms/step - loss: 0.3434 - acc: 0.8622 - val_loss: 0.3650 - val_acc: 0.8672\n",
      "\n",
      "Epoch 00072: val_acc did not improve from 0.86749\n",
      "Epoch 73/200\n",
      "1083/1083 [==============================] - 35s 32ms/step - loss: 0.3437 - acc: 0.8616 - val_loss: 0.3509 - val_acc: 0.8724\n",
      "\n",
      "Epoch 00073: val_acc improved from 0.86749 to 0.87240, saving model to best_model_f3.h5\n",
      "Epoch 74/200\n",
      "1083/1083 [==============================] - 35s 32ms/step - loss: 0.3402 - acc: 0.8626 - val_loss: 0.3805 - val_acc: 0.8582\n",
      "\n",
      "Epoch 00074: val_acc did not improve from 0.87240\n",
      "Epoch 75/200\n",
      "1083/1083 [==============================] - 35s 32ms/step - loss: 0.3384 - acc: 0.8647 - val_loss: 0.3671 - val_acc: 0.8655\n",
      "\n",
      "Epoch 00075: val_acc did not improve from 0.87240\n",
      "Epoch 76/200\n",
      "1083/1083 [==============================] - 35s 32ms/step - loss: 0.3366 - acc: 0.8650 - val_loss: 0.3532 - val_acc: 0.8715\n",
      "\n",
      "Epoch 00076: val_acc did not improve from 0.87240\n",
      "Epoch 77/200\n",
      "1083/1083 [==============================] - 35s 32ms/step - loss: 0.3348 - acc: 0.8671 - val_loss: 0.3625 - val_acc: 0.8690\n",
      "\n",
      "Epoch 00077: val_acc did not improve from 0.87240\n",
      "Epoch 78/200\n",
      "1083/1083 [==============================] - 35s 32ms/step - loss: 0.3338 - acc: 0.8678 - val_loss: 0.3548 - val_acc: 0.8718\n",
      "\n",
      "Epoch 00078: val_acc did not improve from 0.87240\n",
      "Epoch 79/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1083/1083 [==============================] - 35s 32ms/step - loss: 0.3267 - acc: 0.8684 - val_loss: 0.3652 - val_acc: 0.8692\n",
      "\n",
      "Epoch 00079: val_acc did not improve from 0.87240\n",
      "Epoch 80/200\n",
      "1083/1083 [==============================] - 35s 32ms/step - loss: 0.3279 - acc: 0.8697 - val_loss: 0.3552 - val_acc: 0.8717\n",
      "\n",
      "Epoch 00080: val_acc did not improve from 0.87240\n",
      "Epoch 81/200\n",
      "1083/1083 [==============================] - 35s 32ms/step - loss: 0.3266 - acc: 0.8705 - val_loss: 0.3631 - val_acc: 0.8688\n",
      "\n",
      "Epoch 00081: val_acc did not improve from 0.87240\n",
      "Epoch 82/200\n",
      "1083/1083 [==============================] - 35s 32ms/step - loss: 0.3251 - acc: 0.8713 - val_loss: 0.3604 - val_acc: 0.8706\n",
      "\n",
      "Epoch 00082: val_acc did not improve from 0.87240\n",
      "Epoch 83/200\n",
      "1083/1083 [==============================] - 35s 32ms/step - loss: 0.3266 - acc: 0.8693 - val_loss: 0.3461 - val_acc: 0.8745\n",
      "\n",
      "Epoch 00083: val_acc improved from 0.87240 to 0.87454, saving model to best_model_f3.h5\n",
      "Epoch 84/200\n",
      "1083/1083 [==============================] - 35s 32ms/step - loss: 0.3202 - acc: 0.8712 - val_loss: 0.3590 - val_acc: 0.8721\n",
      "\n",
      "Epoch 00084: val_acc did not improve from 0.87454\n",
      "Epoch 85/200\n",
      "1083/1083 [==============================] - 35s 32ms/step - loss: 0.3231 - acc: 0.8711 - val_loss: 0.3536 - val_acc: 0.8727\n",
      "\n",
      "Epoch 00085: val_acc did not improve from 0.87454\n",
      "Epoch 86/200\n",
      "1083/1083 [==============================] - 35s 32ms/step - loss: 0.3197 - acc: 0.8728 - val_loss: 0.3443 - val_acc: 0.8751\n",
      "\n",
      "Epoch 00086: val_acc improved from 0.87454 to 0.87506, saving model to best_model_f3.h5\n",
      "Epoch 87/200\n",
      "1083/1083 [==============================] - 35s 32ms/step - loss: 0.3170 - acc: 0.8729 - val_loss: 0.3517 - val_acc: 0.8740\n",
      "\n",
      "Epoch 00087: val_acc did not improve from 0.87506\n",
      "Epoch 88/200\n",
      "1083/1083 [==============================] - 35s 32ms/step - loss: 0.3181 - acc: 0.8730 - val_loss: 0.3378 - val_acc: 0.8780\n",
      "\n",
      "Epoch 00088: val_acc improved from 0.87506 to 0.87800, saving model to best_model_f3.h5\n",
      "Epoch 89/200\n",
      "1083/1083 [==============================] - 35s 32ms/step - loss: 0.3126 - acc: 0.8762 - val_loss: 0.3455 - val_acc: 0.8761\n",
      "\n",
      "Epoch 00089: val_acc did not improve from 0.87800\n",
      "Epoch 90/200\n",
      "1083/1083 [==============================] - 35s 32ms/step - loss: 0.3125 - acc: 0.8743 - val_loss: 0.3412 - val_acc: 0.8793\n",
      "\n",
      "Epoch 00090: val_acc improved from 0.87800 to 0.87933, saving model to best_model_f3.h5\n",
      "Epoch 91/200\n",
      "1083/1083 [==============================] - 35s 32ms/step - loss: 0.3114 - acc: 0.8758 - val_loss: 0.3456 - val_acc: 0.8792\n",
      "\n",
      "Epoch 00091: val_acc did not improve from 0.87933\n",
      "Epoch 92/200\n",
      "1083/1083 [==============================] - 35s 32ms/step - loss: 0.3082 - acc: 0.8774 - val_loss: 0.3486 - val_acc: 0.8766\n",
      "\n",
      "Epoch 00092: val_acc did not improve from 0.87933\n",
      "Epoch 93/200\n",
      "1083/1083 [==============================] - 35s 32ms/step - loss: 0.3113 - acc: 0.8751 - val_loss: 0.3441 - val_acc: 0.8781\n",
      "\n",
      "Epoch 00093: val_acc did not improve from 0.87933\n",
      "Epoch 94/200\n",
      "1083/1083 [==============================] - 35s 32ms/step - loss: 0.3070 - acc: 0.8774 - val_loss: 0.3373 - val_acc: 0.8797\n",
      "\n",
      "Epoch 00094: val_acc improved from 0.87933 to 0.87968, saving model to best_model_f3.h5\n",
      "Epoch 95/200\n",
      "1083/1083 [==============================] - 35s 32ms/step - loss: 0.3063 - acc: 0.8783 - val_loss: 0.3448 - val_acc: 0.8777\n",
      "\n",
      "Epoch 00095: val_acc did not improve from 0.87968\n",
      "Epoch 96/200\n",
      "1083/1083 [==============================] - 35s 32ms/step - loss: 0.3069 - acc: 0.8773 - val_loss: 0.3435 - val_acc: 0.8789\n",
      "\n",
      "Epoch 00096: val_acc did not improve from 0.87968\n",
      "Epoch 97/200\n",
      "1083/1083 [==============================] - 35s 32ms/step - loss: 0.3049 - acc: 0.8796 - val_loss: 0.3412 - val_acc: 0.8771\n",
      "\n",
      "Epoch 00097: val_acc did not improve from 0.87968\n",
      "Epoch 98/200\n",
      "1083/1083 [==============================] - 35s 32ms/step - loss: 0.3036 - acc: 0.8786 - val_loss: 0.3455 - val_acc: 0.8799\n",
      "\n",
      "Epoch 00098: val_acc improved from 0.87968 to 0.87991, saving model to best_model_f3.h5\n",
      "Epoch 99/200\n",
      "1083/1083 [==============================] - 35s 32ms/step - loss: 0.3016 - acc: 0.8796 - val_loss: 0.3296 - val_acc: 0.8867\n",
      "\n",
      "Epoch 00099: val_acc improved from 0.87991 to 0.88666, saving model to best_model_f3.h5\n",
      "Epoch 100/200\n",
      "1083/1083 [==============================] - 35s 32ms/step - loss: 0.3005 - acc: 0.8807 - val_loss: 0.3607 - val_acc: 0.8762\n",
      "\n",
      "Epoch 00100: val_acc did not improve from 0.88666\n",
      "Epoch 101/200\n",
      "1083/1083 [==============================] - 35s 32ms/step - loss: 0.3009 - acc: 0.8807 - val_loss: 0.3354 - val_acc: 0.8827\n",
      "\n",
      "Epoch 00101: val_acc did not improve from 0.88666\n",
      "Epoch 102/200\n",
      "1083/1083 [==============================] - 35s 32ms/step - loss: 0.2981 - acc: 0.8828 - val_loss: 0.3388 - val_acc: 0.8809\n",
      "\n",
      "Epoch 00102: val_acc did not improve from 0.88666\n",
      "Epoch 103/200\n",
      "1083/1083 [==============================] - 35s 32ms/step - loss: 0.2943 - acc: 0.8838 - val_loss: 0.3364 - val_acc: 0.8818\n",
      "\n",
      "Epoch 00103: val_acc did not improve from 0.88666\n",
      "Epoch 104/200\n",
      "1083/1083 [==============================] - 35s 32ms/step - loss: 0.2941 - acc: 0.8830 - val_loss: 0.3470 - val_acc: 0.8776\n",
      "\n",
      "Epoch 00104: val_acc did not improve from 0.88666\n",
      "Epoch 105/200\n",
      "1083/1083 [==============================] - 35s 32ms/step - loss: 0.2919 - acc: 0.8845 - val_loss: 0.3417 - val_acc: 0.8804\n",
      "\n",
      "Epoch 00105: val_acc did not improve from 0.88666\n",
      "Epoch 106/200\n",
      "1083/1083 [==============================] - 35s 32ms/step - loss: 0.2960 - acc: 0.8833 - val_loss: 0.3279 - val_acc: 0.8855\n",
      "\n",
      "Epoch 00106: val_acc did not improve from 0.88666\n",
      "Epoch 107/200\n",
      "1083/1083 [==============================] - 35s 32ms/step - loss: 0.2923 - acc: 0.8832 - val_loss: 0.3451 - val_acc: 0.8806\n",
      "\n",
      "Epoch 00107: val_acc did not improve from 0.88666\n",
      "Epoch 108/200\n",
      "1083/1083 [==============================] - 35s 32ms/step - loss: 0.2927 - acc: 0.8847 - val_loss: 0.3299 - val_acc: 0.8886\n",
      "\n",
      "Epoch 00108: val_acc improved from 0.88666 to 0.88857, saving model to best_model_f3.h5\n",
      "Epoch 109/200\n",
      "1083/1083 [==============================] - 35s 32ms/step - loss: 0.2900 - acc: 0.8859 - val_loss: 0.3573 - val_acc: 0.8785\n",
      "\n",
      "Epoch 00109: val_acc did not improve from 0.88857\n",
      "Epoch 110/200\n",
      "1083/1083 [==============================] - 35s 32ms/step - loss: 0.2880 - acc: 0.8864 - val_loss: 0.3500 - val_acc: 0.8793\n",
      "\n",
      "Epoch 00110: val_acc did not improve from 0.88857\n",
      "Epoch 111/200\n",
      "1083/1083 [==============================] - 35s 32ms/step - loss: 0.2842 - acc: 0.8879 - val_loss: 0.3340 - val_acc: 0.8857\n",
      "\n",
      "Epoch 00111: val_acc did not improve from 0.88857\n",
      "Epoch 112/200\n",
      "1083/1083 [==============================] - 35s 32ms/step - loss: 0.2864 - acc: 0.8856 - val_loss: 0.3293 - val_acc: 0.8880\n",
      "\n",
      "Epoch 00112: val_acc did not improve from 0.88857\n",
      "Epoch 113/200\n",
      "1083/1083 [==============================] - 35s 32ms/step - loss: 0.2813 - acc: 0.8902 - val_loss: 0.3438 - val_acc: 0.8826\n",
      "\n",
      "Epoch 00113: val_acc did not improve from 0.88857\n",
      "Epoch 114/200\n",
      "1083/1083 [==============================] - 35s 32ms/step - loss: 0.2824 - acc: 0.8880 - val_loss: 0.3424 - val_acc: 0.8823\n",
      "\n",
      "Epoch 00114: val_acc did not improve from 0.88857\n",
      "Epoch 115/200\n",
      "1083/1083 [==============================] - 35s 32ms/step - loss: 0.2806 - acc: 0.8891 - val_loss: 0.3350 - val_acc: 0.8845\n",
      "\n",
      "Epoch 00115: val_acc did not improve from 0.88857\n",
      "Epoch 116/200\n",
      "1083/1083 [==============================] - 35s 32ms/step - loss: 0.2794 - acc: 0.8889 - val_loss: 0.3384 - val_acc: 0.8847\n",
      "\n",
      "Epoch 00116: val_acc did not improve from 0.88857\n",
      "Epoch 117/200\n",
      "1083/1083 [==============================] - 35s 32ms/step - loss: 0.2808 - acc: 0.8895 - val_loss: 0.3429 - val_acc: 0.8845\n",
      "\n",
      "Epoch 00117: val_acc did not improve from 0.88857\n",
      "Epoch 118/200\n",
      "1083/1083 [==============================] - 35s 32ms/step - loss: 0.2785 - acc: 0.8906 - val_loss: 0.3370 - val_acc: 0.8870\n",
      "\n",
      "Epoch 00118: val_acc did not improve from 0.88857\n",
      "Epoch 119/200\n",
      "1083/1083 [==============================] - 35s 32ms/step - loss: 0.2761 - acc: 0.8902 - val_loss: 0.3524 - val_acc: 0.8798\n",
      "\n",
      "Epoch 00119: val_acc did not improve from 0.88857\n",
      "Epoch 120/200\n",
      "1083/1083 [==============================] - 35s 32ms/step - loss: 0.2775 - acc: 0.8908 - val_loss: 0.3454 - val_acc: 0.8830\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00120: val_acc did not improve from 0.88857\n",
      "Epoch 121/200\n",
      "1083/1083 [==============================] - 35s 32ms/step - loss: 0.2711 - acc: 0.8930 - val_loss: 0.3447 - val_acc: 0.8841\n",
      "\n",
      "Epoch 00121: val_acc did not improve from 0.88857\n",
      "Epoch 122/200\n",
      "1083/1083 [==============================] - 35s 32ms/step - loss: 0.2719 - acc: 0.8934 - val_loss: 0.3352 - val_acc: 0.8909\n",
      "\n",
      "Epoch 00122: val_acc improved from 0.88857 to 0.89088, saving model to best_model_f3.h5\n",
      "Epoch 123/200\n",
      "1083/1083 [==============================] - 35s 32ms/step - loss: 0.2709 - acc: 0.8934 - val_loss: 0.3414 - val_acc: 0.8839\n",
      "\n",
      "Epoch 00123: val_acc did not improve from 0.89088\n",
      "Epoch 124/200\n",
      "1083/1083 [==============================] - 35s 32ms/step - loss: 0.2719 - acc: 0.8931 - val_loss: 0.3460 - val_acc: 0.8831\n",
      "\n",
      "Epoch 00124: val_acc did not improve from 0.89088\n",
      "Epoch 125/200\n",
      "1083/1083 [==============================] - 35s 32ms/step - loss: 0.2665 - acc: 0.8953 - val_loss: 0.3371 - val_acc: 0.8865\n",
      "\n",
      "Epoch 00125: val_acc did not improve from 0.89088\n",
      "Epoch 126/200\n",
      "1083/1083 [==============================] - 35s 32ms/step - loss: 0.2667 - acc: 0.8948 - val_loss: 0.3483 - val_acc: 0.8829\n",
      "\n",
      "Epoch 00126: val_acc did not improve from 0.89088\n",
      "Epoch 127/200\n",
      "1083/1083 [==============================] - 35s 32ms/step - loss: 0.2717 - acc: 0.8937 - val_loss: 0.3502 - val_acc: 0.8844\n",
      "\n",
      "Epoch 00127: val_acc did not improve from 0.89088\n",
      "Epoch 128/200\n",
      "1083/1083 [==============================] - 35s 32ms/step - loss: 0.2669 - acc: 0.8949 - val_loss: 0.3463 - val_acc: 0.8845\n",
      "\n",
      "Epoch 00128: val_acc did not improve from 0.89088\n",
      "Epoch 129/200\n",
      "1083/1083 [==============================] - 35s 32ms/step - loss: 0.2641 - acc: 0.8968 - val_loss: 0.3379 - val_acc: 0.8880\n",
      "\n",
      "Epoch 00129: val_acc did not improve from 0.89088\n",
      "Epoch 130/200\n",
      "1083/1083 [==============================] - 35s 32ms/step - loss: 0.2643 - acc: 0.8955 - val_loss: 0.3663 - val_acc: 0.8773\n",
      "\n",
      "Epoch 00130: val_acc did not improve from 0.89088\n",
      "Epoch 131/200\n",
      "1083/1083 [==============================] - 35s 32ms/step - loss: 0.2600 - acc: 0.8981 - val_loss: 0.3393 - val_acc: 0.8849\n",
      "\n",
      "Epoch 00131: val_acc did not improve from 0.89088\n",
      "Epoch 132/200\n",
      "1083/1083 [==============================] - 35s 32ms/step - loss: 0.2684 - acc: 0.8938 - val_loss: 0.3477 - val_acc: 0.8858\n",
      "\n",
      "Epoch 00132: val_acc did not improve from 0.89088\n",
      "Epoch 133/200\n",
      "1083/1083 [==============================] - 35s 32ms/step - loss: 0.2607 - acc: 0.8973 - val_loss: 0.3472 - val_acc: 0.8889\n",
      "\n",
      "Epoch 00133: val_acc did not improve from 0.89088\n",
      "Epoch 134/200\n",
      "1083/1083 [==============================] - 35s 32ms/step - loss: 0.2609 - acc: 0.8989 - val_loss: 0.3576 - val_acc: 0.8833\n",
      "\n",
      "Epoch 00134: val_acc did not improve from 0.89088\n",
      "Epoch 135/200\n",
      "1083/1083 [==============================] - 35s 32ms/step - loss: 0.2615 - acc: 0.8964 - val_loss: 0.3329 - val_acc: 0.8892\n",
      "\n",
      "Epoch 00135: val_acc did not improve from 0.89088\n",
      "Epoch 136/200\n",
      "1083/1083 [==============================] - 35s 32ms/step - loss: 0.2584 - acc: 0.8980 - val_loss: 0.3356 - val_acc: 0.8848\n",
      "\n",
      "Epoch 00136: val_acc did not improve from 0.89088\n",
      "Epoch 137/200\n",
      "1083/1083 [==============================] - 35s 32ms/step - loss: 0.2609 - acc: 0.8972 - val_loss: 0.3328 - val_acc: 0.8898\n",
      "\n",
      "Epoch 00137: val_acc did not improve from 0.89088\n",
      "Epoch 138/200\n",
      "1083/1083 [==============================] - 35s 32ms/step - loss: 0.2606 - acc: 0.8988 - val_loss: 0.3340 - val_acc: 0.8897\n",
      "\n",
      "Epoch 00138: val_acc did not improve from 0.89088\n",
      "Epoch 139/200\n",
      "1083/1083 [==============================] - 35s 32ms/step - loss: 0.2556 - acc: 0.9004 - val_loss: 0.3506 - val_acc: 0.8839\n",
      "\n",
      "Epoch 00139: val_acc did not improve from 0.89088\n",
      "Epoch 140/200\n",
      "1083/1083 [==============================] - 35s 32ms/step - loss: 0.2597 - acc: 0.8968 - val_loss: 0.3450 - val_acc: 0.8842\n",
      "\n",
      "Epoch 00140: val_acc did not improve from 0.89088\n",
      "Epoch 141/200\n",
      "1083/1083 [==============================] - 35s 32ms/step - loss: 0.2565 - acc: 0.8992 - val_loss: 0.3338 - val_acc: 0.8893\n",
      "\n",
      "Epoch 00141: val_acc did not improve from 0.89088\n",
      "Epoch 142/200\n",
      "1083/1083 [==============================] - 35s 33ms/step - loss: 0.2528 - acc: 0.8991 - val_loss: 0.3413 - val_acc: 0.8886\n",
      "\n",
      "Epoch 00142: val_acc did not improve from 0.89088\n",
      "Epoch 143/200\n",
      "1083/1083 [==============================] - 35s 32ms/step - loss: 0.2547 - acc: 0.9000 - val_loss: 0.3356 - val_acc: 0.8886\n",
      "\n",
      "Epoch 00143: val_acc did not improve from 0.89088\n",
      "Epoch 144/200\n",
      "1083/1083 [==============================] - 35s 32ms/step - loss: 0.2533 - acc: 0.9007 - val_loss: 0.3395 - val_acc: 0.8894\n",
      "\n",
      "Epoch 00144: val_acc did not improve from 0.89088\n",
      "Epoch 145/200\n",
      "1083/1083 [==============================] - 35s 32ms/step - loss: 0.2502 - acc: 0.9028 - val_loss: 0.3307 - val_acc: 0.8926\n",
      "\n",
      "Epoch 00145: val_acc improved from 0.89088 to 0.89261, saving model to best_model_f3.h5\n",
      "Epoch 146/200\n",
      "1083/1083 [==============================] - 35s 32ms/step - loss: 0.2486 - acc: 0.9021 - val_loss: 0.3661 - val_acc: 0.8770\n",
      "\n",
      "Epoch 00146: val_acc did not improve from 0.89261\n",
      "Epoch 147/200\n",
      "1083/1083 [==============================] - 35s 32ms/step - loss: 0.2521 - acc: 0.9015 - val_loss: 0.3682 - val_acc: 0.8800\n",
      "\n",
      "Epoch 00147: val_acc did not improve from 0.89261\n",
      "Epoch 148/200\n",
      "1083/1083 [==============================] - 35s 32ms/step - loss: 0.2533 - acc: 0.9009 - val_loss: 0.3456 - val_acc: 0.8879\n",
      "\n",
      "Epoch 00148: val_acc did not improve from 0.89261\n",
      "Epoch 149/200\n",
      "1083/1083 [==============================] - 35s 32ms/step - loss: 0.2498 - acc: 0.9027 - val_loss: 0.3480 - val_acc: 0.8878\n",
      "\n",
      "Epoch 00149: val_acc did not improve from 0.89261\n",
      "Epoch 150/200\n",
      "1083/1083 [==============================] - 35s 32ms/step - loss: 0.2475 - acc: 0.9043 - val_loss: 0.3542 - val_acc: 0.8841\n",
      "\n",
      "Epoch 00150: val_acc did not improve from 0.89261\n",
      "Epoch 151/200\n",
      "1083/1083 [==============================] - 35s 32ms/step - loss: 0.2481 - acc: 0.9035 - val_loss: 0.3411 - val_acc: 0.8894\n",
      "\n",
      "Epoch 00151: val_acc did not improve from 0.89261\n",
      "Epoch 152/200\n",
      "1083/1083 [==============================] - 35s 32ms/step - loss: 0.2488 - acc: 0.9024 - val_loss: 0.3403 - val_acc: 0.8879\n",
      "\n",
      "Epoch 00152: val_acc did not improve from 0.89261\n",
      "Epoch 153/200\n",
      "1083/1083 [==============================] - 35s 32ms/step - loss: 0.2448 - acc: 0.9038 - val_loss: 0.3386 - val_acc: 0.8913\n",
      "\n",
      "Epoch 00153: val_acc did not improve from 0.89261\n",
      "Epoch 154/200\n",
      "1083/1083 [==============================] - 35s 32ms/step - loss: 0.2474 - acc: 0.9031 - val_loss: 0.3436 - val_acc: 0.8868\n",
      "\n",
      "Epoch 00154: val_acc did not improve from 0.89261\n",
      "Epoch 155/200\n",
      "1083/1083 [==============================] - 35s 32ms/step - loss: 0.2442 - acc: 0.9038 - val_loss: 0.3604 - val_acc: 0.8834\n",
      "\n",
      "Epoch 00155: val_acc did not improve from 0.89261\n",
      "Epoch 156/200\n",
      "1083/1083 [==============================] - 35s 32ms/step - loss: 0.2444 - acc: 0.9052 - val_loss: 0.3479 - val_acc: 0.8893\n",
      "\n",
      "Epoch 00156: val_acc did not improve from 0.89261\n",
      "Epoch 157/200\n",
      "1083/1083 [==============================] - 35s 32ms/step - loss: 0.2443 - acc: 0.9047 - val_loss: 0.3517 - val_acc: 0.8875\n",
      "\n",
      "Epoch 00157: val_acc did not improve from 0.89261\n",
      "Epoch 158/200\n",
      "1083/1083 [==============================] - 35s 32ms/step - loss: 0.2399 - acc: 0.9059 - val_loss: 0.3573 - val_acc: 0.8867\n",
      "\n",
      "Epoch 00158: val_acc did not improve from 0.89261\n",
      "Epoch 159/200\n",
      "1083/1083 [==============================] - 35s 32ms/step - loss: 0.2426 - acc: 0.9042 - val_loss: 0.3589 - val_acc: 0.8864\n",
      "\n",
      "Epoch 00159: val_acc did not improve from 0.89261\n",
      "Epoch 160/200\n",
      "1083/1083 [==============================] - 35s 32ms/step - loss: 0.2402 - acc: 0.9061 - val_loss: 0.3284 - val_acc: 0.8918\n",
      "\n",
      "Epoch 00160: val_acc did not improve from 0.89261\n",
      "Epoch 161/200\n",
      "1083/1083 [==============================] - 35s 32ms/step - loss: 0.2386 - acc: 0.9065 - val_loss: 0.3381 - val_acc: 0.8892\n",
      "\n",
      "Epoch 00161: val_acc did not improve from 0.89261\n",
      "Epoch 162/200\n",
      "1083/1083 [==============================] - 35s 32ms/step - loss: 0.2352 - acc: 0.9101 - val_loss: 0.3314 - val_acc: 0.8923\n",
      "\n",
      "Epoch 00162: val_acc did not improve from 0.89261\n",
      "Epoch 163/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1083/1083 [==============================] - 35s 32ms/step - loss: 0.2421 - acc: 0.9065 - val_loss: 0.3535 - val_acc: 0.8851\n",
      "\n",
      "Epoch 00163: val_acc did not improve from 0.89261\n",
      "Epoch 164/200\n",
      "1083/1083 [==============================] - 35s 32ms/step - loss: 0.2380 - acc: 0.9077 - val_loss: 0.3602 - val_acc: 0.8847\n",
      "\n",
      "Epoch 00164: val_acc did not improve from 0.89261\n",
      "Epoch 165/200\n",
      "1083/1083 [==============================] - 35s 32ms/step - loss: 0.2382 - acc: 0.9071 - val_loss: 0.3467 - val_acc: 0.8874\n",
      "\n",
      "Epoch 00165: val_acc did not improve from 0.89261\n",
      "Epoch 166/200\n",
      "1083/1083 [==============================] - 35s 32ms/step - loss: 0.2359 - acc: 0.9073 - val_loss: 0.3484 - val_acc: 0.8882\n",
      "\n",
      "Epoch 00166: val_acc did not improve from 0.89261\n",
      "Epoch 167/200\n",
      "1083/1083 [==============================] - 35s 32ms/step - loss: 0.2362 - acc: 0.9080 - val_loss: 0.3415 - val_acc: 0.8906\n",
      "\n",
      "Epoch 00167: val_acc did not improve from 0.89261\n",
      "Epoch 168/200\n",
      "1083/1083 [==============================] - 35s 32ms/step - loss: 0.2359 - acc: 0.9084 - val_loss: 0.3496 - val_acc: 0.8874\n",
      "\n",
      "Epoch 00168: val_acc did not improve from 0.89261\n",
      "Epoch 169/200\n",
      "1083/1083 [==============================] - 35s 32ms/step - loss: 0.2345 - acc: 0.9100 - val_loss: 0.3591 - val_acc: 0.8849\n",
      "\n",
      "Epoch 00169: val_acc did not improve from 0.89261\n",
      "Epoch 170/200\n",
      "1083/1083 [==============================] - 35s 32ms/step - loss: 0.2321 - acc: 0.9094 - val_loss: 0.3442 - val_acc: 0.8930\n",
      "\n",
      "Epoch 00170: val_acc improved from 0.89261 to 0.89301, saving model to best_model_f3.h5\n",
      "Epoch 171/200\n",
      "1083/1083 [==============================] - 35s 32ms/step - loss: 0.2307 - acc: 0.9107 - val_loss: 0.3370 - val_acc: 0.8942\n",
      "\n",
      "Epoch 00171: val_acc improved from 0.89301 to 0.89423, saving model to best_model_f3.h5\n",
      "Epoch 172/200\n",
      "1083/1083 [==============================] - 35s 32ms/step - loss: 0.2328 - acc: 0.9094 - val_loss: 0.3337 - val_acc: 0.8911\n",
      "\n",
      "Epoch 00172: val_acc did not improve from 0.89423\n",
      "Epoch 173/200\n",
      "1083/1083 [==============================] - 35s 32ms/step - loss: 0.2323 - acc: 0.9091 - val_loss: 0.3643 - val_acc: 0.8864\n",
      "\n",
      "Epoch 00173: val_acc did not improve from 0.89423\n",
      "Epoch 174/200\n",
      "1083/1083 [==============================] - 35s 32ms/step - loss: 0.2284 - acc: 0.9109 - val_loss: 0.3578 - val_acc: 0.8859\n",
      "\n",
      "Epoch 00174: val_acc did not improve from 0.89423\n",
      "Epoch 175/200\n",
      "1083/1083 [==============================] - 35s 32ms/step - loss: 0.2313 - acc: 0.9098 - val_loss: 0.3662 - val_acc: 0.8841\n",
      "\n",
      "Epoch 00175: val_acc did not improve from 0.89423\n",
      "Epoch 176/200\n",
      "1083/1083 [==============================] - 35s 32ms/step - loss: 0.2288 - acc: 0.9117 - val_loss: 0.3554 - val_acc: 0.8860\n",
      "\n",
      "Epoch 00176: val_acc did not improve from 0.89423\n",
      "Epoch 177/200\n",
      "1083/1083 [==============================] - 35s 32ms/step - loss: 0.2267 - acc: 0.9123 - val_loss: 0.3450 - val_acc: 0.8865\n",
      "\n",
      "Epoch 00177: val_acc did not improve from 0.89423\n",
      "Epoch 178/200\n",
      "1083/1083 [==============================] - 35s 32ms/step - loss: 0.2280 - acc: 0.9104 - val_loss: 0.3421 - val_acc: 0.8898\n",
      "\n",
      "Epoch 00178: val_acc did not improve from 0.89423\n",
      "Epoch 179/200\n",
      "1083/1083 [==============================] - 35s 32ms/step - loss: 0.2262 - acc: 0.9130 - val_loss: 0.3447 - val_acc: 0.8921\n",
      "\n",
      "Epoch 00179: val_acc did not improve from 0.89423\n",
      "Epoch 180/200\n",
      "1083/1083 [==============================] - 35s 32ms/step - loss: 0.2294 - acc: 0.9102 - val_loss: 0.3555 - val_acc: 0.8887\n",
      "\n",
      "Epoch 00180: val_acc did not improve from 0.89423\n",
      "Epoch 181/200\n",
      "1083/1083 [==============================] - 35s 32ms/step - loss: 0.2226 - acc: 0.9134 - val_loss: 0.3699 - val_acc: 0.8868\n",
      "\n",
      "Epoch 00181: val_acc did not improve from 0.89423\n",
      "Epoch 182/200\n",
      "1083/1083 [==============================] - 35s 32ms/step - loss: 0.2228 - acc: 0.9143 - val_loss: 0.3558 - val_acc: 0.8905\n",
      "\n",
      "Epoch 00182: val_acc did not improve from 0.89423\n",
      "Epoch 183/200\n",
      "1083/1083 [==============================] - 35s 32ms/step - loss: 0.2259 - acc: 0.9123 - val_loss: 0.3647 - val_acc: 0.8852\n",
      "\n",
      "Epoch 00183: val_acc did not improve from 0.89423\n",
      "Epoch 184/200\n",
      "1083/1083 [==============================] - 35s 32ms/step - loss: 0.2248 - acc: 0.9129 - val_loss: 0.3482 - val_acc: 0.8913\n",
      "\n",
      "Epoch 00184: val_acc did not improve from 0.89423\n",
      "Epoch 185/200\n",
      "1083/1083 [==============================] - 35s 32ms/step - loss: 0.2251 - acc: 0.9127 - val_loss: 0.3498 - val_acc: 0.8911\n",
      "\n",
      "Epoch 00185: val_acc did not improve from 0.89423\n",
      "Epoch 186/200\n",
      "1083/1083 [==============================] - 35s 32ms/step - loss: 0.2203 - acc: 0.9144 - val_loss: 0.3463 - val_acc: 0.8940\n",
      "\n",
      "Epoch 00186: val_acc did not improve from 0.89423\n",
      "Epoch 187/200\n",
      "1083/1083 [==============================] - 35s 32ms/step - loss: 0.2235 - acc: 0.9138 - val_loss: 0.3515 - val_acc: 0.8895\n",
      "\n",
      "Epoch 00187: val_acc did not improve from 0.89423\n",
      "Epoch 188/200\n",
      "1083/1083 [==============================] - 35s 32ms/step - loss: 0.2234 - acc: 0.9143 - val_loss: 0.3438 - val_acc: 0.8947\n",
      "\n",
      "Epoch 00188: val_acc improved from 0.89423 to 0.89475, saving model to best_model_f3.h5\n",
      "Epoch 189/200\n",
      "1083/1083 [==============================] - 35s 32ms/step - loss: 0.2235 - acc: 0.9148 - val_loss: 0.3419 - val_acc: 0.8928\n",
      "\n",
      "Epoch 00189: val_acc did not improve from 0.89475\n",
      "Epoch 190/200\n",
      "1083/1083 [==============================] - 35s 32ms/step - loss: 0.2231 - acc: 0.9119 - val_loss: 0.3792 - val_acc: 0.8818\n",
      "\n",
      "Epoch 00190: val_acc did not improve from 0.89475\n",
      "Epoch 191/200\n",
      "1083/1083 [==============================] - 35s 32ms/step - loss: 0.2202 - acc: 0.9144 - val_loss: 0.3365 - val_acc: 0.8942\n",
      "\n",
      "Epoch 00191: val_acc did not improve from 0.89475\n",
      "Epoch 192/200\n",
      "1083/1083 [==============================] - 35s 32ms/step - loss: 0.2222 - acc: 0.9138 - val_loss: 0.3449 - val_acc: 0.8956\n",
      "\n",
      "Epoch 00192: val_acc improved from 0.89475 to 0.89555, saving model to best_model_f3.h5\n",
      "Epoch 193/200\n",
      "1083/1083 [==============================] - 35s 32ms/step - loss: 0.2183 - acc: 0.9149 - val_loss: 0.3376 - val_acc: 0.8960\n",
      "\n",
      "Epoch 00193: val_acc improved from 0.89555 to 0.89602, saving model to best_model_f3.h5\n",
      "Epoch 194/200\n",
      "1083/1083 [==============================] - 35s 32ms/step - loss: 0.2165 - acc: 0.9171 - val_loss: 0.3628 - val_acc: 0.8894\n",
      "\n",
      "Epoch 00194: val_acc did not improve from 0.89602\n",
      "Epoch 195/200\n",
      "1083/1083 [==============================] - 35s 32ms/step - loss: 0.2181 - acc: 0.9161 - val_loss: 0.3504 - val_acc: 0.8928\n",
      "\n",
      "Epoch 00195: val_acc did not improve from 0.89602\n",
      "Epoch 196/200\n",
      "1083/1083 [==============================] - 35s 32ms/step - loss: 0.2139 - acc: 0.9165 - val_loss: 0.3777 - val_acc: 0.8864\n",
      "\n",
      "Epoch 00196: val_acc did not improve from 0.89602\n",
      "Epoch 197/200\n",
      "1083/1083 [==============================] - 35s 32ms/step - loss: 0.2166 - acc: 0.9158 - val_loss: 0.3489 - val_acc: 0.8928\n",
      "\n",
      "Epoch 00197: val_acc did not improve from 0.89602\n",
      "Epoch 198/200\n",
      "1083/1083 [==============================] - 35s 32ms/step - loss: 0.2179 - acc: 0.9166 - val_loss: 0.3498 - val_acc: 0.8938\n",
      "\n",
      "Epoch 00198: val_acc did not improve from 0.89602\n",
      "Epoch 199/200\n",
      "1083/1083 [==============================] - 35s 32ms/step - loss: 0.2185 - acc: 0.9144 - val_loss: 0.3786 - val_acc: 0.8855\n",
      "\n",
      "Epoch 00199: val_acc did not improve from 0.89602\n",
      "Epoch 200/200\n",
      "1083/1083 [==============================] - 35s 32ms/step - loss: 0.2143 - acc: 0.9184 - val_loss: 0.3435 - val_acc: 0.8957\n",
      "\n",
      "Epoch 00200: val_acc did not improve from 0.89602\n",
      "CPU times: user 7h 16min 10s, sys: 51min 44s, total: 8h 7min 55s\n",
      "Wall time: 1h 57min 6s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "mc3 = ModelCheckpoint('best_model_f3.h5', monitor='val_acc', mode='max', save_best_only=True,verbose=1)  \n",
    "history3 = model3.fit(X_train, y_train, batch_size=64, epochs=200, validation_split=0.2, verbose=1, callbacks=[mc3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "b3f2865d",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('history_f3.json', 'w') as f:\n",
    "    json.dump(history3.history, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "21a83eb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model3.save('themodel_f3.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce95265f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
