{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8de4bbaf",
   "metadata": {},
   "source": [
    "# LSTM - Glove\n",
    "\n",
    "- ASAD Dataset\n",
    "- ROS Balanced\n",
    "- LSTM 1, 2 and 3 Layers\n",
    "- Cell: 64\n",
    "- Learning-rate: 0.001\n",
    "- Embedding: Glove dim 300"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f9aa808",
   "metadata": {},
   "source": [
    "## Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "41167290",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.pyplot as plt\n",
    "import csv\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.layers import Dense,Flatten,Embedding,Activation, Dropout\n",
    "from tensorflow.keras.models import Sequential\n",
    "from keras.layers import LSTM\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from keras import layers\n",
    "from tensorflow.keras.layers import GlobalMaxPooling1D\n",
    "from keras.layers import Bidirectional\n",
    "from keras.callbacks import *\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from scipy import spatial\n",
    "from gensim.utils import simple_preprocess\n",
    "from keras.preprocessing import sequence\n",
    "from keras.utils.vis_utils import plot_model\n",
    "from keras.models import load_model\n",
    "import tensorflow as tf\n",
    "from imblearn.over_sampling import SMOTE, RandomOverSampler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4af0f4bf",
   "metadata": {},
   "source": [
    "## Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "2e6d554a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1221875106206638080</td>\n",
       "      <td>والله الأرقام سيكون مخيب للآمال الأهلي قدها بر...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1221884257490042887</td>\n",
       "      <td>الزعل بيغير ملامحك بيغير نظرة العين بيغير شكلك...</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1226422627436310528</td>\n",
       "      <td>الحب الحقيقي اقتسام شخص أخر أقرب احلام مستغانمي</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1221880820815798277</td>\n",
       "      <td>النهضة فتيل</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1221884400377499651</td>\n",
       "      <td>حباً ايران بقدر ماهو نكايه بترامب وحزبه</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>1221882259139067911</td>\n",
       "      <td>ليه اسوم حياتي غيرت وانا اعرف</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>1221881289881550848</td>\n",
       "      <td>هههه ضحكت حالة نفسية سعيده</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>1227326811652026368</td>\n",
       "      <td>الحمدلله حضنت امي الحقيقية تعرفون شنو شعور تتر...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>1221882556548816896</td>\n",
       "      <td>توني ادري ان قناة اسمها يمدح السوق الا اللي رب...</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>1221883443467952128</td>\n",
       "      <td>عدلت شعري وطلع يهبل وربي صحيت بكره مو كويس لاد...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     id                                               text  \\\n",
       "0   1221875106206638080  والله الأرقام سيكون مخيب للآمال الأهلي قدها بر...   \n",
       "1   1221884257490042887  الزعل بيغير ملامحك بيغير نظرة العين بيغير شكلك...   \n",
       "2   1226422627436310528    الحب الحقيقي اقتسام شخص أخر أقرب احلام مستغانمي   \n",
       "3   1221880820815798277                                        النهضة فتيل   \n",
       "4   1221884400377499651            حباً ايران بقدر ماهو نكايه بترامب وحزبه   \n",
       "..                  ...                                                ...   \n",
       "95  1221882259139067911                      ليه اسوم حياتي غيرت وانا اعرف   \n",
       "96  1221881289881550848                         هههه ضحكت حالة نفسية سعيده   \n",
       "97  1227326811652026368  الحمدلله حضنت امي الحقيقية تعرفون شنو شعور تتر...   \n",
       "98  1221882556548816896  توني ادري ان قناة اسمها يمدح السوق الا اللي رب...   \n",
       "99  1221883443467952128  عدلت شعري وطلع يهبل وربي صحيت بكره مو كويس لاد...   \n",
       "\n",
       "   sentiment  \n",
       "0   Positive  \n",
       "1    Neutral  \n",
       "2   Positive  \n",
       "3   Positive  \n",
       "4    Neutral  \n",
       "..       ...  \n",
       "95   Neutral  \n",
       "96  Positive  \n",
       "97  Positive  \n",
       "98   Neutral  \n",
       "99  Positive  \n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file='../complete_training_all_punctuation_cleaning_stopword.csv'\n",
    "data = pd.read_csv(file,header=0, delimiter=\"\\t\",encoding='utf-8')\n",
    "data.text=data.text.astype(str)\n",
    "data.head(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ef00ad37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(53289, 3)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "e127dab0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Neutral     36082\n",
       "Negative     8674\n",
       "Positive     8533\n",
       "Name: sentiment, dtype: int64"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = data[['id', 'sentiment']]\n",
    "labels.sentiment.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "beb1a55a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Negative', 'Neutral', 'Positive']"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classes = sorted(labels.sentiment.unique())\n",
    "classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "1690888f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[8674, 36082, 8533]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfs = []\n",
    "for sentiment in classes:\n",
    "    df_temp = data.where(data.sentiment == sentiment)\n",
    "    df_temp.dropna(axis=0, inplace=True)\n",
    "    dfs.append(df_temp)\n",
    "ls = [len(df) for df in dfs]\n",
    "ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "57e42330",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 216x216 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(3, 3))\n",
    "plt.pie(ls, labels=classes);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca798d2b",
   "metadata": {},
   "source": [
    "## Augmented data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "66abca3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# new_dfs = [pd.concat([df]*int(max(ls)/len(df)), ignore_index=True) \n",
    "#           for df in dfs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "23946681",
   "metadata": {},
   "outputs": [],
   "source": [
    "# new_ls = [len(df) for df in new_dfs]\n",
    "# new_ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "6115ee9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.figure(figsize=(3, 3))\n",
    "# plt.pie(new_ls, labels=classes);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "ceceeec4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data = pd.concat(new_dfs, ignore_index=True)\n",
    "# labels = data[['id','text', 'sentiment']]\n",
    "# classes = sorted(labels.sentiment.unique())\n",
    "# classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "5fb678d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1221875106206638080</td>\n",
       "      <td>والله الأرقام سيكون مخيب للآمال الأهلي قدها بر...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1221884257490042887</td>\n",
       "      <td>الزعل بيغير ملامحك بيغير نظرة العين بيغير شكلك...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1226422627436310528</td>\n",
       "      <td>الحب الحقيقي اقتسام شخص أخر أقرب احلام مستغانمي</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1221880820815798277</td>\n",
       "      <td>النهضة فتيل</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1221884400377499651</td>\n",
       "      <td>حباً ايران بقدر ماهو نكايه بترامب وحزبه</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>1221882259139067911</td>\n",
       "      <td>ليه اسوم حياتي غيرت وانا اعرف</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>1221881289881550848</td>\n",
       "      <td>هههه ضحكت حالة نفسية سعيده</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>1227326811652026368</td>\n",
       "      <td>الحمدلله حضنت امي الحقيقية تعرفون شنو شعور تتر...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>1221882556548816896</td>\n",
       "      <td>توني ادري ان قناة اسمها يمدح السوق الا اللي رب...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>1221883443467952128</td>\n",
       "      <td>عدلت شعري وطلع يهبل وربي صحيت بكره مو كويس لاد...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     id                                               text  \\\n",
       "0   1221875106206638080  والله الأرقام سيكون مخيب للآمال الأهلي قدها بر...   \n",
       "1   1221884257490042887  الزعل بيغير ملامحك بيغير نظرة العين بيغير شكلك...   \n",
       "2   1226422627436310528    الحب الحقيقي اقتسام شخص أخر أقرب احلام مستغانمي   \n",
       "3   1221880820815798277                                        النهضة فتيل   \n",
       "4   1221884400377499651            حباً ايران بقدر ماهو نكايه بترامب وحزبه   \n",
       "..                  ...                                                ...   \n",
       "95  1221882259139067911                      ليه اسوم حياتي غيرت وانا اعرف   \n",
       "96  1221881289881550848                         هههه ضحكت حالة نفسية سعيده   \n",
       "97  1227326811652026368  الحمدلله حضنت امي الحقيقية تعرفون شنو شعور تتر...   \n",
       "98  1221882556548816896  توني ادري ان قناة اسمها يمدح السوق الا اللي رب...   \n",
       "99  1221883443467952128  عدلت شعري وطلع يهبل وربي صحيت بكره مو كويس لاد...   \n",
       "\n",
       "    sentiment  \n",
       "0           1  \n",
       "1           0  \n",
       "2           1  \n",
       "3           1  \n",
       "4           0  \n",
       "..        ...  \n",
       "95          0  \n",
       "96          1  \n",
       "97          1  \n",
       "98          0  \n",
       "99          1  \n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"sentiment\"].value_counts()\n",
    "cleanup_nums = {\"sentiment\":     {\"Neutral\": 0,\"Negative\":2, \"Positive\": 1,}}\n",
    "data = data.replace(cleanup_nums)\n",
    "data.head(100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2817bafa",
   "metadata": {},
   "source": [
    "## Convert to Numeric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "e7e0930e",
   "metadata": {},
   "outputs": [],
   "source": [
    "maxSeqLength=30\n",
    "\n",
    "#conversion to list and then displaying the list\n",
    "text = data['text'].tolist()\n",
    "\n",
    "#tokenizer to read all the words present in our dtaset\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(text)\n",
    "\n",
    "#declaring the vocab_size\n",
    "size_of_vocabulary  = len(tokenizer.word_index) + 1\n",
    "\n",
    "#conversion to numerical formats\n",
    "encoded_text = tokenizer.texts_to_sequences(text)\n",
    "max_length = maxSeqLength\n",
    "X = sequence.pad_sequences(encoded_text, maxlen=max_length, padding='post')\n",
    "y = data['sentiment']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "b2665174",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(53289, 30)\n",
      "(53289,)\n"
     ]
    }
   ],
   "source": [
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "ee727d8e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    36082\n",
       "2     8674\n",
       "1     8533\n",
       "Name: sentiment, dtype: int64"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "f20939e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(86596, 30) (86596,)\n",
      "(21650, 30) (21650,)\n"
     ]
    }
   ],
   "source": [
    "# ROS\n",
    "ros = RandomOverSampler(random_state=42)\n",
    "X, y = ros.fit_resample(X, y)\n",
    "\n",
    "# Split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state = 42, test_size = 0.2, stratify = y)\n",
    "\n",
    "print(X_train.shape, y_train.shape)\n",
    "print(X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75331113",
   "metadata": {},
   "source": [
    "## Glove Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "62715e99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 14869 word vectors.\n",
      "CPU times: user 592 ms, sys: 7.17 ms, total: 599 ms\n",
      "Wall time: 596 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "filecorpusGlove='../GloveArabicDim300_allclass.txt'\n",
    "import numpy as np\n",
    "glove_vectors = dict()\n",
    "\n",
    "f = open(filecorpusGlove, 'r', encoding='utf-8')\n",
    "for line in f:\n",
    "    values = line.split()\n",
    "    word = values[0]\n",
    "    #storing the word in the variable\n",
    "    vectors = np.asarray(values[1:], dtype='float32')\n",
    "    #storing the vector representation of the respective word in the dictionary\n",
    "    glove_vectors[word] = vectors\n",
    "f.close()\n",
    "print('Loaded %s word vectors.' % len(glove_vectors))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "87018b59",
   "metadata": {},
   "outputs": [],
   "source": [
    "words_not_found = []\n",
    "embedding_dim = 300 \n",
    "embedding_matrix = np.zeros((size_of_vocabulary, embedding_dim))\n",
    "for word, i in tokenizer.word_index.items():\n",
    "    embedding_vector = glove_vectors.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        embedding_matrix[i] = embedding_vector\n",
    "    else:\n",
    "        words_not_found.append(word)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01c8b1a2",
   "metadata": {},
   "source": [
    "# Set CUDA Env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "d4bce875",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "use_cuda = torch.cuda.is_available()\n",
    "print(use_cuda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "d28a84b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__CUDNN VERSION: 7605\n",
      "__Number CUDA Devices: 1\n",
      "__CUDA Device Name: TITAN V\n",
      "__CUDA Device Total Memory [GB]: 12.650217472\n"
     ]
    }
   ],
   "source": [
    "if use_cuda:\n",
    "    print('__CUDNN VERSION:', torch.backends.cudnn.version())\n",
    "    print('__Number CUDA Devices:', torch.cuda.device_count())\n",
    "    print('__CUDA Device Name:',torch.cuda.get_device_name(0))\n",
    "    print('__CUDA Device Total Memory [GB]:',torch.cuda.get_device_properties(0).total_memory/1e9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "b9b85794",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device:  cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "print(\"Device: \", device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ccaa5d8",
   "metadata": {},
   "source": [
    "## LSTM 1 Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "adf02023",
   "metadata": {},
   "outputs": [],
   "source": [
    "UNITS = 64\n",
    "lr = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "5e40602f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_3 (Embedding)      (None, 30, 300)           31476300  \n",
      "_________________________________________________________________\n",
      "lstm_5 (LSTM)                (None, 30, 64)            93440     \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_3 (Glob (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 3)                 195       \n",
      "=================================================================\n",
      "Total params: 31,574,095\n",
      "Trainable params: 97,795\n",
      "Non-trainable params: 31,476,300\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model1=Sequential()\n",
    "model1.add(Embedding(size_of_vocabulary,embedding_dim,weights=[embedding_matrix],input_length=max_length,trainable=False))\n",
    "\n",
    "#Lstm layer\n",
    "model1.add(LSTM(UNITS,return_sequences=True,dropout=0.5))\n",
    "\n",
    "#Global Maxpooling\n",
    "model1.add(GlobalMaxPooling1D())\n",
    "\n",
    "#Dense Layer\n",
    "model1.add(Dense(UNITS, activation='relu'))\n",
    "\n",
    "#Output layer 3 class\n",
    "model1.add(Dense(3,activation='softmax')) \n",
    "\n",
    "model1.compile(optimizer=Adam(learning_rate = lr), loss = 'sparse_categorical_crossentropy', metrics = ['acc']) \n",
    "print(model1.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2441816a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "1083/1083 [==============================] - 12s 10ms/step - loss: 0.8282 - acc: 0.6180 - val_loss: 0.7471 - val_acc: 0.6633\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.66334, saving model to best_model_g1.h5\n",
      "Epoch 2/200\n",
      "1083/1083 [==============================] - 11s 10ms/step - loss: 0.7657 - acc: 0.6546 - val_loss: 0.7079 - val_acc: 0.6841\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.66334 to 0.68406, saving model to best_model_g1.h5\n",
      "Epoch 3/200\n",
      "1083/1083 [==============================] - 11s 10ms/step - loss: 0.7346 - acc: 0.6713 - val_loss: 0.6795 - val_acc: 0.7033\n",
      "\n",
      "Epoch 00003: val_acc improved from 0.68406 to 0.70329, saving model to best_model_g1.h5\n",
      "Epoch 4/200\n",
      "1083/1083 [==============================] - 11s 10ms/step - loss: 0.7036 - acc: 0.6878 - val_loss: 0.6509 - val_acc: 0.7182\n",
      "\n",
      "Epoch 00004: val_acc improved from 0.70329 to 0.71819, saving model to best_model_g1.h5\n",
      "Epoch 5/200\n",
      "1083/1083 [==============================] - 11s 10ms/step - loss: 0.6805 - acc: 0.7012 - val_loss: 0.6301 - val_acc: 0.7307\n",
      "\n",
      "Epoch 00005: val_acc improved from 0.71819 to 0.73072, saving model to best_model_g1.h5\n",
      "Epoch 6/200\n",
      "1083/1083 [==============================] - 11s 10ms/step - loss: 0.6607 - acc: 0.7125 - val_loss: 0.6110 - val_acc: 0.7396\n",
      "\n",
      "Epoch 00006: val_acc improved from 0.73072 to 0.73961, saving model to best_model_g1.h5\n",
      "Epoch 7/200\n",
      "1083/1083 [==============================] - 11s 10ms/step - loss: 0.6421 - acc: 0.7216 - val_loss: 0.5974 - val_acc: 0.7466\n",
      "\n",
      "Epoch 00007: val_acc improved from 0.73961 to 0.74659, saving model to best_model_g1.h5\n",
      "Epoch 8/200\n",
      "1083/1083 [==============================] - 11s 10ms/step - loss: 0.6306 - acc: 0.7258 - val_loss: 0.5829 - val_acc: 0.7539\n",
      "\n",
      "Epoch 00008: val_acc improved from 0.74659 to 0.75387, saving model to best_model_g1.h5\n",
      "Epoch 9/200\n",
      "1083/1083 [==============================] - 11s 10ms/step - loss: 0.6191 - acc: 0.7324 - val_loss: 0.5725 - val_acc: 0.7619\n",
      "\n",
      "Epoch 00009: val_acc improved from 0.75387 to 0.76189, saving model to best_model_g1.h5\n",
      "Epoch 10/200\n",
      "1083/1083 [==============================] - 11s 10ms/step - loss: 0.6070 - acc: 0.7381 - val_loss: 0.5622 - val_acc: 0.7661\n",
      "\n",
      "Epoch 00010: val_acc improved from 0.76189 to 0.76611, saving model to best_model_g1.h5\n",
      "Epoch 11/200\n",
      "1083/1083 [==============================] - 11s 10ms/step - loss: 0.5976 - acc: 0.7458 - val_loss: 0.5545 - val_acc: 0.7699\n",
      "\n",
      "Epoch 00011: val_acc improved from 0.76611 to 0.76986, saving model to best_model_g1.h5\n",
      "Epoch 12/200\n",
      "1083/1083 [==============================] - 11s 10ms/step - loss: 0.5925 - acc: 0.7467 - val_loss: 0.5486 - val_acc: 0.7718\n",
      "\n",
      "Epoch 00012: val_acc improved from 0.76986 to 0.77182, saving model to best_model_g1.h5\n",
      "Epoch 13/200\n",
      "1083/1083 [==============================] - 11s 10ms/step - loss: 0.5811 - acc: 0.7526 - val_loss: 0.5384 - val_acc: 0.7778\n",
      "\n",
      "Epoch 00013: val_acc improved from 0.77182 to 0.77783, saving model to best_model_g1.h5\n",
      "Epoch 14/200\n",
      "1083/1083 [==============================] - 11s 10ms/step - loss: 0.5791 - acc: 0.7540 - val_loss: 0.5341 - val_acc: 0.7806\n",
      "\n",
      "Epoch 00014: val_acc improved from 0.77783 to 0.78060, saving model to best_model_g1.h5\n",
      "Epoch 15/200\n",
      "1083/1083 [==============================] - 11s 10ms/step - loss: 0.5710 - acc: 0.7569 - val_loss: 0.5370 - val_acc: 0.7796\n",
      "\n",
      "Epoch 00015: val_acc did not improve from 0.78060\n",
      "Epoch 16/200\n",
      "1083/1083 [==============================] - 11s 10ms/step - loss: 0.5661 - acc: 0.7606 - val_loss: 0.5281 - val_acc: 0.7795\n",
      "\n",
      "Epoch 00016: val_acc did not improve from 0.78060\n",
      "Epoch 17/200\n",
      "1083/1083 [==============================] - 11s 10ms/step - loss: 0.5578 - acc: 0.7625 - val_loss: 0.5249 - val_acc: 0.7815\n",
      "\n",
      "Epoch 00017: val_acc improved from 0.78060 to 0.78152, saving model to best_model_g1.h5\n",
      "Epoch 18/200\n",
      "1083/1083 [==============================] - 12s 11ms/step - loss: 0.5531 - acc: 0.7665 - val_loss: 0.5115 - val_acc: 0.7890\n",
      "\n",
      "Epoch 00018: val_acc improved from 0.78152 to 0.78897, saving model to best_model_g1.h5\n",
      "Epoch 19/200\n",
      "1083/1083 [==============================] - 11s 10ms/step - loss: 0.5502 - acc: 0.7673 - val_loss: 0.5166 - val_acc: 0.7905\n",
      "\n",
      "Epoch 00019: val_acc improved from 0.78897 to 0.79047, saving model to best_model_g1.h5\n",
      "Epoch 20/200\n",
      "1083/1083 [==============================] - 11s 10ms/step - loss: 0.5434 - acc: 0.7701 - val_loss: 0.5010 - val_acc: 0.7975\n",
      "\n",
      "Epoch 00020: val_acc improved from 0.79047 to 0.79752, saving model to best_model_g1.h5\n",
      "Epoch 21/200\n",
      "1083/1083 [==============================] - 11s 10ms/step - loss: 0.5422 - acc: 0.7698 - val_loss: 0.5193 - val_acc: 0.7880\n",
      "\n",
      "Epoch 00021: val_acc did not improve from 0.79752\n",
      "Epoch 22/200\n",
      "1083/1083 [==============================] - 11s 10ms/step - loss: 0.5356 - acc: 0.7749 - val_loss: 0.4902 - val_acc: 0.8031\n",
      "\n",
      "Epoch 00022: val_acc improved from 0.79752 to 0.80306, saving model to best_model_g1.h5\n",
      "Epoch 23/200\n",
      "1083/1083 [==============================] - 11s 10ms/step - loss: 0.5362 - acc: 0.7744 - val_loss: 0.4902 - val_acc: 0.8031\n",
      "\n",
      "Epoch 00023: val_acc did not improve from 0.80306\n",
      "Epoch 24/200\n",
      "1083/1083 [==============================] - 11s 10ms/step - loss: 0.5271 - acc: 0.7783 - val_loss: 0.4824 - val_acc: 0.8065\n",
      "\n",
      "Epoch 00024: val_acc improved from 0.80306 to 0.80652, saving model to best_model_g1.h5\n",
      "Epoch 25/200\n",
      "1083/1083 [==============================] - 11s 10ms/step - loss: 0.5273 - acc: 0.7784 - val_loss: 0.4804 - val_acc: 0.8044\n",
      "\n",
      "Epoch 00025: val_acc did not improve from 0.80652\n",
      "Epoch 26/200\n",
      "1083/1083 [==============================] - 11s 10ms/step - loss: 0.5227 - acc: 0.7796 - val_loss: 0.4853 - val_acc: 0.8024\n",
      "\n",
      "Epoch 00026: val_acc did not improve from 0.80652\n",
      "Epoch 27/200\n",
      "1083/1083 [==============================] - 11s 10ms/step - loss: 0.5194 - acc: 0.7820 - val_loss: 0.4754 - val_acc: 0.8088\n",
      "\n",
      "Epoch 00027: val_acc improved from 0.80652 to 0.80883, saving model to best_model_g1.h5\n",
      "Epoch 28/200\n",
      "1083/1083 [==============================] - 11s 10ms/step - loss: 0.5167 - acc: 0.7840 - val_loss: 0.4706 - val_acc: 0.8127\n",
      "\n",
      "Epoch 00028: val_acc improved from 0.80883 to 0.81270, saving model to best_model_g1.h5\n",
      "Epoch 29/200\n",
      "1083/1083 [==============================] - 11s 10ms/step - loss: 0.5161 - acc: 0.7852 - val_loss: 0.4697 - val_acc: 0.8122\n",
      "\n",
      "Epoch 00029: val_acc did not improve from 0.81270\n",
      "Epoch 30/200\n",
      "1083/1083 [==============================] - 11s 10ms/step - loss: 0.5113 - acc: 0.7848 - val_loss: 0.4630 - val_acc: 0.8162\n",
      "\n",
      "Epoch 00030: val_acc improved from 0.81270 to 0.81617, saving model to best_model_g1.h5\n",
      "Epoch 31/200\n",
      "1083/1083 [==============================] - 12s 11ms/step - loss: 0.5108 - acc: 0.7871 - val_loss: 0.4627 - val_acc: 0.8162\n",
      "\n",
      "Epoch 00031: val_acc improved from 0.81617 to 0.81622, saving model to best_model_g1.h5\n",
      "Epoch 32/200\n",
      "1083/1083 [==============================] - 11s 10ms/step - loss: 0.5072 - acc: 0.7871 - val_loss: 0.4753 - val_acc: 0.8070\n",
      "\n",
      "Epoch 00032: val_acc did not improve from 0.81622\n",
      "Epoch 33/200\n",
      "1083/1083 [==============================] - 11s 10ms/step - loss: 0.5046 - acc: 0.7879 - val_loss: 0.4550 - val_acc: 0.8205\n",
      "\n",
      "Epoch 00033: val_acc improved from 0.81622 to 0.82050, saving model to best_model_g1.h5\n",
      "Epoch 34/200\n",
      "1083/1083 [==============================] - 11s 10ms/step - loss: 0.5046 - acc: 0.7890 - val_loss: 0.4672 - val_acc: 0.8144\n",
      "\n",
      "Epoch 00034: val_acc did not improve from 0.82050\n",
      "Epoch 35/200\n",
      "1083/1083 [==============================] - 11s 10ms/step - loss: 0.5038 - acc: 0.7900 - val_loss: 0.4538 - val_acc: 0.8170\n",
      "\n",
      "Epoch 00035: val_acc did not improve from 0.82050\n",
      "Epoch 36/200\n",
      "1083/1083 [==============================] - 11s 10ms/step - loss: 0.4976 - acc: 0.7918 - val_loss: 0.4530 - val_acc: 0.8210\n",
      "\n",
      "Epoch 00036: val_acc improved from 0.82050 to 0.82102, saving model to best_model_g1.h5\n",
      "Epoch 37/200\n",
      "1083/1083 [==============================] - 11s 10ms/step - loss: 0.4949 - acc: 0.7936 - val_loss: 0.4526 - val_acc: 0.8197\n",
      "\n",
      "Epoch 00037: val_acc did not improve from 0.82102\n",
      "Epoch 38/200\n",
      "1083/1083 [==============================] - 11s 10ms/step - loss: 0.4967 - acc: 0.7925 - val_loss: 0.4495 - val_acc: 0.8207\n",
      "\n",
      "Epoch 00038: val_acc did not improve from 0.82102\n",
      "Epoch 39/200\n",
      "1083/1083 [==============================] - 11s 10ms/step - loss: 0.4964 - acc: 0.7929 - val_loss: 0.4494 - val_acc: 0.8218\n",
      "\n",
      "Epoch 00039: val_acc improved from 0.82102 to 0.82182, saving model to best_model_g1.h5\n",
      "Epoch 40/200\n",
      "1083/1083 [==============================] - 11s 10ms/step - loss: 0.4913 - acc: 0.7961 - val_loss: 0.4498 - val_acc: 0.8213\n",
      "\n",
      "Epoch 00040: val_acc did not improve from 0.82182\n",
      "Epoch 41/200\n",
      "1083/1083 [==============================] - 11s 10ms/step - loss: 0.4886 - acc: 0.7955 - val_loss: 0.4460 - val_acc: 0.8221\n",
      "\n",
      "Epoch 00041: val_acc improved from 0.82182 to 0.82211, saving model to best_model_g1.h5\n",
      "Epoch 42/200\n",
      "1083/1083 [==============================] - 11s 10ms/step - loss: 0.4938 - acc: 0.7938 - val_loss: 0.4535 - val_acc: 0.8190\n",
      "\n",
      "Epoch 00042: val_acc did not improve from 0.82211\n",
      "Epoch 43/200\n",
      "1083/1083 [==============================] - 11s 10ms/step - loss: 0.4874 - acc: 0.7986 - val_loss: 0.4396 - val_acc: 0.8303\n",
      "\n",
      "Epoch 00043: val_acc improved from 0.82211 to 0.83025, saving model to best_model_g1.h5\n",
      "Epoch 44/200\n",
      "1083/1083 [==============================] - 11s 10ms/step - loss: 0.4881 - acc: 0.7984 - val_loss: 0.4487 - val_acc: 0.8224\n",
      "\n",
      "Epoch 00044: val_acc did not improve from 0.83025\n",
      "Epoch 45/200\n",
      "1083/1083 [==============================] - 11s 10ms/step - loss: 0.4884 - acc: 0.7976 - val_loss: 0.4442 - val_acc: 0.8244\n",
      "\n",
      "Epoch 00045: val_acc did not improve from 0.83025\n",
      "Epoch 46/200\n",
      "1083/1083 [==============================] - 11s 10ms/step - loss: 0.4831 - acc: 0.7990 - val_loss: 0.4403 - val_acc: 0.8297\n",
      "\n",
      "Epoch 00046: val_acc did not improve from 0.83025\n",
      "Epoch 47/200\n",
      "1083/1083 [==============================] - 11s 10ms/step - loss: 0.4849 - acc: 0.7975 - val_loss: 0.4377 - val_acc: 0.8288\n",
      "\n",
      "Epoch 00047: val_acc did not improve from 0.83025\n",
      "Epoch 48/200\n",
      "1083/1083 [==============================] - 11s 10ms/step - loss: 0.4858 - acc: 0.7995 - val_loss: 0.4372 - val_acc: 0.8309\n",
      "\n",
      "Epoch 00048: val_acc improved from 0.83025 to 0.83089, saving model to best_model_g1.h5\n",
      "Epoch 49/200\n",
      "1083/1083 [==============================] - 11s 10ms/step - loss: 0.4817 - acc: 0.7996 - val_loss: 0.4418 - val_acc: 0.8253\n",
      "\n",
      "Epoch 00049: val_acc did not improve from 0.83089\n",
      "Epoch 50/200\n",
      "1083/1083 [==============================] - 11s 10ms/step - loss: 0.4830 - acc: 0.7987 - val_loss: 0.4369 - val_acc: 0.8271\n",
      "\n",
      "Epoch 00050: val_acc did not improve from 0.83089\n",
      "Epoch 51/200\n",
      "1083/1083 [==============================] - 11s 10ms/step - loss: 0.4771 - acc: 0.8020 - val_loss: 0.4403 - val_acc: 0.8260\n",
      "\n",
      "Epoch 00051: val_acc did not improve from 0.83089\n",
      "Epoch 52/200\n",
      "1083/1083 [==============================] - 11s 10ms/step - loss: 0.4826 - acc: 0.7986 - val_loss: 0.4321 - val_acc: 0.8286\n",
      "\n",
      "Epoch 00052: val_acc did not improve from 0.83089\n",
      "Epoch 53/200\n",
      "1083/1083 [==============================] - 11s 10ms/step - loss: 0.4762 - acc: 0.8030 - val_loss: 0.4387 - val_acc: 0.8263\n",
      "\n",
      "Epoch 00053: val_acc did not improve from 0.83089\n",
      "Epoch 54/200\n",
      "1083/1083 [==============================] - 11s 10ms/step - loss: 0.4808 - acc: 0.8007 - val_loss: 0.4459 - val_acc: 0.8232\n",
      "\n",
      "Epoch 00054: val_acc did not improve from 0.83089\n",
      "Epoch 55/200\n",
      "1083/1083 [==============================] - 11s 10ms/step - loss: 0.4751 - acc: 0.8040 - val_loss: 0.4339 - val_acc: 0.8283\n",
      "\n",
      "Epoch 00055: val_acc did not improve from 0.83089\n",
      "Epoch 56/200\n",
      "1083/1083 [==============================] - 11s 10ms/step - loss: 0.4749 - acc: 0.8024 - val_loss: 0.4367 - val_acc: 0.8279\n",
      "\n",
      "Epoch 00056: val_acc did not improve from 0.83089\n",
      "Epoch 57/200\n",
      "1083/1083 [==============================] - 11s 10ms/step - loss: 0.4730 - acc: 0.8046 - val_loss: 0.4384 - val_acc: 0.8275\n",
      "\n",
      "Epoch 00057: val_acc did not improve from 0.83089\n",
      "Epoch 58/200\n",
      "1083/1083 [==============================] - 11s 10ms/step - loss: 0.4735 - acc: 0.8050 - val_loss: 0.4323 - val_acc: 0.8316\n",
      "\n",
      "Epoch 00058: val_acc improved from 0.83089 to 0.83158, saving model to best_model_g1.h5\n",
      "Epoch 59/200\n",
      "1083/1083 [==============================] - 11s 10ms/step - loss: 0.4739 - acc: 0.8045 - val_loss: 0.4274 - val_acc: 0.8341\n",
      "\n",
      "Epoch 00059: val_acc improved from 0.83158 to 0.83412, saving model to best_model_g1.h5\n",
      "Epoch 60/200\n",
      "1083/1083 [==============================] - 11s 10ms/step - loss: 0.4713 - acc: 0.8041 - val_loss: 0.4340 - val_acc: 0.8303\n",
      "\n",
      "Epoch 00060: val_acc did not improve from 0.83412\n",
      "Epoch 61/200\n",
      "1083/1083 [==============================] - 11s 10ms/step - loss: 0.4738 - acc: 0.8035 - val_loss: 0.4320 - val_acc: 0.8296\n",
      "\n",
      "Epoch 00061: val_acc did not improve from 0.83412\n",
      "Epoch 62/200\n",
      "1083/1083 [==============================] - 11s 10ms/step - loss: 0.4714 - acc: 0.8058 - val_loss: 0.4221 - val_acc: 0.8363\n",
      "\n",
      "Epoch 00062: val_acc improved from 0.83412 to 0.83632, saving model to best_model_g1.h5\n",
      "Epoch 63/200\n",
      "1083/1083 [==============================] - 11s 10ms/step - loss: 0.4708 - acc: 0.8048 - val_loss: 0.4336 - val_acc: 0.8300\n",
      "\n",
      "Epoch 00063: val_acc did not improve from 0.83632\n",
      "Epoch 64/200\n",
      "1083/1083 [==============================] - 11s 10ms/step - loss: 0.4710 - acc: 0.8053 - val_loss: 0.4291 - val_acc: 0.8332\n",
      "\n",
      "Epoch 00064: val_acc did not improve from 0.83632\n",
      "Epoch 65/200\n",
      "1083/1083 [==============================] - 11s 10ms/step - loss: 0.4702 - acc: 0.8050 - val_loss: 0.4252 - val_acc: 0.8342\n",
      "\n",
      "Epoch 00065: val_acc did not improve from 0.83632\n",
      "Epoch 66/200\n",
      "1083/1083 [==============================] - 11s 10ms/step - loss: 0.4672 - acc: 0.8077 - val_loss: 0.4324 - val_acc: 0.8308\n",
      "\n",
      "Epoch 00066: val_acc did not improve from 0.83632\n",
      "Epoch 67/200\n",
      "1083/1083 [==============================] - 11s 10ms/step - loss: 0.4633 - acc: 0.8079 - val_loss: 0.4245 - val_acc: 0.8350\n",
      "\n",
      "Epoch 00067: val_acc did not improve from 0.83632\n",
      "Epoch 68/200\n",
      "1083/1083 [==============================] - 11s 10ms/step - loss: 0.4692 - acc: 0.8063 - val_loss: 0.4204 - val_acc: 0.8372\n",
      "\n",
      "Epoch 00068: val_acc improved from 0.83632 to 0.83718, saving model to best_model_g1.h5\n",
      "Epoch 69/200\n",
      "1083/1083 [==============================] - 11s 10ms/step - loss: 0.4631 - acc: 0.8081 - val_loss: 0.4213 - val_acc: 0.8367\n",
      "\n",
      "Epoch 00069: val_acc did not improve from 0.83718\n",
      "Epoch 70/200\n",
      "1083/1083 [==============================] - 11s 10ms/step - loss: 0.4663 - acc: 0.8072 - val_loss: 0.4227 - val_acc: 0.8348\n",
      "\n",
      "Epoch 00070: val_acc did not improve from 0.83718\n",
      "Epoch 71/200\n",
      "1083/1083 [==============================] - 11s 10ms/step - loss: 0.4662 - acc: 0.8072 - val_loss: 0.4311 - val_acc: 0.8286\n",
      "\n",
      "Epoch 00071: val_acc did not improve from 0.83718\n",
      "Epoch 72/200\n",
      "1083/1083 [==============================] - 11s 10ms/step - loss: 0.4618 - acc: 0.8098 - val_loss: 0.4200 - val_acc: 0.8360\n",
      "\n",
      "Epoch 00072: val_acc did not improve from 0.83718\n",
      "Epoch 73/200\n",
      "1083/1083 [==============================] - 11s 10ms/step - loss: 0.4619 - acc: 0.8099 - val_loss: 0.4171 - val_acc: 0.8370\n",
      "\n",
      "Epoch 00073: val_acc did not improve from 0.83718\n",
      "Epoch 74/200\n",
      "1083/1083 [==============================] - 11s 10ms/step - loss: 0.4650 - acc: 0.8082 - val_loss: 0.4188 - val_acc: 0.8389\n",
      "\n",
      "Epoch 00074: val_acc improved from 0.83718 to 0.83891, saving model to best_model_g1.h5\n",
      "Epoch 75/200\n",
      "1083/1083 [==============================] - 11s 10ms/step - loss: 0.4589 - acc: 0.8096 - val_loss: 0.4193 - val_acc: 0.8357\n",
      "\n",
      "Epoch 00075: val_acc did not improve from 0.83891\n",
      "Epoch 76/200\n",
      "1083/1083 [==============================] - 11s 10ms/step - loss: 0.4623 - acc: 0.8095 - val_loss: 0.4189 - val_acc: 0.8352\n",
      "\n",
      "Epoch 00076: val_acc did not improve from 0.83891\n",
      "Epoch 77/200\n",
      "1083/1083 [==============================] - 11s 10ms/step - loss: 0.4613 - acc: 0.8089 - val_loss: 0.4250 - val_acc: 0.8331\n",
      "\n",
      "Epoch 00077: val_acc did not improve from 0.83891\n",
      "Epoch 78/200\n",
      "1083/1083 [==============================] - 11s 10ms/step - loss: 0.4615 - acc: 0.8096 - val_loss: 0.4242 - val_acc: 0.8355\n",
      "\n",
      "Epoch 00078: val_acc did not improve from 0.83891\n",
      "Epoch 79/200\n",
      "1083/1083 [==============================] - 11s 10ms/step - loss: 0.4624 - acc: 0.8089 - val_loss: 0.4279 - val_acc: 0.8342\n",
      "\n",
      "Epoch 00079: val_acc did not improve from 0.83891\n",
      "Epoch 80/200\n",
      "1083/1083 [==============================] - 11s 10ms/step - loss: 0.4589 - acc: 0.8106 - val_loss: 0.4222 - val_acc: 0.8374\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00080: val_acc did not improve from 0.83891\n",
      "Epoch 81/200\n",
      "1083/1083 [==============================] - 11s 10ms/step - loss: 0.4589 - acc: 0.8100 - val_loss: 0.4133 - val_acc: 0.8380\n",
      "\n",
      "Epoch 00081: val_acc did not improve from 0.83891\n",
      "Epoch 82/200\n",
      "1083/1083 [==============================] - 11s 10ms/step - loss: 0.4576 - acc: 0.8111 - val_loss: 0.4187 - val_acc: 0.8356\n",
      "\n",
      "Epoch 00082: val_acc did not improve from 0.83891\n",
      "Epoch 83/200\n",
      "1083/1083 [==============================] - 11s 10ms/step - loss: 0.4557 - acc: 0.8125 - val_loss: 0.4152 - val_acc: 0.8380\n",
      "\n",
      "Epoch 00083: val_acc did not improve from 0.83891\n",
      "Epoch 84/200\n",
      "1083/1083 [==============================] - 11s 10ms/step - loss: 0.4569 - acc: 0.8124 - val_loss: 0.4163 - val_acc: 0.8365\n",
      "\n",
      "Epoch 00084: val_acc did not improve from 0.83891\n",
      "Epoch 85/200\n",
      "1083/1083 [==============================] - 11s 10ms/step - loss: 0.4577 - acc: 0.8104 - val_loss: 0.4175 - val_acc: 0.8367\n",
      "\n",
      "Epoch 00085: val_acc did not improve from 0.83891\n",
      "Epoch 86/200\n",
      "1083/1083 [==============================] - 11s 10ms/step - loss: 0.4550 - acc: 0.8123 - val_loss: 0.4195 - val_acc: 0.8371\n",
      "\n",
      "Epoch 00086: val_acc did not improve from 0.83891\n",
      "Epoch 87/200\n",
      "1083/1083 [==============================] - 11s 10ms/step - loss: 0.4554 - acc: 0.8118 - val_loss: 0.4267 - val_acc: 0.8319\n",
      "\n",
      "Epoch 00087: val_acc did not improve from 0.83891\n",
      "Epoch 88/200\n",
      "1083/1083 [==============================] - 11s 10ms/step - loss: 0.4541 - acc: 0.8136 - val_loss: 0.4176 - val_acc: 0.8356\n",
      "\n",
      "Epoch 00088: val_acc did not improve from 0.83891\n",
      "Epoch 89/200\n",
      "1083/1083 [==============================] - 11s 10ms/step - loss: 0.4556 - acc: 0.8115 - val_loss: 0.4175 - val_acc: 0.8376\n",
      "\n",
      "Epoch 00089: val_acc did not improve from 0.83891\n",
      "Epoch 90/200\n",
      "1083/1083 [==============================] - 11s 10ms/step - loss: 0.4533 - acc: 0.8129 - val_loss: 0.4121 - val_acc: 0.8389\n",
      "\n",
      "Epoch 00090: val_acc did not improve from 0.83891\n",
      "Epoch 91/200\n",
      "1083/1083 [==============================] - 11s 10ms/step - loss: 0.4535 - acc: 0.8125 - val_loss: 0.4169 - val_acc: 0.8368\n",
      "\n",
      "Epoch 00091: val_acc did not improve from 0.83891\n",
      "Epoch 92/200\n",
      "1083/1083 [==============================] - 11s 10ms/step - loss: 0.4553 - acc: 0.8116 - val_loss: 0.4153 - val_acc: 0.8399\n",
      "\n",
      "Epoch 00092: val_acc improved from 0.83891 to 0.83990, saving model to best_model_g1.h5\n",
      "Epoch 93/200\n",
      "1083/1083 [==============================] - 11s 10ms/step - loss: 0.4541 - acc: 0.8110 - val_loss: 0.4100 - val_acc: 0.8439\n",
      "\n",
      "Epoch 00093: val_acc improved from 0.83990 to 0.84388, saving model to best_model_g1.h5\n",
      "Epoch 94/200\n",
      "1083/1083 [==============================] - 11s 10ms/step - loss: 0.4549 - acc: 0.8116 - val_loss: 0.4217 - val_acc: 0.8365\n",
      "\n",
      "Epoch 00094: val_acc did not improve from 0.84388\n",
      "Epoch 95/200\n",
      "1083/1083 [==============================] - 11s 10ms/step - loss: 0.4507 - acc: 0.8129 - val_loss: 0.4084 - val_acc: 0.8434\n",
      "\n",
      "Epoch 00095: val_acc did not improve from 0.84388\n",
      "Epoch 96/200\n",
      "1083/1083 [==============================] - 11s 10ms/step - loss: 0.4537 - acc: 0.8146 - val_loss: 0.4210 - val_acc: 0.8369\n",
      "\n",
      "Epoch 00096: val_acc did not improve from 0.84388\n",
      "Epoch 97/200\n",
      "1083/1083 [==============================] - 11s 10ms/step - loss: 0.4547 - acc: 0.8120 - val_loss: 0.4074 - val_acc: 0.8436\n",
      "\n",
      "Epoch 00097: val_acc did not improve from 0.84388\n",
      "Epoch 98/200\n",
      "1083/1083 [==============================] - 11s 10ms/step - loss: 0.4528 - acc: 0.8145 - val_loss: 0.4151 - val_acc: 0.8397\n",
      "\n",
      "Epoch 00098: val_acc did not improve from 0.84388\n",
      "Epoch 99/200\n",
      "1083/1083 [==============================] - 11s 10ms/step - loss: 0.4488 - acc: 0.8162 - val_loss: 0.4114 - val_acc: 0.8409\n",
      "\n",
      "Epoch 00099: val_acc did not improve from 0.84388\n",
      "Epoch 100/200\n",
      "1083/1083 [==============================] - 11s 10ms/step - loss: 0.4505 - acc: 0.8155 - val_loss: 0.4125 - val_acc: 0.8420\n",
      "\n",
      "Epoch 00100: val_acc did not improve from 0.84388\n",
      "Epoch 101/200\n",
      "1083/1083 [==============================] - 11s 10ms/step - loss: 0.4497 - acc: 0.8152 - val_loss: 0.4063 - val_acc: 0.8413\n",
      "\n",
      "Epoch 00101: val_acc did not improve from 0.84388\n",
      "Epoch 102/200\n",
      "1083/1083 [==============================] - 11s 10ms/step - loss: 0.4487 - acc: 0.8157 - val_loss: 0.4145 - val_acc: 0.8395\n",
      "\n",
      "Epoch 00102: val_acc did not improve from 0.84388\n",
      "Epoch 103/200\n",
      "1083/1083 [==============================] - 11s 10ms/step - loss: 0.4534 - acc: 0.8134 - val_loss: 0.4052 - val_acc: 0.8416\n",
      "\n",
      "Epoch 00103: val_acc did not improve from 0.84388\n",
      "Epoch 104/200\n",
      "1083/1083 [==============================] - 11s 10ms/step - loss: 0.4468 - acc: 0.8155 - val_loss: 0.4165 - val_acc: 0.8382\n",
      "\n",
      "Epoch 00104: val_acc did not improve from 0.84388\n",
      "Epoch 105/200\n",
      "1083/1083 [==============================] - 11s 10ms/step - loss: 0.4468 - acc: 0.8162 - val_loss: 0.4102 - val_acc: 0.8390\n",
      "\n",
      "Epoch 00105: val_acc did not improve from 0.84388\n",
      "Epoch 106/200\n",
      "1083/1083 [==============================] - 11s 10ms/step - loss: 0.4485 - acc: 0.8169 - val_loss: 0.4145 - val_acc: 0.8389\n",
      "\n",
      "Epoch 00106: val_acc did not improve from 0.84388\n",
      "Epoch 107/200\n",
      "1083/1083 [==============================] - 11s 10ms/step - loss: 0.4491 - acc: 0.8161 - val_loss: 0.4120 - val_acc: 0.8363\n",
      "\n",
      "Epoch 00107: val_acc did not improve from 0.84388\n",
      "Epoch 108/200\n",
      "1083/1083 [==============================] - 11s 10ms/step - loss: 0.4459 - acc: 0.8153 - val_loss: 0.4067 - val_acc: 0.8395\n",
      "\n",
      "Epoch 00108: val_acc did not improve from 0.84388\n",
      "Epoch 109/200\n",
      "1083/1083 [==============================] - 11s 10ms/step - loss: 0.4454 - acc: 0.8177 - val_loss: 0.4086 - val_acc: 0.8392\n",
      "\n",
      "Epoch 00109: val_acc did not improve from 0.84388\n",
      "Epoch 110/200\n",
      "1083/1083 [==============================] - 11s 10ms/step - loss: 0.4484 - acc: 0.8158 - val_loss: 0.4017 - val_acc: 0.8442\n",
      "\n",
      "Epoch 00110: val_acc improved from 0.84388 to 0.84417, saving model to best_model_g1.h5\n",
      "Epoch 111/200\n",
      "1083/1083 [==============================] - 11s 10ms/step - loss: 0.4464 - acc: 0.8176 - val_loss: 0.4163 - val_acc: 0.8393\n",
      "\n",
      "Epoch 00111: val_acc did not improve from 0.84417\n",
      "Epoch 112/200\n",
      "1083/1083 [==============================] - 11s 10ms/step - loss: 0.4434 - acc: 0.8174 - val_loss: 0.4113 - val_acc: 0.8421\n",
      "\n",
      "Epoch 00112: val_acc did not improve from 0.84417\n",
      "Epoch 113/200\n",
      "1083/1083 [==============================] - 11s 10ms/step - loss: 0.4485 - acc: 0.8151 - val_loss: 0.4100 - val_acc: 0.8409\n",
      "\n",
      "Epoch 00113: val_acc did not improve from 0.84417\n",
      "Epoch 114/200\n",
      "1083/1083 [==============================] - 11s 10ms/step - loss: 0.4475 - acc: 0.8147 - val_loss: 0.4084 - val_acc: 0.8413\n",
      "\n",
      "Epoch 00114: val_acc did not improve from 0.84417\n",
      "Epoch 115/200\n",
      "1083/1083 [==============================] - 11s 10ms/step - loss: 0.4436 - acc: 0.8178 - val_loss: 0.4033 - val_acc: 0.8446\n",
      "\n",
      "Epoch 00115: val_acc improved from 0.84417 to 0.84463, saving model to best_model_g1.h5\n",
      "Epoch 116/200\n",
      "1083/1083 [==============================] - 11s 10ms/step - loss: 0.4438 - acc: 0.8183 - val_loss: 0.4083 - val_acc: 0.8421\n",
      "\n",
      "Epoch 00116: val_acc did not improve from 0.84463\n",
      "Epoch 117/200\n",
      "1083/1083 [==============================] - 11s 10ms/step - loss: 0.4461 - acc: 0.8154 - val_loss: 0.4121 - val_acc: 0.8406\n",
      "\n",
      "Epoch 00117: val_acc did not improve from 0.84463\n",
      "Epoch 118/200\n",
      "1083/1083 [==============================] - 11s 10ms/step - loss: 0.4425 - acc: 0.8185 - val_loss: 0.4066 - val_acc: 0.8434\n",
      "\n",
      "Epoch 00118: val_acc did not improve from 0.84463\n",
      "Epoch 119/200\n",
      "1083/1083 [==============================] - 11s 10ms/step - loss: 0.4440 - acc: 0.8169 - val_loss: 0.4168 - val_acc: 0.8381\n",
      "\n",
      "Epoch 00119: val_acc did not improve from 0.84463\n",
      "Epoch 120/200\n",
      "1083/1083 [==============================] - 11s 10ms/step - loss: 0.4415 - acc: 0.8187 - val_loss: 0.4062 - val_acc: 0.8447\n",
      "\n",
      "Epoch 00120: val_acc improved from 0.84463 to 0.84469, saving model to best_model_g1.h5\n",
      "Epoch 121/200\n",
      "1083/1083 [==============================] - 11s 10ms/step - loss: 0.4388 - acc: 0.8194 - val_loss: 0.4093 - val_acc: 0.8447\n",
      "\n",
      "Epoch 00121: val_acc improved from 0.84469 to 0.84475, saving model to best_model_g1.h5\n",
      "Epoch 122/200\n",
      "1083/1083 [==============================] - 11s 10ms/step - loss: 0.4429 - acc: 0.8195 - val_loss: 0.4013 - val_acc: 0.8486\n",
      "\n",
      "Epoch 00122: val_acc improved from 0.84475 to 0.84856, saving model to best_model_g1.h5\n",
      "Epoch 123/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1083/1083 [==============================] - 11s 10ms/step - loss: 0.4462 - acc: 0.8161 - val_loss: 0.4054 - val_acc: 0.8431\n",
      "\n",
      "Epoch 00123: val_acc did not improve from 0.84856\n",
      "Epoch 124/200\n",
      "1083/1083 [==============================] - 11s 10ms/step - loss: 0.4441 - acc: 0.8174 - val_loss: 0.3987 - val_acc: 0.8472\n",
      "\n",
      "Epoch 00124: val_acc did not improve from 0.84856\n",
      "Epoch 125/200\n",
      "1083/1083 [==============================] - 11s 10ms/step - loss: 0.4416 - acc: 0.8176 - val_loss: 0.4006 - val_acc: 0.8457\n",
      "\n",
      "Epoch 00125: val_acc did not improve from 0.84856\n",
      "Epoch 126/200\n",
      "1083/1083 [==============================] - 11s 10ms/step - loss: 0.4420 - acc: 0.8189 - val_loss: 0.3981 - val_acc: 0.8465\n",
      "\n",
      "Epoch 00126: val_acc did not improve from 0.84856\n",
      "Epoch 127/200\n",
      "1083/1083 [==============================] - 11s 10ms/step - loss: 0.4440 - acc: 0.8181 - val_loss: 0.4059 - val_acc: 0.8447\n",
      "\n",
      "Epoch 00127: val_acc did not improve from 0.84856\n",
      "Epoch 128/200\n",
      "1083/1083 [==============================] - 11s 10ms/step - loss: 0.4419 - acc: 0.8202 - val_loss: 0.4040 - val_acc: 0.8453\n",
      "\n",
      "Epoch 00128: val_acc did not improve from 0.84856\n",
      "Epoch 129/200\n",
      "1083/1083 [==============================] - 11s 10ms/step - loss: 0.4440 - acc: 0.8184 - val_loss: 0.4040 - val_acc: 0.8438\n",
      "\n",
      "Epoch 00129: val_acc did not improve from 0.84856\n",
      "Epoch 130/200\n",
      "1083/1083 [==============================] - 11s 10ms/step - loss: 0.4410 - acc: 0.8187 - val_loss: 0.3912 - val_acc: 0.8482\n",
      "\n",
      "Epoch 00130: val_acc did not improve from 0.84856\n",
      "Epoch 131/200\n",
      "1083/1083 [==============================] - 11s 10ms/step - loss: 0.4377 - acc: 0.8201 - val_loss: 0.4103 - val_acc: 0.8451\n",
      "\n",
      "Epoch 00131: val_acc did not improve from 0.84856\n",
      "Epoch 132/200\n",
      "1083/1083 [==============================] - 11s 10ms/step - loss: 0.4396 - acc: 0.8193 - val_loss: 0.3971 - val_acc: 0.8494\n",
      "\n",
      "Epoch 00132: val_acc improved from 0.84856 to 0.84942, saving model to best_model_g1.h5\n",
      "Epoch 133/200\n",
      "1083/1083 [==============================] - 11s 10ms/step - loss: 0.4406 - acc: 0.8191 - val_loss: 0.3962 - val_acc: 0.8450\n",
      "\n",
      "Epoch 00133: val_acc did not improve from 0.84942\n",
      "Epoch 134/200\n",
      "1083/1083 [==============================] - 11s 10ms/step - loss: 0.4395 - acc: 0.8215 - val_loss: 0.4046 - val_acc: 0.8458\n",
      "\n",
      "Epoch 00134: val_acc did not improve from 0.84942\n",
      "Epoch 135/200\n",
      "1083/1083 [==============================] - 11s 10ms/step - loss: 0.4397 - acc: 0.8195 - val_loss: 0.3961 - val_acc: 0.8476\n",
      "\n",
      "Epoch 00135: val_acc did not improve from 0.84942\n",
      "Epoch 136/200\n",
      "1083/1083 [==============================] - 11s 10ms/step - loss: 0.4407 - acc: 0.8217 - val_loss: 0.3984 - val_acc: 0.8458\n",
      "\n",
      "Epoch 00136: val_acc did not improve from 0.84942\n",
      "Epoch 137/200\n",
      "1083/1083 [==============================] - 11s 10ms/step - loss: 0.4403 - acc: 0.8194 - val_loss: 0.4003 - val_acc: 0.8454\n",
      "\n",
      "Epoch 00137: val_acc did not improve from 0.84942\n",
      "Epoch 138/200\n",
      "1083/1083 [==============================] - 11s 10ms/step - loss: 0.4398 - acc: 0.8178 - val_loss: 0.4036 - val_acc: 0.8467\n",
      "\n",
      "Epoch 00138: val_acc did not improve from 0.84942\n",
      "Epoch 139/200\n",
      "1083/1083 [==============================] - 11s 10ms/step - loss: 0.4365 - acc: 0.8211 - val_loss: 0.4006 - val_acc: 0.8458\n",
      "\n",
      "Epoch 00139: val_acc did not improve from 0.84942\n",
      "Epoch 140/200\n",
      "1083/1083 [==============================] - 11s 10ms/step - loss: 0.4381 - acc: 0.8194 - val_loss: 0.4047 - val_acc: 0.8421\n",
      "\n",
      "Epoch 00140: val_acc did not improve from 0.84942\n",
      "Epoch 141/200\n",
      "1083/1083 [==============================] - 11s 10ms/step - loss: 0.4340 - acc: 0.8225 - val_loss: 0.4070 - val_acc: 0.8405\n",
      "\n",
      "Epoch 00141: val_acc did not improve from 0.84942\n",
      "Epoch 142/200\n",
      "1083/1083 [==============================] - 11s 10ms/step - loss: 0.4385 - acc: 0.8211 - val_loss: 0.4146 - val_acc: 0.8370\n",
      "\n",
      "Epoch 00142: val_acc did not improve from 0.84942\n",
      "Epoch 143/200\n",
      "1083/1083 [==============================] - 11s 10ms/step - loss: 0.4372 - acc: 0.8215 - val_loss: 0.3992 - val_acc: 0.8429\n",
      "\n",
      "Epoch 00143: val_acc did not improve from 0.84942\n",
      "Epoch 144/200\n",
      "1083/1083 [==============================] - 11s 10ms/step - loss: 0.4416 - acc: 0.8204 - val_loss: 0.4044 - val_acc: 0.8439\n",
      "\n",
      "Epoch 00144: val_acc did not improve from 0.84942\n",
      "Epoch 145/200\n",
      "1083/1083 [==============================] - 11s 10ms/step - loss: 0.4389 - acc: 0.8198 - val_loss: 0.4022 - val_acc: 0.8456\n",
      "\n",
      "Epoch 00145: val_acc did not improve from 0.84942\n",
      "Epoch 146/200\n",
      "1083/1083 [==============================] - 11s 10ms/step - loss: 0.4415 - acc: 0.8195 - val_loss: 0.4015 - val_acc: 0.8461\n",
      "\n",
      "Epoch 00146: val_acc did not improve from 0.84942\n",
      "Epoch 147/200\n",
      "1083/1083 [==============================] - 11s 10ms/step - loss: 0.4380 - acc: 0.8198 - val_loss: 0.3961 - val_acc: 0.8452\n",
      "\n",
      "Epoch 00147: val_acc did not improve from 0.84942\n",
      "Epoch 148/200\n",
      "1083/1083 [==============================] - 11s 10ms/step - loss: 0.4353 - acc: 0.8217 - val_loss: 0.4114 - val_acc: 0.8406\n",
      "\n",
      "Epoch 00148: val_acc did not improve from 0.84942\n",
      "Epoch 149/200\n",
      "1083/1083 [==============================] - 11s 10ms/step - loss: 0.4355 - acc: 0.8219 - val_loss: 0.4171 - val_acc: 0.8375\n",
      "\n",
      "Epoch 00149: val_acc did not improve from 0.84942\n",
      "Epoch 150/200\n",
      "1083/1083 [==============================] - 11s 10ms/step - loss: 0.4369 - acc: 0.8200 - val_loss: 0.3921 - val_acc: 0.8497\n",
      "\n",
      "Epoch 00150: val_acc improved from 0.84942 to 0.84971, saving model to best_model_g1.h5\n",
      "Epoch 151/200\n",
      "1083/1083 [==============================] - 11s 10ms/step - loss: 0.4333 - acc: 0.8227 - val_loss: 0.3985 - val_acc: 0.8465\n",
      "\n",
      "Epoch 00151: val_acc did not improve from 0.84971\n",
      "Epoch 152/200\n",
      "1083/1083 [==============================] - 11s 10ms/step - loss: 0.4351 - acc: 0.8212 - val_loss: 0.3966 - val_acc: 0.8462\n",
      "\n",
      "Epoch 00152: val_acc did not improve from 0.84971\n",
      "Epoch 153/200\n",
      "1083/1083 [==============================] - 11s 10ms/step - loss: 0.4353 - acc: 0.8215 - val_loss: 0.4013 - val_acc: 0.8473\n",
      "\n",
      "Epoch 00153: val_acc did not improve from 0.84971\n",
      "Epoch 154/200\n",
      "1083/1083 [==============================] - 11s 10ms/step - loss: 0.4350 - acc: 0.8225 - val_loss: 0.3901 - val_acc: 0.8505\n",
      "\n",
      "Epoch 00154: val_acc improved from 0.84971 to 0.85052, saving model to best_model_g1.h5\n",
      "Epoch 155/200\n",
      "1083/1083 [==============================] - 11s 10ms/step - loss: 0.4359 - acc: 0.8217 - val_loss: 0.3953 - val_acc: 0.8486\n",
      "\n",
      "Epoch 00155: val_acc did not improve from 0.85052\n",
      "Epoch 156/200\n",
      "1083/1083 [==============================] - 11s 10ms/step - loss: 0.4345 - acc: 0.8218 - val_loss: 0.3980 - val_acc: 0.8476\n",
      "\n",
      "Epoch 00156: val_acc did not improve from 0.85052\n",
      "Epoch 157/200\n",
      "1083/1083 [==============================] - 11s 10ms/step - loss: 0.4340 - acc: 0.8209 - val_loss: 0.4231 - val_acc: 0.8357\n",
      "\n",
      "Epoch 00157: val_acc did not improve from 0.85052\n",
      "Epoch 158/200\n",
      "1083/1083 [==============================] - 11s 10ms/step - loss: 0.4341 - acc: 0.8222 - val_loss: 0.3868 - val_acc: 0.8508\n",
      "\n",
      "Epoch 00158: val_acc improved from 0.85052 to 0.85081, saving model to best_model_g1.h5\n",
      "Epoch 159/200\n",
      "1083/1083 [==============================] - 12s 11ms/step - loss: 0.4350 - acc: 0.8210 - val_loss: 0.3892 - val_acc: 0.8490\n",
      "\n",
      "Epoch 00159: val_acc did not improve from 0.85081\n",
      "Epoch 160/200\n",
      "1083/1083 [==============================] - 11s 10ms/step - loss: 0.4359 - acc: 0.8211 - val_loss: 0.3960 - val_acc: 0.8490\n",
      "\n",
      "Epoch 00160: val_acc did not improve from 0.85081\n",
      "Epoch 161/200\n",
      "1083/1083 [==============================] - 11s 10ms/step - loss: 0.4320 - acc: 0.8235 - val_loss: 0.4051 - val_acc: 0.8431\n",
      "\n",
      "Epoch 00161: val_acc did not improve from 0.85081\n",
      "Epoch 162/200\n",
      "1083/1083 [==============================] - 11s 10ms/step - loss: 0.4344 - acc: 0.8233 - val_loss: 0.4028 - val_acc: 0.8454\n",
      "\n",
      "Epoch 00162: val_acc did not improve from 0.85081\n",
      "Epoch 163/200\n",
      "1083/1083 [==============================] - 11s 10ms/step - loss: 0.4343 - acc: 0.8228 - val_loss: 0.3966 - val_acc: 0.8472\n",
      "\n",
      "Epoch 00163: val_acc did not improve from 0.85081\n",
      "Epoch 164/200\n",
      "1083/1083 [==============================] - 11s 10ms/step - loss: 0.4307 - acc: 0.8257 - val_loss: 0.3831 - val_acc: 0.8533\n",
      "\n",
      "Epoch 00164: val_acc improved from 0.85081 to 0.85329, saving model to best_model_g1.h5\n",
      "Epoch 165/200\n",
      "1083/1083 [==============================] - 11s 10ms/step - loss: 0.4353 - acc: 0.8226 - val_loss: 0.4074 - val_acc: 0.8430\n",
      "\n",
      "Epoch 00165: val_acc did not improve from 0.85329\n",
      "Epoch 166/200\n",
      "1083/1083 [==============================] - 11s 10ms/step - loss: 0.4311 - acc: 0.8242 - val_loss: 0.3931 - val_acc: 0.8513\n",
      "\n",
      "Epoch 00166: val_acc did not improve from 0.85329\n",
      "Epoch 167/200\n",
      "1083/1083 [==============================] - 11s 10ms/step - loss: 0.4323 - acc: 0.8228 - val_loss: 0.4045 - val_acc: 0.8472\n",
      "\n",
      "Epoch 00167: val_acc did not improve from 0.85329\n",
      "Epoch 168/200\n",
      "1083/1083 [==============================] - 11s 10ms/step - loss: 0.4348 - acc: 0.8223 - val_loss: 0.3965 - val_acc: 0.8480\n",
      "\n",
      "Epoch 00168: val_acc did not improve from 0.85329\n",
      "Epoch 169/200\n",
      "1083/1083 [==============================] - 11s 10ms/step - loss: 0.4316 - acc: 0.8233 - val_loss: 0.3875 - val_acc: 0.8531\n",
      "\n",
      "Epoch 00169: val_acc did not improve from 0.85329\n",
      "Epoch 170/200\n",
      "1083/1083 [==============================] - 11s 10ms/step - loss: 0.4318 - acc: 0.8220 - val_loss: 0.3996 - val_acc: 0.8483\n",
      "\n",
      "Epoch 00170: val_acc did not improve from 0.85329\n",
      "Epoch 171/200\n",
      "1083/1083 [==============================] - 11s 10ms/step - loss: 0.4322 - acc: 0.8236 - val_loss: 0.3960 - val_acc: 0.8490\n",
      "\n",
      "Epoch 00171: val_acc did not improve from 0.85329\n",
      "Epoch 172/200\n",
      "1083/1083 [==============================] - 11s 10ms/step - loss: 0.4329 - acc: 0.8244 - val_loss: 0.3904 - val_acc: 0.8497\n",
      "\n",
      "Epoch 00172: val_acc did not improve from 0.85329\n",
      "Epoch 173/200\n",
      "1083/1083 [==============================] - 11s 10ms/step - loss: 0.4302 - acc: 0.8236 - val_loss: 0.4038 - val_acc: 0.8445\n",
      "\n",
      "Epoch 00173: val_acc did not improve from 0.85329\n",
      "Epoch 174/200\n",
      "1083/1083 [==============================] - 11s 10ms/step - loss: 0.4287 - acc: 0.8247 - val_loss: 0.3914 - val_acc: 0.8491\n",
      "\n",
      "Epoch 00174: val_acc did not improve from 0.85329\n",
      "Epoch 175/200\n",
      "1083/1083 [==============================] - 11s 10ms/step - loss: 0.4292 - acc: 0.8247 - val_loss: 0.3950 - val_acc: 0.8472\n",
      "\n",
      "Epoch 00175: val_acc did not improve from 0.85329\n",
      "Epoch 176/200\n",
      "1083/1083 [==============================] - 11s 10ms/step - loss: 0.4279 - acc: 0.8251 - val_loss: 0.3907 - val_acc: 0.8486\n",
      "\n",
      "Epoch 00176: val_acc did not improve from 0.85329\n",
      "Epoch 177/200\n",
      "1083/1083 [==============================] - 11s 10ms/step - loss: 0.4327 - acc: 0.8229 - val_loss: 0.3956 - val_acc: 0.8500\n",
      "\n",
      "Epoch 00177: val_acc did not improve from 0.85329\n",
      "Epoch 178/200\n",
      "1083/1083 [==============================] - 11s 10ms/step - loss: 0.4297 - acc: 0.8243 - val_loss: 0.4011 - val_acc: 0.8461\n",
      "\n",
      "Epoch 00178: val_acc did not improve from 0.85329\n",
      "Epoch 179/200\n",
      "1083/1083 [==============================] - 11s 10ms/step - loss: 0.4314 - acc: 0.8246 - val_loss: 0.3897 - val_acc: 0.8525\n",
      "\n",
      "Epoch 00179: val_acc did not improve from 0.85329\n",
      "Epoch 180/200\n",
      "1083/1083 [==============================] - 11s 10ms/step - loss: 0.4288 - acc: 0.8257 - val_loss: 0.3996 - val_acc: 0.8452\n",
      "\n",
      "Epoch 00180: val_acc did not improve from 0.85329\n",
      "Epoch 181/200\n",
      "1083/1083 [==============================] - 11s 10ms/step - loss: 0.4256 - acc: 0.8269 - val_loss: 0.3963 - val_acc: 0.8483\n",
      "\n",
      "Epoch 00181: val_acc did not improve from 0.85329\n",
      "Epoch 182/200\n",
      "1083/1083 [==============================] - 11s 10ms/step - loss: 0.4311 - acc: 0.8234 - val_loss: 0.3862 - val_acc: 0.8543\n",
      "\n",
      "Epoch 00182: val_acc improved from 0.85329 to 0.85433, saving model to best_model_g1.h5\n",
      "Epoch 183/200\n",
      "1083/1083 [==============================] - 11s 10ms/step - loss: 0.4286 - acc: 0.8243 - val_loss: 0.3953 - val_acc: 0.8483\n",
      "\n",
      "Epoch 00183: val_acc did not improve from 0.85433\n",
      "Epoch 184/200\n",
      "1083/1083 [==============================] - 11s 10ms/step - loss: 0.4300 - acc: 0.8234 - val_loss: 0.3994 - val_acc: 0.8460\n",
      "\n",
      "Epoch 00184: val_acc did not improve from 0.85433\n",
      "Epoch 185/200\n",
      "1083/1083 [==============================] - 11s 10ms/step - loss: 0.4322 - acc: 0.8240 - val_loss: 0.3834 - val_acc: 0.8532\n",
      "\n",
      "Epoch 00185: val_acc did not improve from 0.85433\n",
      "Epoch 186/200\n",
      "1083/1083 [==============================] - 11s 10ms/step - loss: 0.4289 - acc: 0.8230 - val_loss: 0.3982 - val_acc: 0.8487\n",
      "\n",
      "Epoch 00186: val_acc did not improve from 0.85433\n",
      "Epoch 187/200\n",
      "1083/1083 [==============================] - 11s 10ms/step - loss: 0.4272 - acc: 0.8258 - val_loss: 0.3838 - val_acc: 0.8542\n",
      "\n",
      "Epoch 00187: val_acc did not improve from 0.85433\n",
      "Epoch 188/200\n",
      "1083/1083 [==============================] - 11s 10ms/step - loss: 0.4283 - acc: 0.8271 - val_loss: 0.3863 - val_acc: 0.8510\n",
      "\n",
      "Epoch 00188: val_acc did not improve from 0.85433\n",
      "Epoch 189/200\n",
      "1083/1083 [==============================] - 11s 10ms/step - loss: 0.4271 - acc: 0.8262 - val_loss: 0.3902 - val_acc: 0.8502\n",
      "\n",
      "Epoch 00189: val_acc did not improve from 0.85433\n",
      "Epoch 190/200\n",
      "1083/1083 [==============================] - 11s 10ms/step - loss: 0.4313 - acc: 0.8231 - val_loss: 0.3950 - val_acc: 0.8457\n",
      "\n",
      "Epoch 00190: val_acc did not improve from 0.85433\n",
      "Epoch 191/200\n",
      "1083/1083 [==============================] - 11s 10ms/step - loss: 0.4270 - acc: 0.8273 - val_loss: 0.3898 - val_acc: 0.8478\n",
      "\n",
      "Epoch 00191: val_acc did not improve from 0.85433\n",
      "Epoch 192/200\n",
      "1083/1083 [==============================] - 11s 10ms/step - loss: 0.4280 - acc: 0.8240 - val_loss: 0.3883 - val_acc: 0.8528\n",
      "\n",
      "Epoch 00192: val_acc did not improve from 0.85433\n",
      "Epoch 193/200\n",
      "1083/1083 [==============================] - 11s 10ms/step - loss: 0.4228 - acc: 0.8271 - val_loss: 0.3963 - val_acc: 0.8491\n",
      "\n",
      "Epoch 00193: val_acc did not improve from 0.85433\n",
      "Epoch 194/200\n",
      "1083/1083 [==============================] - 11s 10ms/step - loss: 0.4281 - acc: 0.8254 - val_loss: 0.3976 - val_acc: 0.8471\n",
      "\n",
      "Epoch 00194: val_acc did not improve from 0.85433\n",
      "Epoch 195/200\n",
      "1083/1083 [==============================] - 11s 10ms/step - loss: 0.4272 - acc: 0.8259 - val_loss: 0.4050 - val_acc: 0.8438\n",
      "\n",
      "Epoch 00195: val_acc did not improve from 0.85433\n",
      "Epoch 196/200\n",
      "1083/1083 [==============================] - 11s 10ms/step - loss: 0.4291 - acc: 0.8229 - val_loss: 0.3865 - val_acc: 0.8516\n",
      "\n",
      "Epoch 00196: val_acc did not improve from 0.85433\n",
      "Epoch 197/200\n",
      "1083/1083 [==============================] - 11s 10ms/step - loss: 0.4287 - acc: 0.8253 - val_loss: 0.3914 - val_acc: 0.8490\n",
      "\n",
      "Epoch 00197: val_acc did not improve from 0.85433\n",
      "Epoch 198/200\n",
      "1083/1083 [==============================] - 11s 10ms/step - loss: 0.4253 - acc: 0.8251 - val_loss: 0.3909 - val_acc: 0.8513\n",
      "\n",
      "Epoch 00198: val_acc did not improve from 0.85433\n",
      "Epoch 199/200\n",
      "1083/1083 [==============================] - 11s 10ms/step - loss: 0.4268 - acc: 0.8260 - val_loss: 0.3902 - val_acc: 0.8484\n",
      "\n",
      "Epoch 00199: val_acc did not improve from 0.85433\n",
      "Epoch 200/200\n",
      "1083/1083 [==============================] - 11s 10ms/step - loss: 0.4286 - acc: 0.8247 - val_loss: 0.3951 - val_acc: 0.8480\n",
      "\n",
      "Epoch 00200: val_acc did not improve from 0.85433\n",
      "CPU times: user 3h 16min 17s, sys: 20min 56s, total: 3h 37min 13s\n",
      "Wall time: 37min 9s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "mc1 = ModelCheckpoint('best_model_g1.h5', monitor='val_acc', mode='max', save_best_only=True,verbose=1)  \n",
    "history1 = model1.fit(X_train, y_train, batch_size=64, epochs=200, validation_split=0.2, verbose=1, callbacks=[mc1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "78008339",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('history_g1.json', 'w') as f:\n",
    "    json.dump(history1.history, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e4641c00",
   "metadata": {},
   "outputs": [],
   "source": [
    "model1.save('themodel_g1.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "976d49ed",
   "metadata": {},
   "source": [
    "## LSTM 2 Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "70acd36f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_4 (Embedding)      (None, 30, 300)           31476300  \n",
      "_________________________________________________________________\n",
      "lstm_6 (LSTM)                (None, 30, 64)            93440     \n",
      "_________________________________________________________________\n",
      "lstm_7 (LSTM)                (None, 30, 64)            33024     \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_4 (Glob (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 3)                 195       \n",
      "=================================================================\n",
      "Total params: 31,607,119\n",
      "Trainable params: 130,819\n",
      "Non-trainable params: 31,476,300\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model2=Sequential()\n",
    "model2.add(Embedding(size_of_vocabulary,embedding_dim,weights=[embedding_matrix],input_length=max_length,trainable=False))\n",
    "\n",
    "#Lstm layer\n",
    "model2.add(LSTM(UNITS,return_sequences=True,dropout=0.5))\n",
    "model2.add(LSTM(UNITS,return_sequences=True))\n",
    "\n",
    "#Global Maxpooling\n",
    "model2.add(GlobalMaxPooling1D())\n",
    "\n",
    "#Dense Layer\n",
    "model2.add(Dense(UNITS, activation='relu'))\n",
    "\n",
    "#Output layer 3 class\n",
    "model2.add(Dense(3,activation='softmax')) \n",
    "\n",
    "model2.compile(optimizer=Adam(learning_rate = lr), loss = 'sparse_categorical_crossentropy', metrics = ['acc']) \n",
    "print(model2.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "0a03d607",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4819      1\n",
       "46760     0\n",
       "17908     0\n",
       "88148     2\n",
       "101474    2\n",
       "         ..\n",
       "101797    2\n",
       "69811     1\n",
       "86616     2\n",
       "102733    2\n",
       "77480     1\n",
       "Name: sentiment, Length: 86596, dtype: int64"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "17f9f91e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "1083/1083 [==============================] - 21s 18ms/step - loss: 0.8247 - acc: 0.6198 - val_loss: 0.7534 - val_acc: 0.6662\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.66617, saving model to best_model_g2.h5\n",
      "Epoch 2/200\n",
      "1083/1083 [==============================] - 19s 17ms/step - loss: 0.7655 - acc: 0.6562 - val_loss: 0.7185 - val_acc: 0.6781\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.66617 to 0.67806, saving model to best_model_g2.h5\n",
      "Epoch 3/200\n",
      "1083/1083 [==============================] - 19s 18ms/step - loss: 0.7284 - acc: 0.6753 - val_loss: 0.6817 - val_acc: 0.6996\n",
      "\n",
      "Epoch 00003: val_acc improved from 0.67806 to 0.69960, saving model to best_model_g2.h5\n",
      "Epoch 4/200\n",
      "1083/1083 [==============================] - 19s 17ms/step - loss: 0.7004 - acc: 0.6888 - val_loss: 0.6556 - val_acc: 0.7121\n",
      "\n",
      "Epoch 00004: val_acc improved from 0.69960 to 0.71207, saving model to best_model_g2.h5\n",
      "Epoch 5/200\n",
      "1083/1083 [==============================] - 19s 17ms/step - loss: 0.6714 - acc: 0.7048 - val_loss: 0.6318 - val_acc: 0.7278\n",
      "\n",
      "Epoch 00005: val_acc improved from 0.71207 to 0.72783, saving model to best_model_g2.h5\n",
      "Epoch 6/200\n",
      "1083/1083 [==============================] - 19s 17ms/step - loss: 0.6483 - acc: 0.7170 - val_loss: 0.6051 - val_acc: 0.7415\n",
      "\n",
      "Epoch 00006: val_acc improved from 0.72783 to 0.74151, saving model to best_model_g2.h5\n",
      "Epoch 7/200\n",
      "1083/1083 [==============================] - 19s 17ms/step - loss: 0.6266 - acc: 0.7262 - val_loss: 0.5912 - val_acc: 0.7498\n",
      "\n",
      "Epoch 00007: val_acc improved from 0.74151 to 0.74977, saving model to best_model_g2.h5\n",
      "Epoch 8/200\n",
      "1083/1083 [==============================] - 19s 17ms/step - loss: 0.6099 - acc: 0.7361 - val_loss: 0.5693 - val_acc: 0.7637\n",
      "\n",
      "Epoch 00008: val_acc improved from 0.74977 to 0.76374, saving model to best_model_g2.h5\n",
      "Epoch 9/200\n",
      "1083/1083 [==============================] - 19s 17ms/step - loss: 0.5975 - acc: 0.7431 - val_loss: 0.5589 - val_acc: 0.7653\n",
      "\n",
      "Epoch 00009: val_acc improved from 0.76374 to 0.76530, saving model to best_model_g2.h5\n",
      "Epoch 10/200\n",
      "1083/1083 [==============================] - 19s 18ms/step - loss: 0.5831 - acc: 0.7497 - val_loss: 0.5435 - val_acc: 0.7744\n",
      "\n",
      "Epoch 00010: val_acc improved from 0.76530 to 0.77442, saving model to best_model_g2.h5\n",
      "Epoch 11/200\n",
      "1083/1083 [==============================] - 19s 17ms/step - loss: 0.5685 - acc: 0.7572 - val_loss: 0.5322 - val_acc: 0.7801\n",
      "\n",
      "Epoch 00011: val_acc improved from 0.77442 to 0.78008, saving model to best_model_g2.h5\n",
      "Epoch 12/200\n",
      "1083/1083 [==============================] - 19s 17ms/step - loss: 0.5569 - acc: 0.7636 - val_loss: 0.5266 - val_acc: 0.7846\n",
      "\n",
      "Epoch 00012: val_acc improved from 0.78008 to 0.78464, saving model to best_model_g2.h5\n",
      "Epoch 13/200\n",
      "1083/1083 [==============================] - 19s 17ms/step - loss: 0.5485 - acc: 0.7675 - val_loss: 0.5104 - val_acc: 0.7904\n",
      "\n",
      "Epoch 00013: val_acc improved from 0.78464 to 0.79036, saving model to best_model_g2.h5\n",
      "Epoch 14/200\n",
      "1083/1083 [==============================] - 19s 17ms/step - loss: 0.5411 - acc: 0.7695 - val_loss: 0.5011 - val_acc: 0.7990\n",
      "\n",
      "Epoch 00014: val_acc improved from 0.79036 to 0.79896, saving model to best_model_g2.h5\n",
      "Epoch 15/200\n",
      "1083/1083 [==============================] - 19s 18ms/step - loss: 0.5315 - acc: 0.7752 - val_loss: 0.4960 - val_acc: 0.7986\n",
      "\n",
      "Epoch 00015: val_acc did not improve from 0.79896\n",
      "Epoch 16/200\n",
      "1083/1083 [==============================] - 19s 17ms/step - loss: 0.5241 - acc: 0.7788 - val_loss: 0.4910 - val_acc: 0.8039\n",
      "\n",
      "Epoch 00016: val_acc improved from 0.79896 to 0.80387, saving model to best_model_g2.h5\n",
      "Epoch 17/200\n",
      "1083/1083 [==============================] - 19s 17ms/step - loss: 0.5218 - acc: 0.7803 - val_loss: 0.4834 - val_acc: 0.8060\n",
      "\n",
      "Epoch 00017: val_acc improved from 0.80387 to 0.80600, saving model to best_model_g2.h5\n",
      "Epoch 18/200\n",
      "1083/1083 [==============================] - 19s 17ms/step - loss: 0.5175 - acc: 0.7819 - val_loss: 0.4801 - val_acc: 0.8075\n",
      "\n",
      "Epoch 00018: val_acc improved from 0.80600 to 0.80751, saving model to best_model_g2.h5\n",
      "Epoch 19/200\n",
      "1083/1083 [==============================] - 19s 17ms/step - loss: 0.5025 - acc: 0.7909 - val_loss: 0.4698 - val_acc: 0.8147\n",
      "\n",
      "Epoch 00019: val_acc improved from 0.80751 to 0.81472, saving model to best_model_g2.h5\n",
      "Epoch 20/200\n",
      "1083/1083 [==============================] - 19s 17ms/step - loss: 0.5036 - acc: 0.7882 - val_loss: 0.4645 - val_acc: 0.8148\n",
      "\n",
      "Epoch 00020: val_acc improved from 0.81472 to 0.81478, saving model to best_model_g2.h5\n",
      "Epoch 21/200\n",
      "1083/1083 [==============================] - 19s 17ms/step - loss: 0.4978 - acc: 0.7909 - val_loss: 0.4586 - val_acc: 0.8166\n",
      "\n",
      "Epoch 00021: val_acc improved from 0.81478 to 0.81657, saving model to best_model_g2.h5\n",
      "Epoch 22/200\n",
      "1083/1083 [==============================] - 19s 17ms/step - loss: 0.4935 - acc: 0.7933 - val_loss: 0.4626 - val_acc: 0.8172\n",
      "\n",
      "Epoch 00022: val_acc improved from 0.81657 to 0.81721, saving model to best_model_g2.h5\n",
      "Epoch 23/200\n",
      "1083/1083 [==============================] - 19s 17ms/step - loss: 0.4884 - acc: 0.7961 - val_loss: 0.4624 - val_acc: 0.8150\n",
      "\n",
      "Epoch 00023: val_acc did not improve from 0.81721\n",
      "Epoch 24/200\n",
      "1083/1083 [==============================] - 19s 17ms/step - loss: 0.4814 - acc: 0.7978 - val_loss: 0.4520 - val_acc: 0.8229\n",
      "\n",
      "Epoch 00024: val_acc improved from 0.81721 to 0.82292, saving model to best_model_g2.h5\n",
      "Epoch 25/200\n",
      "1083/1083 [==============================] - 19s 17ms/step - loss: 0.4786 - acc: 0.8006 - val_loss: 0.4513 - val_acc: 0.8200\n",
      "\n",
      "Epoch 00025: val_acc did not improve from 0.82292\n",
      "Epoch 26/200\n",
      "1083/1083 [==============================] - 19s 17ms/step - loss: 0.4733 - acc: 0.8037 - val_loss: 0.4440 - val_acc: 0.8252\n",
      "\n",
      "Epoch 00026: val_acc improved from 0.82292 to 0.82517, saving model to best_model_g2.h5\n",
      "Epoch 27/200\n",
      "1083/1083 [==============================] - 19s 18ms/step - loss: 0.4693 - acc: 0.8045 - val_loss: 0.4376 - val_acc: 0.8259\n",
      "\n",
      "Epoch 00027: val_acc improved from 0.82517 to 0.82587, saving model to best_model_g2.h5\n",
      "Epoch 28/200\n",
      "1083/1083 [==============================] - 20s 18ms/step - loss: 0.4677 - acc: 0.8047 - val_loss: 0.4321 - val_acc: 0.8289\n",
      "\n",
      "Epoch 00028: val_acc improved from 0.82587 to 0.82893, saving model to best_model_g2.h5\n",
      "Epoch 29/200\n",
      "1083/1083 [==============================] - 20s 18ms/step - loss: 0.4608 - acc: 0.8097 - val_loss: 0.4528 - val_acc: 0.8217\n",
      "\n",
      "Epoch 00029: val_acc did not improve from 0.82893\n",
      "Epoch 30/200\n",
      "1083/1083 [==============================] - 20s 18ms/step - loss: 0.4620 - acc: 0.8075 - val_loss: 0.4399 - val_acc: 0.8256\n",
      "\n",
      "Epoch 00030: val_acc did not improve from 0.82893\n",
      "Epoch 31/200\n",
      "1083/1083 [==============================] - 20s 18ms/step - loss: 0.4554 - acc: 0.8107 - val_loss: 0.4255 - val_acc: 0.8323\n",
      "\n",
      "Epoch 00031: val_acc improved from 0.82893 to 0.83227, saving model to best_model_g2.h5\n",
      "Epoch 32/200\n",
      "1083/1083 [==============================] - 20s 18ms/step - loss: 0.4534 - acc: 0.8138 - val_loss: 0.4255 - val_acc: 0.8311\n",
      "\n",
      "Epoch 00032: val_acc did not improve from 0.83227\n",
      "Epoch 33/200\n",
      "1083/1083 [==============================] - 20s 18ms/step - loss: 0.4465 - acc: 0.8163 - val_loss: 0.4221 - val_acc: 0.8335\n",
      "\n",
      "Epoch 00033: val_acc improved from 0.83227 to 0.83349, saving model to best_model_g2.h5\n",
      "Epoch 34/200\n",
      "1083/1083 [==============================] - 20s 18ms/step - loss: 0.4496 - acc: 0.8143 - val_loss: 0.4179 - val_acc: 0.8371\n",
      "\n",
      "Epoch 00034: val_acc improved from 0.83349 to 0.83707, saving model to best_model_g2.h5\n",
      "Epoch 35/200\n",
      "1083/1083 [==============================] - 20s 18ms/step - loss: 0.4433 - acc: 0.8167 - val_loss: 0.4262 - val_acc: 0.8307\n",
      "\n",
      "Epoch 00035: val_acc did not improve from 0.83707\n",
      "Epoch 36/200\n",
      "1083/1083 [==============================] - 20s 18ms/step - loss: 0.4450 - acc: 0.8166 - val_loss: 0.4242 - val_acc: 0.8329\n",
      "\n",
      "Epoch 00036: val_acc did not improve from 0.83707\n",
      "Epoch 37/200\n",
      "1083/1083 [==============================] - 20s 18ms/step - loss: 0.4430 - acc: 0.8165 - val_loss: 0.4205 - val_acc: 0.8333\n",
      "\n",
      "Epoch 00037: val_acc did not improve from 0.83707\n",
      "Epoch 38/200\n",
      "1083/1083 [==============================] - 20s 18ms/step - loss: 0.4385 - acc: 0.8180 - val_loss: 0.4186 - val_acc: 0.8330\n",
      "\n",
      "Epoch 00038: val_acc did not improve from 0.83707\n",
      "Epoch 39/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1083/1083 [==============================] - 20s 18ms/step - loss: 0.4357 - acc: 0.8227 - val_loss: 0.4158 - val_acc: 0.8368\n",
      "\n",
      "Epoch 00039: val_acc did not improve from 0.83707\n",
      "Epoch 40/200\n",
      "1083/1083 [==============================] - 20s 18ms/step - loss: 0.4361 - acc: 0.8190 - val_loss: 0.4125 - val_acc: 0.8396\n",
      "\n",
      "Epoch 00040: val_acc improved from 0.83707 to 0.83961, saving model to best_model_g2.h5\n",
      "Epoch 41/200\n",
      "1083/1083 [==============================] - 20s 18ms/step - loss: 0.4332 - acc: 0.8221 - val_loss: 0.4037 - val_acc: 0.8406\n",
      "\n",
      "Epoch 00041: val_acc improved from 0.83961 to 0.84059, saving model to best_model_g2.h5\n",
      "Epoch 42/200\n",
      "1083/1083 [==============================] - 20s 18ms/step - loss: 0.4293 - acc: 0.8225 - val_loss: 0.4235 - val_acc: 0.8310\n",
      "\n",
      "Epoch 00042: val_acc did not improve from 0.84059\n",
      "Epoch 43/200\n",
      "1083/1083 [==============================] - 20s 18ms/step - loss: 0.4283 - acc: 0.8240 - val_loss: 0.4060 - val_acc: 0.8398\n",
      "\n",
      "Epoch 00043: val_acc did not improve from 0.84059\n",
      "Epoch 44/200\n",
      "1083/1083 [==============================] - 20s 18ms/step - loss: 0.4273 - acc: 0.8234 - val_loss: 0.4036 - val_acc: 0.8406\n",
      "\n",
      "Epoch 00044: val_acc improved from 0.84059 to 0.84065, saving model to best_model_g2.h5\n",
      "Epoch 45/200\n",
      "1083/1083 [==============================] - 20s 18ms/step - loss: 0.4235 - acc: 0.8252 - val_loss: 0.4212 - val_acc: 0.8374\n",
      "\n",
      "Epoch 00045: val_acc did not improve from 0.84065\n",
      "Epoch 46/200\n",
      "1083/1083 [==============================] - 20s 18ms/step - loss: 0.4207 - acc: 0.8259 - val_loss: 0.4001 - val_acc: 0.8462\n",
      "\n",
      "Epoch 00046: val_acc improved from 0.84065 to 0.84619, saving model to best_model_g2.h5\n",
      "Epoch 47/200\n",
      "1083/1083 [==============================] - 19s 17ms/step - loss: 0.4201 - acc: 0.8274 - val_loss: 0.4093 - val_acc: 0.8391\n",
      "\n",
      "Epoch 00047: val_acc did not improve from 0.84619\n",
      "Epoch 48/200\n",
      "1083/1083 [==============================] - 19s 17ms/step - loss: 0.4192 - acc: 0.8284 - val_loss: 0.3976 - val_acc: 0.8458\n",
      "\n",
      "Epoch 00048: val_acc did not improve from 0.84619\n",
      "Epoch 49/200\n",
      "1083/1083 [==============================] - 19s 17ms/step - loss: 0.4167 - acc: 0.8297 - val_loss: 0.4034 - val_acc: 0.8450\n",
      "\n",
      "Epoch 00049: val_acc did not improve from 0.84619\n",
      "Epoch 50/200\n",
      "1083/1083 [==============================] - 19s 17ms/step - loss: 0.4158 - acc: 0.8293 - val_loss: 0.4007 - val_acc: 0.8477\n",
      "\n",
      "Epoch 00050: val_acc improved from 0.84619 to 0.84775, saving model to best_model_g2.h5\n",
      "Epoch 51/200\n",
      "1083/1083 [==============================] - 19s 18ms/step - loss: 0.4110 - acc: 0.8314 - val_loss: 0.4000 - val_acc: 0.8452\n",
      "\n",
      "Epoch 00051: val_acc did not improve from 0.84775\n",
      "Epoch 52/200\n",
      "1083/1083 [==============================] - 19s 17ms/step - loss: 0.4146 - acc: 0.8304 - val_loss: 0.3941 - val_acc: 0.8470\n",
      "\n",
      "Epoch 00052: val_acc did not improve from 0.84775\n",
      "Epoch 53/200\n",
      "1083/1083 [==============================] - 19s 17ms/step - loss: 0.4092 - acc: 0.8315 - val_loss: 0.3940 - val_acc: 0.8473\n",
      "\n",
      "Epoch 00053: val_acc did not improve from 0.84775\n",
      "Epoch 54/200\n",
      "1083/1083 [==============================] - 19s 17ms/step - loss: 0.4105 - acc: 0.8316 - val_loss: 0.3963 - val_acc: 0.8457\n",
      "\n",
      "Epoch 00054: val_acc did not improve from 0.84775\n",
      "Epoch 55/200\n",
      "1083/1083 [==============================] - 19s 17ms/step - loss: 0.4092 - acc: 0.8325 - val_loss: 0.4019 - val_acc: 0.8442\n",
      "\n",
      "Epoch 00055: val_acc did not improve from 0.84775\n",
      "Epoch 56/200\n",
      "1083/1083 [==============================] - 19s 17ms/step - loss: 0.4076 - acc: 0.8334 - val_loss: 0.3973 - val_acc: 0.8501\n",
      "\n",
      "Epoch 00056: val_acc improved from 0.84775 to 0.85006, saving model to best_model_g2.h5\n",
      "Epoch 57/200\n",
      "1083/1083 [==============================] - 19s 18ms/step - loss: 0.4016 - acc: 0.8354 - val_loss: 0.3873 - val_acc: 0.8518\n",
      "\n",
      "Epoch 00057: val_acc improved from 0.85006 to 0.85185, saving model to best_model_g2.h5\n",
      "Epoch 58/200\n",
      "1083/1083 [==============================] - 25s 23ms/step - loss: 0.4028 - acc: 0.8352 - val_loss: 0.3918 - val_acc: 0.8491\n",
      "\n",
      "Epoch 00058: val_acc did not improve from 0.85185\n",
      "Epoch 59/200\n",
      "1083/1083 [==============================] - 25s 23ms/step - loss: 0.4066 - acc: 0.8342 - val_loss: 0.3961 - val_acc: 0.8477\n",
      "\n",
      "Epoch 00059: val_acc did not improve from 0.85185\n",
      "Epoch 60/200\n",
      "1083/1083 [==============================] - 25s 23ms/step - loss: 0.3988 - acc: 0.8371 - val_loss: 0.3835 - val_acc: 0.8528\n",
      "\n",
      "Epoch 00060: val_acc improved from 0.85185 to 0.85283, saving model to best_model_g2.h5\n",
      "Epoch 61/200\n",
      "1083/1083 [==============================] - 25s 23ms/step - loss: 0.4002 - acc: 0.8376 - val_loss: 0.4031 - val_acc: 0.8449\n",
      "\n",
      "Epoch 00061: val_acc did not improve from 0.85283\n",
      "Epoch 62/200\n",
      "1083/1083 [==============================] - 25s 24ms/step - loss: 0.4001 - acc: 0.8353 - val_loss: 0.3877 - val_acc: 0.8530\n",
      "\n",
      "Epoch 00062: val_acc improved from 0.85283 to 0.85300, saving model to best_model_g2.h5\n",
      "Epoch 63/200\n",
      "1083/1083 [==============================] - 25s 23ms/step - loss: 0.3978 - acc: 0.8380 - val_loss: 0.3906 - val_acc: 0.8490\n",
      "\n",
      "Epoch 00063: val_acc did not improve from 0.85300\n",
      "Epoch 64/200\n",
      "1083/1083 [==============================] - 25s 23ms/step - loss: 0.3963 - acc: 0.8382 - val_loss: 0.3856 - val_acc: 0.8539\n",
      "\n",
      "Epoch 00064: val_acc improved from 0.85300 to 0.85393, saving model to best_model_g2.h5\n",
      "Epoch 65/200\n",
      "1083/1083 [==============================] - 25s 23ms/step - loss: 0.3939 - acc: 0.8379 - val_loss: 0.3990 - val_acc: 0.8486\n",
      "\n",
      "Epoch 00065: val_acc did not improve from 0.85393\n",
      "Epoch 66/200\n",
      "1083/1083 [==============================] - 25s 24ms/step - loss: 0.3911 - acc: 0.8414 - val_loss: 0.3974 - val_acc: 0.8482\n",
      "\n",
      "Epoch 00066: val_acc did not improve from 0.85393\n",
      "Epoch 67/200\n",
      "1083/1083 [==============================] - 25s 23ms/step - loss: 0.3916 - acc: 0.8416 - val_loss: 0.3887 - val_acc: 0.8536\n",
      "\n",
      "Epoch 00067: val_acc did not improve from 0.85393\n",
      "Epoch 68/200\n",
      "1083/1083 [==============================] - 25s 23ms/step - loss: 0.3937 - acc: 0.8404 - val_loss: 0.3928 - val_acc: 0.8503\n",
      "\n",
      "Epoch 00068: val_acc did not improve from 0.85393\n",
      "Epoch 69/200\n",
      "1083/1083 [==============================] - 25s 24ms/step - loss: 0.3889 - acc: 0.8415 - val_loss: 0.4044 - val_acc: 0.8435\n",
      "\n",
      "Epoch 00069: val_acc did not improve from 0.85393\n",
      "Epoch 70/200\n",
      "1083/1083 [==============================] - 26s 24ms/step - loss: 0.3892 - acc: 0.8422 - val_loss: 0.3824 - val_acc: 0.8542\n",
      "\n",
      "Epoch 00070: val_acc improved from 0.85393 to 0.85421, saving model to best_model_g2.h5\n",
      "Epoch 71/200\n",
      "1083/1083 [==============================] - 25s 23ms/step - loss: 0.3854 - acc: 0.8428 - val_loss: 0.3872 - val_acc: 0.8546\n",
      "\n",
      "Epoch 00071: val_acc improved from 0.85421 to 0.85456, saving model to best_model_g2.h5\n",
      "Epoch 72/200\n",
      "1083/1083 [==============================] - 25s 23ms/step - loss: 0.3879 - acc: 0.8431 - val_loss: 0.3841 - val_acc: 0.8566\n",
      "\n",
      "Epoch 00072: val_acc improved from 0.85456 to 0.85664, saving model to best_model_g2.h5\n",
      "Epoch 73/200\n",
      "1083/1083 [==============================] - 25s 24ms/step - loss: 0.3861 - acc: 0.8423 - val_loss: 0.3956 - val_acc: 0.8501\n",
      "\n",
      "Epoch 00073: val_acc did not improve from 0.85664\n",
      "Epoch 74/200\n",
      "1083/1083 [==============================] - 25s 24ms/step - loss: 0.3832 - acc: 0.8448 - val_loss: 0.3756 - val_acc: 0.8583\n",
      "\n",
      "Epoch 00074: val_acc improved from 0.85664 to 0.85831, saving model to best_model_g2.h5\n",
      "Epoch 75/200\n",
      "1083/1083 [==============================] - 25s 23ms/step - loss: 0.3872 - acc: 0.8425 - val_loss: 0.3821 - val_acc: 0.8584\n",
      "\n",
      "Epoch 00075: val_acc improved from 0.85831 to 0.85837, saving model to best_model_g2.h5\n",
      "Epoch 76/200\n",
      "1083/1083 [==============================] - 25s 23ms/step - loss: 0.3814 - acc: 0.8456 - val_loss: 0.3769 - val_acc: 0.8559\n",
      "\n",
      "Epoch 00076: val_acc did not improve from 0.85837\n",
      "Epoch 77/200\n",
      "1083/1083 [==============================] - 25s 23ms/step - loss: 0.3799 - acc: 0.8464 - val_loss: 0.3846 - val_acc: 0.8564\n",
      "\n",
      "Epoch 00077: val_acc did not improve from 0.85837\n",
      "Epoch 78/200\n",
      "1083/1083 [==============================] - 25s 24ms/step - loss: 0.3833 - acc: 0.8433 - val_loss: 0.3771 - val_acc: 0.8569\n",
      "\n",
      "Epoch 00078: val_acc did not improve from 0.85837\n",
      "Epoch 79/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1083/1083 [==============================] - 25s 23ms/step - loss: 0.3804 - acc: 0.8455 - val_loss: 0.3844 - val_acc: 0.8542\n",
      "\n",
      "Epoch 00079: val_acc did not improve from 0.85837\n",
      "Epoch 80/200\n",
      "1083/1083 [==============================] - 25s 24ms/step - loss: 0.3733 - acc: 0.8502 - val_loss: 0.3828 - val_acc: 0.8563\n",
      "\n",
      "Epoch 00080: val_acc did not improve from 0.85837\n",
      "Epoch 81/200\n",
      "1083/1083 [==============================] - 25s 24ms/step - loss: 0.3802 - acc: 0.8454 - val_loss: 0.3806 - val_acc: 0.8533\n",
      "\n",
      "Epoch 00081: val_acc did not improve from 0.85837\n",
      "Epoch 82/200\n",
      "1083/1083 [==============================] - 25s 24ms/step - loss: 0.3755 - acc: 0.8471 - val_loss: 0.3889 - val_acc: 0.8519\n",
      "\n",
      "Epoch 00082: val_acc did not improve from 0.85837\n",
      "Epoch 83/200\n",
      "1083/1083 [==============================] - 25s 23ms/step - loss: 0.3770 - acc: 0.8461 - val_loss: 0.3783 - val_acc: 0.8568\n",
      "\n",
      "Epoch 00083: val_acc did not improve from 0.85837\n",
      "Epoch 84/200\n",
      "1083/1083 [==============================] - 25s 23ms/step - loss: 0.3755 - acc: 0.8464 - val_loss: 0.3849 - val_acc: 0.8580\n",
      "\n",
      "Epoch 00084: val_acc did not improve from 0.85837\n",
      "Epoch 85/200\n",
      "1083/1083 [==============================] - 26s 24ms/step - loss: 0.3713 - acc: 0.8495 - val_loss: 0.3748 - val_acc: 0.8603\n",
      "\n",
      "Epoch 00085: val_acc improved from 0.85837 to 0.86033, saving model to best_model_g2.h5\n",
      "Epoch 86/200\n",
      "1083/1083 [==============================] - 25s 23ms/step - loss: 0.3774 - acc: 0.8489 - val_loss: 0.3675 - val_acc: 0.8611\n",
      "\n",
      "Epoch 00086: val_acc improved from 0.86033 to 0.86109, saving model to best_model_g2.h5\n",
      "Epoch 87/200\n",
      "1083/1083 [==============================] - 25s 24ms/step - loss: 0.3715 - acc: 0.8499 - val_loss: 0.3868 - val_acc: 0.8531\n",
      "\n",
      "Epoch 00087: val_acc did not improve from 0.86109\n",
      "Epoch 88/200\n",
      "1083/1083 [==============================] - 25s 23ms/step - loss: 0.3746 - acc: 0.8491 - val_loss: 0.3762 - val_acc: 0.8579\n",
      "\n",
      "Epoch 00088: val_acc did not improve from 0.86109\n",
      "Epoch 89/200\n",
      "1083/1083 [==============================] - 26s 24ms/step - loss: 0.3731 - acc: 0.8477 - val_loss: 0.3697 - val_acc: 0.8592\n",
      "\n",
      "Epoch 00089: val_acc did not improve from 0.86109\n",
      "Epoch 90/200\n",
      "1083/1083 [==============================] - 25s 24ms/step - loss: 0.3680 - acc: 0.8516 - val_loss: 0.3919 - val_acc: 0.8535\n",
      "\n",
      "Epoch 00090: val_acc did not improve from 0.86109\n",
      "Epoch 91/200\n",
      "1083/1083 [==============================] - 25s 23ms/step - loss: 0.3700 - acc: 0.8501 - val_loss: 0.3801 - val_acc: 0.8589\n",
      "\n",
      "Epoch 00091: val_acc did not improve from 0.86109\n",
      "Epoch 92/200\n",
      "1083/1083 [==============================] - 25s 24ms/step - loss: 0.3671 - acc: 0.8526 - val_loss: 0.3681 - val_acc: 0.8598\n",
      "\n",
      "Epoch 00092: val_acc did not improve from 0.86109\n",
      "Epoch 93/200\n",
      "1083/1083 [==============================] - 26s 24ms/step - loss: 0.3701 - acc: 0.8497 - val_loss: 0.3913 - val_acc: 0.8544\n",
      "\n",
      "Epoch 00093: val_acc did not improve from 0.86109\n",
      "Epoch 94/200\n",
      "1083/1083 [==============================] - 26s 24ms/step - loss: 0.3640 - acc: 0.8532 - val_loss: 0.4021 - val_acc: 0.8529\n",
      "\n",
      "Epoch 00094: val_acc did not improve from 0.86109\n",
      "Epoch 95/200\n",
      "1083/1083 [==============================] - 25s 23ms/step - loss: 0.3652 - acc: 0.8528 - val_loss: 0.3819 - val_acc: 0.8558\n",
      "\n",
      "Epoch 00095: val_acc did not improve from 0.86109\n",
      "Epoch 96/200\n",
      "1083/1083 [==============================] - 26s 24ms/step - loss: 0.3685 - acc: 0.8522 - val_loss: 0.3886 - val_acc: 0.8547\n",
      "\n",
      "Epoch 00096: val_acc did not improve from 0.86109\n",
      "Epoch 97/200\n",
      "1083/1083 [==============================] - 25s 24ms/step - loss: 0.3636 - acc: 0.8534 - val_loss: 0.3891 - val_acc: 0.8548\n",
      "\n",
      "Epoch 00097: val_acc did not improve from 0.86109\n",
      "Epoch 98/200\n",
      "1083/1083 [==============================] - 25s 24ms/step - loss: 0.3652 - acc: 0.8516 - val_loss: 0.3914 - val_acc: 0.8553\n",
      "\n",
      "Epoch 00098: val_acc did not improve from 0.86109\n",
      "Epoch 99/200\n",
      "1083/1083 [==============================] - 25s 23ms/step - loss: 0.3597 - acc: 0.8547 - val_loss: 0.3808 - val_acc: 0.8580\n",
      "\n",
      "Epoch 00099: val_acc did not improve from 0.86109\n",
      "Epoch 100/200\n",
      "1083/1083 [==============================] - 25s 24ms/step - loss: 0.3595 - acc: 0.8536 - val_loss: 0.3870 - val_acc: 0.8533\n",
      "\n",
      "Epoch 00100: val_acc did not improve from 0.86109\n",
      "Epoch 101/200\n",
      "1083/1083 [==============================] - 25s 24ms/step - loss: 0.3624 - acc: 0.8532 - val_loss: 0.3663 - val_acc: 0.8591\n",
      "\n",
      "Epoch 00101: val_acc did not improve from 0.86109\n",
      "Epoch 102/200\n",
      "1083/1083 [==============================] - 26s 24ms/step - loss: 0.3611 - acc: 0.8553 - val_loss: 0.4019 - val_acc: 0.8519\n",
      "\n",
      "Epoch 00102: val_acc did not improve from 0.86109\n",
      "Epoch 103/200\n",
      "1083/1083 [==============================] - 26s 24ms/step - loss: 0.3611 - acc: 0.8533 - val_loss: 0.3683 - val_acc: 0.8611\n",
      "\n",
      "Epoch 00103: val_acc improved from 0.86109 to 0.86114, saving model to best_model_g2.h5\n",
      "Epoch 104/200\n",
      "1083/1083 [==============================] - 25s 23ms/step - loss: 0.3558 - acc: 0.8566 - val_loss: 0.3799 - val_acc: 0.8576\n",
      "\n",
      "Epoch 00104: val_acc did not improve from 0.86114\n",
      "Epoch 105/200\n",
      "1083/1083 [==============================] - 25s 24ms/step - loss: 0.3590 - acc: 0.8566 - val_loss: 0.3768 - val_acc: 0.8571\n",
      "\n",
      "Epoch 00105: val_acc did not improve from 0.86114\n",
      "Epoch 106/200\n",
      "1083/1083 [==============================] - 25s 24ms/step - loss: 0.3584 - acc: 0.8566 - val_loss: 0.3779 - val_acc: 0.8579\n",
      "\n",
      "Epoch 00106: val_acc did not improve from 0.86114\n",
      "Epoch 107/200\n",
      "1083/1083 [==============================] - 25s 24ms/step - loss: 0.3553 - acc: 0.8563 - val_loss: 0.3598 - val_acc: 0.8638\n",
      "\n",
      "Epoch 00107: val_acc improved from 0.86114 to 0.86380, saving model to best_model_g2.h5\n",
      "Epoch 108/200\n",
      "1083/1083 [==============================] - 25s 23ms/step - loss: 0.3569 - acc: 0.8571 - val_loss: 0.3631 - val_acc: 0.8650\n",
      "\n",
      "Epoch 00108: val_acc improved from 0.86380 to 0.86495, saving model to best_model_g2.h5\n",
      "Epoch 109/200\n",
      "1083/1083 [==============================] - 25s 24ms/step - loss: 0.3560 - acc: 0.8551 - val_loss: 0.3696 - val_acc: 0.8619\n",
      "\n",
      "Epoch 00109: val_acc did not improve from 0.86495\n",
      "Epoch 110/200\n",
      "1083/1083 [==============================] - 26s 24ms/step - loss: 0.3541 - acc: 0.8572 - val_loss: 0.3693 - val_acc: 0.8622\n",
      "\n",
      "Epoch 00110: val_acc did not improve from 0.86495\n",
      "Epoch 111/200\n",
      "1083/1083 [==============================] - 26s 24ms/step - loss: 0.3523 - acc: 0.8587 - val_loss: 0.3811 - val_acc: 0.8568\n",
      "\n",
      "Epoch 00111: val_acc did not improve from 0.86495\n",
      "Epoch 112/200\n",
      "1083/1083 [==============================] - 25s 24ms/step - loss: 0.3554 - acc: 0.8582 - val_loss: 0.3733 - val_acc: 0.8589\n",
      "\n",
      "Epoch 00112: val_acc did not improve from 0.86495\n",
      "Epoch 113/200\n",
      "1083/1083 [==============================] - 26s 24ms/step - loss: 0.3551 - acc: 0.8572 - val_loss: 0.3618 - val_acc: 0.8658\n",
      "\n",
      "Epoch 00113: val_acc improved from 0.86495 to 0.86576, saving model to best_model_g2.h5\n",
      "Epoch 114/200\n",
      "1083/1083 [==============================] - 25s 23ms/step - loss: 0.3540 - acc: 0.8580 - val_loss: 0.3737 - val_acc: 0.8595\n",
      "\n",
      "Epoch 00114: val_acc did not improve from 0.86576\n",
      "Epoch 115/200\n",
      "1083/1083 [==============================] - 26s 24ms/step - loss: 0.3510 - acc: 0.8582 - val_loss: 0.3679 - val_acc: 0.8652\n",
      "\n",
      "Epoch 00115: val_acc did not improve from 0.86576\n",
      "Epoch 116/200\n",
      "1083/1083 [==============================] - 25s 23ms/step - loss: 0.3551 - acc: 0.8568 - val_loss: 0.3592 - val_acc: 0.8673\n",
      "\n",
      "Epoch 00116: val_acc improved from 0.86576 to 0.86732, saving model to best_model_g2.h5\n",
      "Epoch 117/200\n",
      "1083/1083 [==============================] - 25s 24ms/step - loss: 0.3494 - acc: 0.8580 - val_loss: 0.3745 - val_acc: 0.8620\n",
      "\n",
      "Epoch 00117: val_acc did not improve from 0.86732\n",
      "Epoch 118/200\n",
      "1083/1083 [==============================] - 26s 24ms/step - loss: 0.3447 - acc: 0.8623 - val_loss: 0.3668 - val_acc: 0.8648\n",
      "\n",
      "Epoch 00118: val_acc did not improve from 0.86732\n",
      "Epoch 119/200\n",
      "1083/1083 [==============================] - 26s 24ms/step - loss: 0.3501 - acc: 0.8588 - val_loss: 0.3624 - val_acc: 0.8629\n",
      "\n",
      "Epoch 00119: val_acc did not improve from 0.86732\n",
      "Epoch 120/200\n",
      "1083/1083 [==============================] - 26s 24ms/step - loss: 0.3523 - acc: 0.8586 - val_loss: 0.3702 - val_acc: 0.8614\n",
      "\n",
      "Epoch 00120: val_acc did not improve from 0.86732\n",
      "Epoch 121/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1083/1083 [==============================] - 25s 24ms/step - loss: 0.3482 - acc: 0.8580 - val_loss: 0.3759 - val_acc: 0.8611\n",
      "\n",
      "Epoch 00121: val_acc did not improve from 0.86732\n",
      "Epoch 122/200\n",
      "1083/1083 [==============================] - 26s 24ms/step - loss: 0.3475 - acc: 0.8598 - val_loss: 0.3750 - val_acc: 0.8618\n",
      "\n",
      "Epoch 00122: val_acc did not improve from 0.86732\n",
      "Epoch 123/200\n",
      "1083/1083 [==============================] - 25s 24ms/step - loss: 0.3461 - acc: 0.8601 - val_loss: 0.3846 - val_acc: 0.8604\n",
      "\n",
      "Epoch 00123: val_acc did not improve from 0.86732\n",
      "Epoch 124/200\n",
      "1083/1083 [==============================] - 25s 24ms/step - loss: 0.3480 - acc: 0.8592 - val_loss: 0.3721 - val_acc: 0.8658\n",
      "\n",
      "Epoch 00124: val_acc did not improve from 0.86732\n",
      "Epoch 125/200\n",
      "1083/1083 [==============================] - 25s 23ms/step - loss: 0.3458 - acc: 0.8618 - val_loss: 0.3728 - val_acc: 0.8630\n",
      "\n",
      "Epoch 00125: val_acc did not improve from 0.86732\n",
      "Epoch 126/200\n",
      "1083/1083 [==============================] - 25s 23ms/step - loss: 0.3414 - acc: 0.8638 - val_loss: 0.3665 - val_acc: 0.8661\n",
      "\n",
      "Epoch 00126: val_acc did not improve from 0.86732\n",
      "Epoch 127/200\n",
      "1083/1083 [==============================] - 25s 24ms/step - loss: 0.3461 - acc: 0.8605 - val_loss: 0.3866 - val_acc: 0.8610\n",
      "\n",
      "Epoch 00127: val_acc did not improve from 0.86732\n",
      "Epoch 128/200\n",
      "1083/1083 [==============================] - 26s 24ms/step - loss: 0.3434 - acc: 0.8620 - val_loss: 0.3932 - val_acc: 0.8581\n",
      "\n",
      "Epoch 00128: val_acc did not improve from 0.86732\n",
      "Epoch 129/200\n",
      "1083/1083 [==============================] - 25s 24ms/step - loss: 0.3463 - acc: 0.8605 - val_loss: 0.3852 - val_acc: 0.8582\n",
      "\n",
      "Epoch 00129: val_acc did not improve from 0.86732\n",
      "Epoch 130/200\n",
      "1083/1083 [==============================] - 25s 23ms/step - loss: 0.3451 - acc: 0.8614 - val_loss: 0.3790 - val_acc: 0.8632\n",
      "\n",
      "Epoch 00130: val_acc did not improve from 0.86732\n",
      "Epoch 131/200\n",
      "1083/1083 [==============================] - 25s 24ms/step - loss: 0.3429 - acc: 0.8621 - val_loss: 0.3748 - val_acc: 0.8640\n",
      "\n",
      "Epoch 00131: val_acc did not improve from 0.86732\n",
      "Epoch 132/200\n",
      "1083/1083 [==============================] - 26s 24ms/step - loss: 0.3445 - acc: 0.8620 - val_loss: 0.3709 - val_acc: 0.8654\n",
      "\n",
      "Epoch 00132: val_acc did not improve from 0.86732\n",
      "Epoch 133/200\n",
      "1083/1083 [==============================] - 26s 24ms/step - loss: 0.3413 - acc: 0.8613 - val_loss: 0.3720 - val_acc: 0.8626\n",
      "\n",
      "Epoch 00133: val_acc did not improve from 0.86732\n",
      "Epoch 134/200\n",
      "1083/1083 [==============================] - 25s 23ms/step - loss: 0.3433 - acc: 0.8613 - val_loss: 0.3853 - val_acc: 0.8595\n",
      "\n",
      "Epoch 00134: val_acc did not improve from 0.86732\n",
      "Epoch 135/200\n",
      "1083/1083 [==============================] - 26s 24ms/step - loss: 0.3454 - acc: 0.8622 - val_loss: 0.3654 - val_acc: 0.8659\n",
      "\n",
      "Epoch 00135: val_acc did not improve from 0.86732\n",
      "Epoch 136/200\n",
      "1083/1083 [==============================] - 25s 24ms/step - loss: 0.3444 - acc: 0.8606 - val_loss: 0.3708 - val_acc: 0.8655\n",
      "\n",
      "Epoch 00136: val_acc did not improve from 0.86732\n",
      "Epoch 137/200\n",
      "1083/1083 [==============================] - 25s 24ms/step - loss: 0.3394 - acc: 0.8622 - val_loss: 0.3757 - val_acc: 0.8610\n",
      "\n",
      "Epoch 00137: val_acc did not improve from 0.86732\n",
      "Epoch 138/200\n",
      "1083/1083 [==============================] - 26s 24ms/step - loss: 0.3386 - acc: 0.8652 - val_loss: 0.3745 - val_acc: 0.8644\n",
      "\n",
      "Epoch 00138: val_acc did not improve from 0.86732\n",
      "Epoch 139/200\n",
      "1083/1083 [==============================] - 26s 24ms/step - loss: 0.3412 - acc: 0.8632 - val_loss: 0.3765 - val_acc: 0.8641\n",
      "\n",
      "Epoch 00139: val_acc did not improve from 0.86732\n",
      "Epoch 140/200\n",
      "1083/1083 [==============================] - 26s 24ms/step - loss: 0.3385 - acc: 0.8633 - val_loss: 0.3704 - val_acc: 0.8654\n",
      "\n",
      "Epoch 00140: val_acc did not improve from 0.86732\n",
      "Epoch 141/200\n",
      "1083/1083 [==============================] - 25s 24ms/step - loss: 0.3358 - acc: 0.8650 - val_loss: 0.3783 - val_acc: 0.8654\n",
      "\n",
      "Epoch 00141: val_acc did not improve from 0.86732\n",
      "Epoch 142/200\n",
      "1083/1083 [==============================] - 26s 24ms/step - loss: 0.3362 - acc: 0.8645 - val_loss: 0.3573 - val_acc: 0.8702\n",
      "\n",
      "Epoch 00142: val_acc improved from 0.86732 to 0.87021, saving model to best_model_g2.h5\n",
      "Epoch 143/200\n",
      "1083/1083 [==============================] - 25s 23ms/step - loss: 0.3364 - acc: 0.8644 - val_loss: 0.3835 - val_acc: 0.8621\n",
      "\n",
      "Epoch 00143: val_acc did not improve from 0.87021\n",
      "Epoch 144/200\n",
      "1083/1083 [==============================] - 25s 23ms/step - loss: 0.3361 - acc: 0.8656 - val_loss: 0.3760 - val_acc: 0.8640\n",
      "\n",
      "Epoch 00144: val_acc did not improve from 0.87021\n",
      "Epoch 145/200\n",
      "1083/1083 [==============================] - 25s 24ms/step - loss: 0.3346 - acc: 0.8650 - val_loss: 0.3963 - val_acc: 0.8577\n",
      "\n",
      "Epoch 00145: val_acc did not improve from 0.87021\n",
      "Epoch 146/200\n",
      "1083/1083 [==============================] - 25s 24ms/step - loss: 0.3388 - acc: 0.8648 - val_loss: 0.3734 - val_acc: 0.8640\n",
      "\n",
      "Epoch 00146: val_acc did not improve from 0.87021\n",
      "Epoch 147/200\n",
      "1083/1083 [==============================] - 25s 24ms/step - loss: 0.3375 - acc: 0.8633 - val_loss: 0.3764 - val_acc: 0.8600\n",
      "\n",
      "Epoch 00147: val_acc did not improve from 0.87021\n",
      "Epoch 148/200\n",
      "1083/1083 [==============================] - 26s 24ms/step - loss: 0.3343 - acc: 0.8672 - val_loss: 0.3735 - val_acc: 0.8668\n",
      "\n",
      "Epoch 00148: val_acc did not improve from 0.87021\n",
      "Epoch 149/200\n",
      "1083/1083 [==============================] - 26s 24ms/step - loss: 0.3329 - acc: 0.8666 - val_loss: 0.3717 - val_acc: 0.8681\n",
      "\n",
      "Epoch 00149: val_acc did not improve from 0.87021\n",
      "Epoch 150/200\n",
      "1083/1083 [==============================] - 26s 24ms/step - loss: 0.3348 - acc: 0.8651 - val_loss: 0.3651 - val_acc: 0.8682\n",
      "\n",
      "Epoch 00150: val_acc did not improve from 0.87021\n",
      "Epoch 151/200\n",
      "1083/1083 [==============================] - 26s 24ms/step - loss: 0.3357 - acc: 0.8642 - val_loss: 0.3650 - val_acc: 0.8665\n",
      "\n",
      "Epoch 00151: val_acc did not improve from 0.87021\n",
      "Epoch 152/200\n",
      "1083/1083 [==============================] - 26s 24ms/step - loss: 0.3343 - acc: 0.8669 - val_loss: 0.3807 - val_acc: 0.8630\n",
      "\n",
      "Epoch 00152: val_acc did not improve from 0.87021\n",
      "Epoch 153/200\n",
      "1083/1083 [==============================] - 26s 24ms/step - loss: 0.3361 - acc: 0.8647 - val_loss: 0.3784 - val_acc: 0.8633\n",
      "\n",
      "Epoch 00153: val_acc did not improve from 0.87021\n",
      "Epoch 154/200\n",
      "1083/1083 [==============================] - 25s 23ms/step - loss: 0.3317 - acc: 0.8677 - val_loss: 0.3684 - val_acc: 0.8672\n",
      "\n",
      "Epoch 00154: val_acc did not improve from 0.87021\n",
      "Epoch 155/200\n",
      "1083/1083 [==============================] - 26s 24ms/step - loss: 0.3349 - acc: 0.8649 - val_loss: 0.3728 - val_acc: 0.8639\n",
      "\n",
      "Epoch 00155: val_acc did not improve from 0.87021\n",
      "Epoch 156/200\n",
      "1083/1083 [==============================] - 25s 23ms/step - loss: 0.3298 - acc: 0.8668 - val_loss: 0.3668 - val_acc: 0.8652\n",
      "\n",
      "Epoch 00156: val_acc did not improve from 0.87021\n",
      "Epoch 157/200\n",
      "1083/1083 [==============================] - 26s 24ms/step - loss: 0.3354 - acc: 0.8662 - val_loss: 0.3772 - val_acc: 0.8629\n",
      "\n",
      "Epoch 00157: val_acc did not improve from 0.87021\n",
      "Epoch 158/200\n",
      "1083/1083 [==============================] - 26s 24ms/step - loss: 0.3306 - acc: 0.8675 - val_loss: 0.3713 - val_acc: 0.8628\n",
      "\n",
      "Epoch 00158: val_acc did not improve from 0.87021\n",
      "Epoch 159/200\n",
      "1083/1083 [==============================] - 26s 24ms/step - loss: 0.3299 - acc: 0.8672 - val_loss: 0.3705 - val_acc: 0.8660\n",
      "\n",
      "Epoch 00159: val_acc did not improve from 0.87021\n",
      "Epoch 160/200\n",
      "1083/1083 [==============================] - 25s 24ms/step - loss: 0.3335 - acc: 0.8654 - val_loss: 0.3662 - val_acc: 0.8648\n",
      "\n",
      "Epoch 00160: val_acc did not improve from 0.87021\n",
      "Epoch 161/200\n",
      "1083/1083 [==============================] - 25s 24ms/step - loss: 0.3349 - acc: 0.8646 - val_loss: 0.3934 - val_acc: 0.8580\n",
      "\n",
      "Epoch 00161: val_acc did not improve from 0.87021\n",
      "Epoch 162/200\n",
      "1083/1083 [==============================] - 25s 24ms/step - loss: 0.3305 - acc: 0.8668 - val_loss: 0.3731 - val_acc: 0.8642\n",
      "\n",
      "Epoch 00162: val_acc did not improve from 0.87021\n",
      "Epoch 163/200\n",
      "1083/1083 [==============================] - 25s 23ms/step - loss: 0.3281 - acc: 0.8695 - val_loss: 0.3629 - val_acc: 0.8682\n",
      "\n",
      "Epoch 00163: val_acc did not improve from 0.87021\n",
      "Epoch 164/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1083/1083 [==============================] - 25s 23ms/step - loss: 0.3254 - acc: 0.8698 - val_loss: 0.3583 - val_acc: 0.8704\n",
      "\n",
      "Epoch 00164: val_acc improved from 0.87021 to 0.87044, saving model to best_model_g2.h5\n",
      "Epoch 165/200\n",
      "1083/1083 [==============================] - 26s 24ms/step - loss: 0.3279 - acc: 0.8679 - val_loss: 0.3639 - val_acc: 0.8692\n",
      "\n",
      "Epoch 00165: val_acc did not improve from 0.87044\n",
      "Epoch 166/200\n",
      "1083/1083 [==============================] - 25s 23ms/step - loss: 0.3263 - acc: 0.8686 - val_loss: 0.3708 - val_acc: 0.8667\n",
      "\n",
      "Epoch 00166: val_acc did not improve from 0.87044\n",
      "Epoch 167/200\n",
      "1083/1083 [==============================] - 25s 23ms/step - loss: 0.3286 - acc: 0.8674 - val_loss: 0.3688 - val_acc: 0.8685\n",
      "\n",
      "Epoch 00167: val_acc did not improve from 0.87044\n",
      "Epoch 168/200\n",
      "1083/1083 [==============================] - 25s 24ms/step - loss: 0.3244 - acc: 0.8703 - val_loss: 0.3597 - val_acc: 0.8725\n",
      "\n",
      "Epoch 00168: val_acc improved from 0.87044 to 0.87246, saving model to best_model_g2.h5\n",
      "Epoch 169/200\n",
      "1083/1083 [==============================] - 25s 24ms/step - loss: 0.3272 - acc: 0.8691 - val_loss: 0.3572 - val_acc: 0.8721\n",
      "\n",
      "Epoch 00169: val_acc did not improve from 0.87246\n",
      "Epoch 170/200\n",
      "1083/1083 [==============================] - 26s 24ms/step - loss: 0.3261 - acc: 0.8693 - val_loss: 0.3667 - val_acc: 0.8692\n",
      "\n",
      "Epoch 00170: val_acc did not improve from 0.87246\n",
      "Epoch 171/200\n",
      "1083/1083 [==============================] - 26s 24ms/step - loss: 0.3242 - acc: 0.8699 - val_loss: 0.3799 - val_acc: 0.8649\n",
      "\n",
      "Epoch 00171: val_acc did not improve from 0.87246\n",
      "Epoch 172/200\n",
      "1083/1083 [==============================] - 26s 24ms/step - loss: 0.3266 - acc: 0.8690 - val_loss: 0.3581 - val_acc: 0.8721\n",
      "\n",
      "Epoch 00172: val_acc did not improve from 0.87246\n",
      "Epoch 173/200\n",
      "1083/1083 [==============================] - 26s 24ms/step - loss: 0.3267 - acc: 0.8705 - val_loss: 0.3763 - val_acc: 0.8669\n",
      "\n",
      "Epoch 00173: val_acc did not improve from 0.87246\n",
      "Epoch 174/200\n",
      "1083/1083 [==============================] - 25s 24ms/step - loss: 0.3232 - acc: 0.8712 - val_loss: 0.3611 - val_acc: 0.8707\n",
      "\n",
      "Epoch 00174: val_acc did not improve from 0.87246\n",
      "Epoch 175/200\n",
      "1083/1083 [==============================] - 26s 24ms/step - loss: 0.3241 - acc: 0.8685 - val_loss: 0.3623 - val_acc: 0.8698\n",
      "\n",
      "Epoch 00175: val_acc did not improve from 0.87246\n",
      "Epoch 176/200\n",
      "1083/1083 [==============================] - 26s 24ms/step - loss: 0.3255 - acc: 0.8695 - val_loss: 0.3780 - val_acc: 0.8641\n",
      "\n",
      "Epoch 00176: val_acc did not improve from 0.87246\n",
      "Epoch 177/200\n",
      "1083/1083 [==============================] - 25s 23ms/step - loss: 0.3268 - acc: 0.8705 - val_loss: 0.3822 - val_acc: 0.8611\n",
      "\n",
      "Epoch 00177: val_acc did not improve from 0.87246\n",
      "Epoch 178/200\n",
      "1083/1083 [==============================] - 25s 24ms/step - loss: 0.3219 - acc: 0.8705 - val_loss: 0.3589 - val_acc: 0.8710\n",
      "\n",
      "Epoch 00178: val_acc did not improve from 0.87246\n",
      "Epoch 179/200\n",
      "1083/1083 [==============================] - 26s 24ms/step - loss: 0.3209 - acc: 0.8715 - val_loss: 0.3805 - val_acc: 0.8632\n",
      "\n",
      "Epoch 00179: val_acc did not improve from 0.87246\n",
      "Epoch 180/200\n",
      "1083/1083 [==============================] - 26s 24ms/step - loss: 0.3253 - acc: 0.8681 - val_loss: 0.3624 - val_acc: 0.8663\n",
      "\n",
      "Epoch 00180: val_acc did not improve from 0.87246\n",
      "Epoch 181/200\n",
      "1083/1083 [==============================] - 26s 24ms/step - loss: 0.3237 - acc: 0.8701 - val_loss: 0.3519 - val_acc: 0.8750\n",
      "\n",
      "Epoch 00181: val_acc improved from 0.87246 to 0.87500, saving model to best_model_g2.h5\n",
      "Epoch 182/200\n",
      "1083/1083 [==============================] - 25s 24ms/step - loss: 0.3230 - acc: 0.8702 - val_loss: 0.3773 - val_acc: 0.8680\n",
      "\n",
      "Epoch 00182: val_acc did not improve from 0.87500\n",
      "Epoch 183/200\n",
      "1083/1083 [==============================] - 25s 23ms/step - loss: 0.3244 - acc: 0.8704 - val_loss: 0.3651 - val_acc: 0.8676\n",
      "\n",
      "Epoch 00183: val_acc did not improve from 0.87500\n",
      "Epoch 184/200\n",
      "1083/1083 [==============================] - 25s 24ms/step - loss: 0.3203 - acc: 0.8718 - val_loss: 0.3623 - val_acc: 0.8704\n",
      "\n",
      "Epoch 00184: val_acc did not improve from 0.87500\n",
      "Epoch 185/200\n",
      "1083/1083 [==============================] - 26s 24ms/step - loss: 0.3223 - acc: 0.8707 - val_loss: 0.3633 - val_acc: 0.8697\n",
      "\n",
      "Epoch 00185: val_acc did not improve from 0.87500\n",
      "Epoch 186/200\n",
      "1083/1083 [==============================] - 26s 24ms/step - loss: 0.3197 - acc: 0.8707 - val_loss: 0.3749 - val_acc: 0.8702\n",
      "\n",
      "Epoch 00186: val_acc did not improve from 0.87500\n",
      "Epoch 187/200\n",
      "1083/1083 [==============================] - 26s 24ms/step - loss: 0.3200 - acc: 0.8726 - val_loss: 0.3757 - val_acc: 0.8676\n",
      "\n",
      "Epoch 00187: val_acc did not improve from 0.87500\n",
      "Epoch 188/200\n",
      "1083/1083 [==============================] - 26s 24ms/step - loss: 0.3180 - acc: 0.8737 - val_loss: 0.3657 - val_acc: 0.8697\n",
      "\n",
      "Epoch 00188: val_acc did not improve from 0.87500\n",
      "Epoch 189/200\n",
      "1083/1083 [==============================] - 26s 24ms/step - loss: 0.3191 - acc: 0.8720 - val_loss: 0.3583 - val_acc: 0.8749\n",
      "\n",
      "Epoch 00189: val_acc did not improve from 0.87500\n",
      "Epoch 190/200\n",
      "1083/1083 [==============================] - 26s 24ms/step - loss: 0.3198 - acc: 0.8726 - val_loss: 0.3514 - val_acc: 0.8764\n",
      "\n",
      "Epoch 00190: val_acc improved from 0.87500 to 0.87644, saving model to best_model_g2.h5\n",
      "Epoch 191/200\n",
      "1083/1083 [==============================] - 25s 23ms/step - loss: 0.3194 - acc: 0.8725 - val_loss: 0.3608 - val_acc: 0.8745\n",
      "\n",
      "Epoch 00191: val_acc did not improve from 0.87644\n",
      "Epoch 192/200\n",
      "1083/1083 [==============================] - 25s 24ms/step - loss: 0.3183 - acc: 0.8728 - val_loss: 0.3743 - val_acc: 0.8662\n",
      "\n",
      "Epoch 00192: val_acc did not improve from 0.87644\n",
      "Epoch 193/200\n",
      "1083/1083 [==============================] - 25s 24ms/step - loss: 0.3183 - acc: 0.8724 - val_loss: 0.3649 - val_acc: 0.8715\n",
      "\n",
      "Epoch 00193: val_acc did not improve from 0.87644\n",
      "Epoch 194/200\n",
      "1083/1083 [==============================] - 26s 24ms/step - loss: 0.3140 - acc: 0.8747 - val_loss: 0.3704 - val_acc: 0.8672\n",
      "\n",
      "Epoch 00194: val_acc did not improve from 0.87644\n",
      "Epoch 195/200\n",
      "1083/1083 [==============================] - 26s 24ms/step - loss: 0.3140 - acc: 0.8757 - val_loss: 0.3828 - val_acc: 0.8647\n",
      "\n",
      "Epoch 00195: val_acc did not improve from 0.87644\n",
      "Epoch 196/200\n",
      "1083/1083 [==============================] - 25s 23ms/step - loss: 0.3191 - acc: 0.8730 - val_loss: 0.3583 - val_acc: 0.8737\n",
      "\n",
      "Epoch 00196: val_acc did not improve from 0.87644\n",
      "Epoch 197/200\n",
      "1083/1083 [==============================] - 25s 24ms/step - loss: 0.3183 - acc: 0.8731 - val_loss: 0.3458 - val_acc: 0.8757\n",
      "\n",
      "Epoch 00197: val_acc did not improve from 0.87644\n",
      "Epoch 198/200\n",
      "1083/1083 [==============================] - 25s 23ms/step - loss: 0.3155 - acc: 0.8752 - val_loss: 0.3794 - val_acc: 0.8644\n",
      "\n",
      "Epoch 00198: val_acc did not improve from 0.87644\n",
      "Epoch 199/200\n",
      "1083/1083 [==============================] - 25s 24ms/step - loss: 0.3158 - acc: 0.8732 - val_loss: 0.3546 - val_acc: 0.8751\n",
      "\n",
      "Epoch 00199: val_acc did not improve from 0.87644\n",
      "Epoch 200/200\n",
      "1083/1083 [==============================] - 25s 24ms/step - loss: 0.3140 - acc: 0.8739 - val_loss: 0.3707 - val_acc: 0.8714\n",
      "\n",
      "Epoch 00200: val_acc did not improve from 0.87644\n",
      "CPU times: user 5h 24min 19s, sys: 36min 26s, total: 6h 45s\n",
      "Wall time: 1h 19min 11s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "mc2 = ModelCheckpoint('best_model_g2.h5', monitor='val_acc', mode='max', save_best_only=True,verbose=1)  \n",
    "history2 = model2.fit(X_train, y_train, batch_size=64, epochs=200, validation_split=0.2, verbose=1, callbacks=[mc2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "49f9dd18",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('history_g2.json', 'w') as f:\n",
    "    json.dump(history2.history, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "75c14eed",
   "metadata": {},
   "outputs": [],
   "source": [
    "model2.save('themodel_g2.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5929d035",
   "metadata": {},
   "source": [
    "## LSTM 3 Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "11543333",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_5 (Embedding)      (None, 30, 300)           31476300  \n",
      "_________________________________________________________________\n",
      "lstm_8 (LSTM)                (None, 30, 64)            93440     \n",
      "_________________________________________________________________\n",
      "lstm_9 (LSTM)                (None, 30, 64)            33024     \n",
      "_________________________________________________________________\n",
      "lstm_10 (LSTM)               (None, 30, 64)            33024     \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_5 (Glob (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 3)                 195       \n",
      "=================================================================\n",
      "Total params: 31,640,143\n",
      "Trainable params: 163,843\n",
      "Non-trainable params: 31,476,300\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model3=Sequential()\n",
    "model3.add(Embedding(size_of_vocabulary,embedding_dim,weights=[embedding_matrix],input_length=max_length,trainable=False))\n",
    "\n",
    "#Lstm layer\n",
    "model3.add(LSTM(UNITS,return_sequences=True,dropout=0.5))\n",
    "model3.add(LSTM(UNITS,return_sequences=True))\n",
    "model3.add(LSTM(UNITS,return_sequences=True))\n",
    "\n",
    "#Global Maxpooling\n",
    "model3.add(GlobalMaxPooling1D())\n",
    "\n",
    "#Dense Layer\n",
    "model3.add(Dense(UNITS, activation='relu'))\n",
    "\n",
    "#Output layer 3 class\n",
    "model3.add(Dense(3,activation='softmax')) \n",
    "\n",
    "model3.compile(optimizer=Adam(learning_rate = lr), loss = 'sparse_categorical_crossentropy', metrics = ['acc']) \n",
    "print(model3.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "5458db29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "1083/1083 [==============================] - 33s 29ms/step - loss: 0.8296 - acc: 0.6192 - val_loss: 0.7595 - val_acc: 0.6620\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.66201, saving model to best_model_g3.h5\n",
      "Epoch 2/200\n",
      "1083/1083 [==============================] - 35s 32ms/step - loss: 0.7728 - acc: 0.6520 - val_loss: 0.7191 - val_acc: 0.6814\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.66201 to 0.68135, saving model to best_model_g3.h5\n",
      "Epoch 3/200\n",
      "1083/1083 [==============================] - 35s 33ms/step - loss: 0.7416 - acc: 0.6667 - val_loss: 0.6970 - val_acc: 0.6905\n",
      "\n",
      "Epoch 00003: val_acc improved from 0.68135 to 0.69053, saving model to best_model_g3.h5\n",
      "Epoch 4/200\n",
      "1083/1083 [==============================] - 35s 33ms/step - loss: 0.7129 - acc: 0.6835 - val_loss: 0.6730 - val_acc: 0.7026\n",
      "\n",
      "Epoch 00004: val_acc improved from 0.69053 to 0.70260, saving model to best_model_g3.h5\n",
      "Epoch 5/200\n",
      "1083/1083 [==============================] - 35s 33ms/step - loss: 0.6880 - acc: 0.6964 - val_loss: 0.6472 - val_acc: 0.7173\n",
      "\n",
      "Epoch 00005: val_acc improved from 0.70260 to 0.71732, saving model to best_model_g3.h5\n",
      "Epoch 6/200\n",
      "1083/1083 [==============================] - 35s 33ms/step - loss: 0.6621 - acc: 0.7106 - val_loss: 0.6352 - val_acc: 0.7221\n",
      "\n",
      "Epoch 00006: val_acc improved from 0.71732 to 0.72206, saving model to best_model_g3.h5\n",
      "Epoch 7/200\n",
      "1083/1083 [==============================] - 35s 33ms/step - loss: 0.6452 - acc: 0.7184 - val_loss: 0.6144 - val_acc: 0.7374\n",
      "\n",
      "Epoch 00007: val_acc improved from 0.72206 to 0.73736, saving model to best_model_g3.h5\n",
      "Epoch 8/200\n",
      "1083/1083 [==============================] - 35s 33ms/step - loss: 0.6271 - acc: 0.7279 - val_loss: 0.5956 - val_acc: 0.7477\n",
      "\n",
      "Epoch 00008: val_acc improved from 0.73736 to 0.74769, saving model to best_model_g3.h5\n",
      "Epoch 9/200\n",
      "1083/1083 [==============================] - 35s 32ms/step - loss: 0.6117 - acc: 0.7354 - val_loss: 0.5825 - val_acc: 0.7550\n",
      "\n",
      "Epoch 00009: val_acc improved from 0.74769 to 0.75502, saving model to best_model_g3.h5\n",
      "Epoch 10/200\n",
      "1083/1083 [==============================] - 35s 33ms/step - loss: 0.5956 - acc: 0.7453 - val_loss: 0.5734 - val_acc: 0.7603\n",
      "\n",
      "Epoch 00010: val_acc improved from 0.75502 to 0.76033, saving model to best_model_g3.h5\n",
      "Epoch 11/200\n",
      "1083/1083 [==============================] - 35s 33ms/step - loss: 0.5864 - acc: 0.7485 - val_loss: 0.5527 - val_acc: 0.7688\n",
      "\n",
      "Epoch 00011: val_acc improved from 0.76033 to 0.76876, saving model to best_model_g3.h5\n",
      "Epoch 12/200\n",
      "1083/1083 [==============================] - 35s 33ms/step - loss: 0.5746 - acc: 0.7543 - val_loss: 0.5473 - val_acc: 0.7729\n",
      "\n",
      "Epoch 00012: val_acc improved from 0.76876 to 0.77286, saving model to best_model_g3.h5\n",
      "Epoch 13/200\n",
      "1083/1083 [==============================] - 35s 33ms/step - loss: 0.5633 - acc: 0.7604 - val_loss: 0.5539 - val_acc: 0.7654\n",
      "\n",
      "Epoch 00013: val_acc did not improve from 0.77286\n",
      "Epoch 14/200\n",
      "1083/1083 [==============================] - 35s 33ms/step - loss: 0.5578 - acc: 0.7630 - val_loss: 0.5309 - val_acc: 0.7799\n",
      "\n",
      "Epoch 00014: val_acc improved from 0.77286 to 0.77991, saving model to best_model_g3.h5\n",
      "Epoch 15/200\n",
      "1083/1083 [==============================] - 35s 33ms/step - loss: 0.5475 - acc: 0.7684 - val_loss: 0.5224 - val_acc: 0.7850\n",
      "\n",
      "Epoch 00015: val_acc improved from 0.77991 to 0.78499, saving model to best_model_g3.h5\n",
      "Epoch 16/200\n",
      "1083/1083 [==============================] - 35s 33ms/step - loss: 0.5377 - acc: 0.7730 - val_loss: 0.5069 - val_acc: 0.7917\n",
      "\n",
      "Epoch 00016: val_acc improved from 0.78499 to 0.79174, saving model to best_model_g3.h5\n",
      "Epoch 17/200\n",
      "1083/1083 [==============================] - 35s 33ms/step - loss: 0.5310 - acc: 0.7750 - val_loss: 0.5098 - val_acc: 0.7894\n",
      "\n",
      "Epoch 00017: val_acc did not improve from 0.79174\n",
      "Epoch 18/200\n",
      "1083/1083 [==============================] - 35s 33ms/step - loss: 0.5251 - acc: 0.7802 - val_loss: 0.4974 - val_acc: 0.7984\n",
      "\n",
      "Epoch 00018: val_acc improved from 0.79174 to 0.79844, saving model to best_model_g3.h5\n",
      "Epoch 19/200\n",
      "1083/1083 [==============================] - 35s 33ms/step - loss: 0.5165 - acc: 0.7820 - val_loss: 0.4879 - val_acc: 0.8043\n",
      "\n",
      "Epoch 00019: val_acc improved from 0.79844 to 0.80427, saving model to best_model_g3.h5\n",
      "Epoch 20/200\n",
      "1083/1083 [==============================] - 35s 33ms/step - loss: 0.5115 - acc: 0.7855 - val_loss: 0.4844 - val_acc: 0.8035\n",
      "\n",
      "Epoch 00020: val_acc did not improve from 0.80427\n",
      "Epoch 21/200\n",
      "1083/1083 [==============================] - 35s 33ms/step - loss: 0.5046 - acc: 0.7884 - val_loss: 0.4781 - val_acc: 0.8068\n",
      "\n",
      "Epoch 00021: val_acc improved from 0.80427 to 0.80676, saving model to best_model_g3.h5\n",
      "Epoch 22/200\n",
      "1083/1083 [==============================] - 35s 33ms/step - loss: 0.4980 - acc: 0.7926 - val_loss: 0.4856 - val_acc: 0.8020\n",
      "\n",
      "Epoch 00022: val_acc did not improve from 0.80676\n",
      "Epoch 23/200\n",
      "1083/1083 [==============================] - 35s 33ms/step - loss: 0.4922 - acc: 0.7935 - val_loss: 0.4721 - val_acc: 0.8077\n",
      "\n",
      "Epoch 00023: val_acc improved from 0.80676 to 0.80768, saving model to best_model_g3.h5\n",
      "Epoch 24/200\n",
      "1083/1083 [==============================] - 35s 32ms/step - loss: 0.4884 - acc: 0.7949 - val_loss: 0.4674 - val_acc: 0.8145\n",
      "\n",
      "Epoch 00024: val_acc improved from 0.80768 to 0.81455, saving model to best_model_g3.h5\n",
      "Epoch 25/200\n",
      "1083/1083 [==============================] - 35s 33ms/step - loss: 0.4841 - acc: 0.7980 - val_loss: 0.4607 - val_acc: 0.8129\n",
      "\n",
      "Epoch 00025: val_acc did not improve from 0.81455\n",
      "Epoch 26/200\n",
      "1083/1083 [==============================] - 35s 33ms/step - loss: 0.4817 - acc: 0.7983 - val_loss: 0.4633 - val_acc: 0.8127\n",
      "\n",
      "Epoch 00026: val_acc did not improve from 0.81455\n",
      "Epoch 27/200\n",
      "1083/1083 [==============================] - 35s 33ms/step - loss: 0.4755 - acc: 0.8012 - val_loss: 0.4557 - val_acc: 0.8188\n",
      "\n",
      "Epoch 00027: val_acc improved from 0.81455 to 0.81882, saving model to best_model_g3.h5\n",
      "Epoch 28/200\n",
      "1083/1083 [==============================] - 35s 33ms/step - loss: 0.4715 - acc: 0.8035 - val_loss: 0.4510 - val_acc: 0.8205\n",
      "\n",
      "Epoch 00028: val_acc improved from 0.81882 to 0.82050, saving model to best_model_g3.h5\n",
      "Epoch 29/200\n",
      "1083/1083 [==============================] - 35s 33ms/step - loss: 0.4695 - acc: 0.8045 - val_loss: 0.4506 - val_acc: 0.8203\n",
      "\n",
      "Epoch 00029: val_acc did not improve from 0.82050\n",
      "Epoch 30/200\n",
      "1083/1083 [==============================] - 35s 33ms/step - loss: 0.4643 - acc: 0.8067 - val_loss: 0.4596 - val_acc: 0.8152\n",
      "\n",
      "Epoch 00030: val_acc did not improve from 0.82050\n",
      "Epoch 31/200\n",
      "1083/1083 [==============================] - 35s 33ms/step - loss: 0.4611 - acc: 0.8101 - val_loss: 0.4396 - val_acc: 0.8261\n",
      "\n",
      "Epoch 00031: val_acc improved from 0.82050 to 0.82610, saving model to best_model_g3.h5\n",
      "Epoch 32/200\n",
      "1083/1083 [==============================] - 35s 33ms/step - loss: 0.4588 - acc: 0.8115 - val_loss: 0.4455 - val_acc: 0.8256\n",
      "\n",
      "Epoch 00032: val_acc did not improve from 0.82610\n",
      "Epoch 33/200\n",
      "1083/1083 [==============================] - 35s 33ms/step - loss: 0.4566 - acc: 0.8117 - val_loss: 0.4325 - val_acc: 0.8317\n",
      "\n",
      "Epoch 00033: val_acc improved from 0.82610 to 0.83170, saving model to best_model_g3.h5\n",
      "Epoch 34/200\n",
      "1083/1083 [==============================] - 35s 33ms/step - loss: 0.4483 - acc: 0.8142 - val_loss: 0.4279 - val_acc: 0.8338\n",
      "\n",
      "Epoch 00034: val_acc improved from 0.83170 to 0.83383, saving model to best_model_g3.h5\n",
      "Epoch 35/200\n",
      "1083/1083 [==============================] - 35s 33ms/step - loss: 0.4451 - acc: 0.8164 - val_loss: 0.4413 - val_acc: 0.8302\n",
      "\n",
      "Epoch 00035: val_acc did not improve from 0.83383\n",
      "Epoch 36/200\n",
      "1083/1083 [==============================] - 35s 33ms/step - loss: 0.4471 - acc: 0.8166 - val_loss: 0.4301 - val_acc: 0.8320\n",
      "\n",
      "Epoch 00036: val_acc did not improve from 0.83383\n",
      "Epoch 37/200\n",
      "1083/1083 [==============================] - 35s 33ms/step - loss: 0.4409 - acc: 0.8179 - val_loss: 0.4316 - val_acc: 0.8314\n",
      "\n",
      "Epoch 00037: val_acc did not improve from 0.83383\n",
      "Epoch 38/200\n",
      "1083/1083 [==============================] - 35s 33ms/step - loss: 0.4384 - acc: 0.8199 - val_loss: 0.4274 - val_acc: 0.8316\n",
      "\n",
      "Epoch 00038: val_acc did not improve from 0.83383\n",
      "Epoch 39/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1083/1083 [==============================] - 35s 33ms/step - loss: 0.4335 - acc: 0.8227 - val_loss: 0.4200 - val_acc: 0.8370\n",
      "\n",
      "Epoch 00039: val_acc improved from 0.83383 to 0.83701, saving model to best_model_g3.h5\n",
      "Epoch 40/200\n",
      "1083/1083 [==============================] - 35s 33ms/step - loss: 0.4345 - acc: 0.8220 - val_loss: 0.4211 - val_acc: 0.8353\n",
      "\n",
      "Epoch 00040: val_acc did not improve from 0.83701\n",
      "Epoch 41/200\n",
      "1083/1083 [==============================] - 35s 33ms/step - loss: 0.4287 - acc: 0.8255 - val_loss: 0.4217 - val_acc: 0.8367\n",
      "\n",
      "Epoch 00041: val_acc did not improve from 0.83701\n",
      "Epoch 42/200\n",
      "1083/1083 [==============================] - 35s 33ms/step - loss: 0.4293 - acc: 0.8239 - val_loss: 0.4148 - val_acc: 0.8405\n",
      "\n",
      "Epoch 00042: val_acc improved from 0.83701 to 0.84047, saving model to best_model_g3.h5\n",
      "Epoch 43/200\n",
      "1083/1083 [==============================] - 35s 33ms/step - loss: 0.4235 - acc: 0.8278 - val_loss: 0.4226 - val_acc: 0.8367\n",
      "\n",
      "Epoch 00043: val_acc did not improve from 0.84047\n",
      "Epoch 44/200\n",
      "1083/1083 [==============================] - 35s 33ms/step - loss: 0.4225 - acc: 0.8271 - val_loss: 0.4169 - val_acc: 0.8404\n",
      "\n",
      "Epoch 00044: val_acc did not improve from 0.84047\n",
      "Epoch 45/200\n",
      "1083/1083 [==============================] - 35s 33ms/step - loss: 0.4207 - acc: 0.8277 - val_loss: 0.4289 - val_acc: 0.8352\n",
      "\n",
      "Epoch 00045: val_acc did not improve from 0.84047\n",
      "Epoch 46/200\n",
      "1083/1083 [==============================] - 35s 33ms/step - loss: 0.4192 - acc: 0.8281 - val_loss: 0.4178 - val_acc: 0.8391\n",
      "\n",
      "Epoch 00046: val_acc did not improve from 0.84047\n",
      "Epoch 47/200\n",
      "1083/1083 [==============================] - 35s 33ms/step - loss: 0.4169 - acc: 0.8298 - val_loss: 0.4037 - val_acc: 0.8453\n",
      "\n",
      "Epoch 00047: val_acc improved from 0.84047 to 0.84527, saving model to best_model_g3.h5\n",
      "Epoch 48/200\n",
      "1083/1083 [==============================] - 35s 33ms/step - loss: 0.4143 - acc: 0.8299 - val_loss: 0.4107 - val_acc: 0.8431\n",
      "\n",
      "Epoch 00048: val_acc did not improve from 0.84527\n",
      "Epoch 49/200\n",
      "1083/1083 [==============================] - 35s 33ms/step - loss: 0.4069 - acc: 0.8334 - val_loss: 0.4172 - val_acc: 0.8415\n",
      "\n",
      "Epoch 00049: val_acc did not improve from 0.84527\n",
      "Epoch 50/200\n",
      "1083/1083 [==============================] - 35s 33ms/step - loss: 0.4104 - acc: 0.8338 - val_loss: 0.4072 - val_acc: 0.8460\n",
      "\n",
      "Epoch 00050: val_acc improved from 0.84527 to 0.84596, saving model to best_model_g3.h5\n",
      "Epoch 51/200\n",
      "1083/1083 [==============================] - 35s 33ms/step - loss: 0.4026 - acc: 0.8352 - val_loss: 0.4087 - val_acc: 0.8460\n",
      "\n",
      "Epoch 00051: val_acc improved from 0.84596 to 0.84602, saving model to best_model_g3.h5\n",
      "Epoch 52/200\n",
      "1083/1083 [==============================] - 35s 33ms/step - loss: 0.4056 - acc: 0.8344 - val_loss: 0.4114 - val_acc: 0.8443\n",
      "\n",
      "Epoch 00052: val_acc did not improve from 0.84602\n",
      "Epoch 53/200\n",
      "1083/1083 [==============================] - 35s 33ms/step - loss: 0.4022 - acc: 0.8360 - val_loss: 0.4041 - val_acc: 0.8420\n",
      "\n",
      "Epoch 00053: val_acc did not improve from 0.84602\n",
      "Epoch 54/200\n",
      "1083/1083 [==============================] - 35s 33ms/step - loss: 0.3972 - acc: 0.8384 - val_loss: 0.4101 - val_acc: 0.8440\n",
      "\n",
      "Epoch 00054: val_acc did not improve from 0.84602\n",
      "Epoch 55/200\n",
      "1083/1083 [==============================] - 35s 33ms/step - loss: 0.3995 - acc: 0.8372 - val_loss: 0.3963 - val_acc: 0.8480\n",
      "\n",
      "Epoch 00055: val_acc improved from 0.84602 to 0.84798, saving model to best_model_g3.h5\n",
      "Epoch 56/200\n",
      "1083/1083 [==============================] - 35s 33ms/step - loss: 0.3942 - acc: 0.8410 - val_loss: 0.3986 - val_acc: 0.8479\n",
      "\n",
      "Epoch 00056: val_acc did not improve from 0.84798\n",
      "Epoch 57/200\n",
      "1083/1083 [==============================] - 35s 33ms/step - loss: 0.3961 - acc: 0.8391 - val_loss: 0.3960 - val_acc: 0.8513\n",
      "\n",
      "Epoch 00057: val_acc improved from 0.84798 to 0.85127, saving model to best_model_g3.h5\n",
      "Epoch 58/200\n",
      "1083/1083 [==============================] - 35s 33ms/step - loss: 0.3920 - acc: 0.8391 - val_loss: 0.4013 - val_acc: 0.8499\n",
      "\n",
      "Epoch 00058: val_acc did not improve from 0.85127\n",
      "Epoch 59/200\n",
      "1083/1083 [==============================] - 35s 33ms/step - loss: 0.3913 - acc: 0.8420 - val_loss: 0.3973 - val_acc: 0.8510\n",
      "\n",
      "Epoch 00059: val_acc did not improve from 0.85127\n",
      "Epoch 60/200\n",
      "1083/1083 [==============================] - 36s 33ms/step - loss: 0.3922 - acc: 0.8402 - val_loss: 0.3894 - val_acc: 0.8528\n",
      "\n",
      "Epoch 00060: val_acc improved from 0.85127 to 0.85277, saving model to best_model_g3.h5\n",
      "Epoch 61/200\n",
      "1083/1083 [==============================] - 35s 33ms/step - loss: 0.3885 - acc: 0.8415 - val_loss: 0.3997 - val_acc: 0.8523\n",
      "\n",
      "Epoch 00061: val_acc did not improve from 0.85277\n",
      "Epoch 62/200\n",
      "1083/1083 [==============================] - 35s 33ms/step - loss: 0.3890 - acc: 0.8416 - val_loss: 0.4020 - val_acc: 0.8468\n",
      "\n",
      "Epoch 00062: val_acc did not improve from 0.85277\n",
      "Epoch 63/200\n",
      "1083/1083 [==============================] - 35s 33ms/step - loss: 0.3879 - acc: 0.8419 - val_loss: 0.3847 - val_acc: 0.8570\n",
      "\n",
      "Epoch 00063: val_acc improved from 0.85277 to 0.85699, saving model to best_model_g3.h5\n",
      "Epoch 64/200\n",
      "1083/1083 [==============================] - 35s 33ms/step - loss: 0.3842 - acc: 0.8442 - val_loss: 0.4030 - val_acc: 0.8491\n",
      "\n",
      "Epoch 00064: val_acc did not improve from 0.85699\n",
      "Epoch 65/200\n",
      "1083/1083 [==============================] - 35s 33ms/step - loss: 0.3817 - acc: 0.8433 - val_loss: 0.4020 - val_acc: 0.8487\n",
      "\n",
      "Epoch 00065: val_acc did not improve from 0.85699\n",
      "Epoch 66/200\n",
      "1083/1083 [==============================] - 35s 33ms/step - loss: 0.3816 - acc: 0.8453 - val_loss: 0.3811 - val_acc: 0.8574\n",
      "\n",
      "Epoch 00066: val_acc improved from 0.85699 to 0.85745, saving model to best_model_g3.h5\n",
      "Epoch 67/200\n",
      "1083/1083 [==============================] - 35s 33ms/step - loss: 0.3807 - acc: 0.8464 - val_loss: 0.3930 - val_acc: 0.8510\n",
      "\n",
      "Epoch 00067: val_acc did not improve from 0.85745\n",
      "Epoch 68/200\n",
      "1083/1083 [==============================] - 35s 33ms/step - loss: 0.3775 - acc: 0.8467 - val_loss: 0.3920 - val_acc: 0.8550\n",
      "\n",
      "Epoch 00068: val_acc did not improve from 0.85745\n",
      "Epoch 69/200\n",
      "1083/1083 [==============================] - 35s 33ms/step - loss: 0.3777 - acc: 0.8478 - val_loss: 0.3790 - val_acc: 0.8579\n",
      "\n",
      "Epoch 00069: val_acc improved from 0.85745 to 0.85785, saving model to best_model_g3.h5\n",
      "Epoch 70/200\n",
      "1083/1083 [==============================] - 35s 33ms/step - loss: 0.3770 - acc: 0.8471 - val_loss: 0.3664 - val_acc: 0.8641\n",
      "\n",
      "Epoch 00070: val_acc improved from 0.85785 to 0.86409, saving model to best_model_g3.h5\n",
      "Epoch 71/200\n",
      "1083/1083 [==============================] - 35s 33ms/step - loss: 0.3723 - acc: 0.8490 - val_loss: 0.3747 - val_acc: 0.8602\n",
      "\n",
      "Epoch 00071: val_acc did not improve from 0.86409\n",
      "Epoch 72/200\n",
      "1083/1083 [==============================] - 35s 33ms/step - loss: 0.3698 - acc: 0.8504 - val_loss: 0.3778 - val_acc: 0.8613\n",
      "\n",
      "Epoch 00072: val_acc did not improve from 0.86409\n",
      "Epoch 73/200\n",
      "1083/1083 [==============================] - 35s 33ms/step - loss: 0.3740 - acc: 0.8490 - val_loss: 0.3913 - val_acc: 0.8568\n",
      "\n",
      "Epoch 00073: val_acc did not improve from 0.86409\n",
      "Epoch 74/200\n",
      "1083/1083 [==============================] - 35s 33ms/step - loss: 0.3682 - acc: 0.8503 - val_loss: 0.3831 - val_acc: 0.8591\n",
      "\n",
      "Epoch 00074: val_acc did not improve from 0.86409\n",
      "Epoch 75/200\n",
      "1083/1083 [==============================] - 35s 33ms/step - loss: 0.3665 - acc: 0.8504 - val_loss: 0.3963 - val_acc: 0.8519\n",
      "\n",
      "Epoch 00075: val_acc did not improve from 0.86409\n",
      "Epoch 76/200\n",
      "1083/1083 [==============================] - 35s 33ms/step - loss: 0.3670 - acc: 0.8504 - val_loss: 0.3980 - val_acc: 0.8498\n",
      "\n",
      "Epoch 00076: val_acc did not improve from 0.86409\n",
      "Epoch 77/200\n",
      "1083/1083 [==============================] - 35s 33ms/step - loss: 0.3640 - acc: 0.8536 - val_loss: 0.4011 - val_acc: 0.8502\n",
      "\n",
      "Epoch 00077: val_acc did not improve from 0.86409\n",
      "Epoch 78/200\n",
      "1083/1083 [==============================] - 35s 33ms/step - loss: 0.3662 - acc: 0.8529 - val_loss: 0.3894 - val_acc: 0.8570\n",
      "\n",
      "Epoch 00078: val_acc did not improve from 0.86409\n",
      "Epoch 79/200\n",
      "1083/1083 [==============================] - 35s 33ms/step - loss: 0.3672 - acc: 0.8519 - val_loss: 0.3776 - val_acc: 0.8625\n",
      "\n",
      "Epoch 00079: val_acc did not improve from 0.86409\n",
      "Epoch 80/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1083/1083 [==============================] - 35s 33ms/step - loss: 0.3622 - acc: 0.8528 - val_loss: 0.3904 - val_acc: 0.8567\n",
      "\n",
      "Epoch 00080: val_acc did not improve from 0.86409\n",
      "Epoch 81/200\n",
      "1083/1083 [==============================] - 35s 33ms/step - loss: 0.3614 - acc: 0.8544 - val_loss: 0.3809 - val_acc: 0.8582\n",
      "\n",
      "Epoch 00081: val_acc did not improve from 0.86409\n",
      "Epoch 82/200\n",
      "1083/1083 [==============================] - 35s 33ms/step - loss: 0.3619 - acc: 0.8547 - val_loss: 0.4000 - val_acc: 0.8516\n",
      "\n",
      "Epoch 00082: val_acc did not improve from 0.86409\n",
      "Epoch 83/200\n",
      "1083/1083 [==============================] - 35s 33ms/step - loss: 0.3577 - acc: 0.8551 - val_loss: 0.3938 - val_acc: 0.8540\n",
      "\n",
      "Epoch 00083: val_acc did not improve from 0.86409\n",
      "Epoch 84/200\n",
      "1083/1083 [==============================] - 35s 33ms/step - loss: 0.3552 - acc: 0.8564 - val_loss: 0.3756 - val_acc: 0.8626\n",
      "\n",
      "Epoch 00084: val_acc did not improve from 0.86409\n",
      "Epoch 85/200\n",
      "1083/1083 [==============================] - 35s 33ms/step - loss: 0.3541 - acc: 0.8564 - val_loss: 0.3757 - val_acc: 0.8632\n",
      "\n",
      "Epoch 00085: val_acc did not improve from 0.86409\n",
      "Epoch 86/200\n",
      "1083/1083 [==============================] - 35s 33ms/step - loss: 0.3550 - acc: 0.8565 - val_loss: 0.3769 - val_acc: 0.8635\n",
      "\n",
      "Epoch 00086: val_acc did not improve from 0.86409\n",
      "Epoch 87/200\n",
      "1083/1083 [==============================] - 35s 33ms/step - loss: 0.3508 - acc: 0.8579 - val_loss: 0.3770 - val_acc: 0.8633\n",
      "\n",
      "Epoch 00087: val_acc did not improve from 0.86409\n",
      "Epoch 88/200\n",
      "1083/1083 [==============================] - 35s 33ms/step - loss: 0.3496 - acc: 0.8610 - val_loss: 0.4024 - val_acc: 0.8509\n",
      "\n",
      "Epoch 00088: val_acc did not improve from 0.86409\n",
      "Epoch 89/200\n",
      "1083/1083 [==============================] - 35s 33ms/step - loss: 0.3515 - acc: 0.8590 - val_loss: 0.3898 - val_acc: 0.8559\n",
      "\n",
      "Epoch 00089: val_acc did not improve from 0.86409\n",
      "Epoch 90/200\n",
      "1083/1083 [==============================] - 35s 33ms/step - loss: 0.3471 - acc: 0.8598 - val_loss: 0.3794 - val_acc: 0.8632\n",
      "\n",
      "Epoch 00090: val_acc did not improve from 0.86409\n",
      "Epoch 91/200\n",
      "1083/1083 [==============================] - 35s 33ms/step - loss: 0.3458 - acc: 0.8615 - val_loss: 0.3713 - val_acc: 0.8661\n",
      "\n",
      "Epoch 00091: val_acc improved from 0.86409 to 0.86605, saving model to best_model_g3.h5\n",
      "Epoch 92/200\n",
      "1083/1083 [==============================] - 35s 33ms/step - loss: 0.3489 - acc: 0.8594 - val_loss: 0.3940 - val_acc: 0.8586\n",
      "\n",
      "Epoch 00092: val_acc did not improve from 0.86605\n",
      "Epoch 93/200\n",
      "1083/1083 [==============================] - 35s 33ms/step - loss: 0.3472 - acc: 0.8599 - val_loss: 0.3717 - val_acc: 0.8636\n",
      "\n",
      "Epoch 00093: val_acc did not improve from 0.86605\n",
      "Epoch 94/200\n",
      "1083/1083 [==============================] - 35s 33ms/step - loss: 0.3474 - acc: 0.8595 - val_loss: 0.3639 - val_acc: 0.8658\n",
      "\n",
      "Epoch 00094: val_acc did not improve from 0.86605\n",
      "Epoch 95/200\n",
      "1083/1083 [==============================] - 35s 33ms/step - loss: 0.3423 - acc: 0.8623 - val_loss: 0.3719 - val_acc: 0.8659\n",
      "\n",
      "Epoch 00095: val_acc did not improve from 0.86605\n",
      "Epoch 96/200\n",
      "1083/1083 [==============================] - 35s 33ms/step - loss: 0.3435 - acc: 0.8622 - val_loss: 0.3715 - val_acc: 0.8621\n",
      "\n",
      "Epoch 00096: val_acc did not improve from 0.86605\n",
      "Epoch 97/200\n",
      "1083/1083 [==============================] - 35s 33ms/step - loss: 0.3450 - acc: 0.8605 - val_loss: 0.3793 - val_acc: 0.8612\n",
      "\n",
      "Epoch 00097: val_acc did not improve from 0.86605\n",
      "Epoch 98/200\n",
      "1083/1083 [==============================] - 35s 33ms/step - loss: 0.3412 - acc: 0.8633 - val_loss: 0.3670 - val_acc: 0.8693\n",
      "\n",
      "Epoch 00098: val_acc improved from 0.86605 to 0.86934, saving model to best_model_g3.h5\n",
      "Epoch 99/200\n",
      "1083/1083 [==============================] - 35s 33ms/step - loss: 0.3395 - acc: 0.8640 - val_loss: 0.3797 - val_acc: 0.8643\n",
      "\n",
      "Epoch 00099: val_acc did not improve from 0.86934\n",
      "Epoch 100/200\n",
      "1083/1083 [==============================] - 35s 33ms/step - loss: 0.3358 - acc: 0.8633 - val_loss: 0.3818 - val_acc: 0.8621\n",
      "\n",
      "Epoch 00100: val_acc did not improve from 0.86934\n",
      "Epoch 101/200\n",
      "1083/1083 [==============================] - 35s 33ms/step - loss: 0.3378 - acc: 0.8637 - val_loss: 0.3685 - val_acc: 0.8652\n",
      "\n",
      "Epoch 00101: val_acc did not improve from 0.86934\n",
      "Epoch 102/200\n",
      "1083/1083 [==============================] - 35s 33ms/step - loss: 0.3358 - acc: 0.8660 - val_loss: 0.3819 - val_acc: 0.8610\n",
      "\n",
      "Epoch 00102: val_acc did not improve from 0.86934\n",
      "Epoch 103/200\n",
      "1083/1083 [==============================] - 35s 33ms/step - loss: 0.3386 - acc: 0.8644 - val_loss: 0.3713 - val_acc: 0.8681\n",
      "\n",
      "Epoch 00103: val_acc did not improve from 0.86934\n",
      "Epoch 104/200\n",
      "1083/1083 [==============================] - 35s 33ms/step - loss: 0.3341 - acc: 0.8664 - val_loss: 0.4033 - val_acc: 0.8594\n",
      "\n",
      "Epoch 00104: val_acc did not improve from 0.86934\n",
      "Epoch 105/200\n",
      "1083/1083 [==============================] - 35s 33ms/step - loss: 0.3313 - acc: 0.8669 - val_loss: 0.3756 - val_acc: 0.8644\n",
      "\n",
      "Epoch 00105: val_acc did not improve from 0.86934\n",
      "Epoch 106/200\n",
      "1083/1083 [==============================] - 35s 33ms/step - loss: 0.3317 - acc: 0.8672 - val_loss: 0.3921 - val_acc: 0.8601\n",
      "\n",
      "Epoch 00106: val_acc did not improve from 0.86934\n",
      "Epoch 107/200\n",
      "1083/1083 [==============================] - 35s 33ms/step - loss: 0.3340 - acc: 0.8658 - val_loss: 0.3713 - val_acc: 0.8658\n",
      "\n",
      "Epoch 00107: val_acc did not improve from 0.86934\n",
      "Epoch 108/200\n",
      "1083/1083 [==============================] - 35s 33ms/step - loss: 0.3324 - acc: 0.8662 - val_loss: 0.3650 - val_acc: 0.8704\n",
      "\n",
      "Epoch 00108: val_acc improved from 0.86934 to 0.87044, saving model to best_model_g3.h5\n",
      "Epoch 109/200\n",
      "1083/1083 [==============================] - 35s 33ms/step - loss: 0.3304 - acc: 0.8669 - val_loss: 0.3882 - val_acc: 0.8611\n",
      "\n",
      "Epoch 00109: val_acc did not improve from 0.87044\n",
      "Epoch 110/200\n",
      "1083/1083 [==============================] - 35s 33ms/step - loss: 0.3294 - acc: 0.8684 - val_loss: 0.3687 - val_acc: 0.8678\n",
      "\n",
      "Epoch 00110: val_acc did not improve from 0.87044\n",
      "Epoch 111/200\n",
      "1083/1083 [==============================] - 35s 33ms/step - loss: 0.3297 - acc: 0.8671 - val_loss: 0.3707 - val_acc: 0.8645\n",
      "\n",
      "Epoch 00111: val_acc did not improve from 0.87044\n",
      "Epoch 112/200\n",
      "1083/1083 [==============================] - 35s 33ms/step - loss: 0.3293 - acc: 0.8684 - val_loss: 0.3748 - val_acc: 0.8662\n",
      "\n",
      "Epoch 00112: val_acc did not improve from 0.87044\n",
      "Epoch 113/200\n",
      "1083/1083 [==============================] - 35s 33ms/step - loss: 0.3278 - acc: 0.8683 - val_loss: 0.3787 - val_acc: 0.8640\n",
      "\n",
      "Epoch 00113: val_acc did not improve from 0.87044\n",
      "Epoch 114/200\n",
      "1083/1083 [==============================] - 35s 33ms/step - loss: 0.3258 - acc: 0.8698 - val_loss: 0.3575 - val_acc: 0.8725\n",
      "\n",
      "Epoch 00114: val_acc improved from 0.87044 to 0.87246, saving model to best_model_g3.h5\n",
      "Epoch 115/200\n",
      "1083/1083 [==============================] - 35s 33ms/step - loss: 0.3246 - acc: 0.8710 - val_loss: 0.3629 - val_acc: 0.8726\n",
      "\n",
      "Epoch 00115: val_acc improved from 0.87246 to 0.87258, saving model to best_model_g3.h5\n",
      "Epoch 116/200\n",
      "1083/1083 [==============================] - 35s 33ms/step - loss: 0.3212 - acc: 0.8713 - val_loss: 0.3788 - val_acc: 0.8676\n",
      "\n",
      "Epoch 00116: val_acc did not improve from 0.87258\n",
      "Epoch 117/200\n",
      "1083/1083 [==============================] - 35s 33ms/step - loss: 0.3239 - acc: 0.8701 - val_loss: 0.3648 - val_acc: 0.8708\n",
      "\n",
      "Epoch 00117: val_acc did not improve from 0.87258\n",
      "Epoch 118/200\n",
      "1083/1083 [==============================] - 35s 33ms/step - loss: 0.3214 - acc: 0.8721 - val_loss: 0.3749 - val_acc: 0.8641\n",
      "\n",
      "Epoch 00118: val_acc did not improve from 0.87258\n",
      "Epoch 119/200\n",
      "1083/1083 [==============================] - 35s 33ms/step - loss: 0.3241 - acc: 0.8687 - val_loss: 0.3745 - val_acc: 0.8680\n",
      "\n",
      "Epoch 00119: val_acc did not improve from 0.87258\n",
      "Epoch 120/200\n",
      "1083/1083 [==============================] - 35s 33ms/step - loss: 0.3224 - acc: 0.8721 - val_loss: 0.3670 - val_acc: 0.8688\n",
      "\n",
      "Epoch 00120: val_acc did not improve from 0.87258\n",
      "Epoch 121/200\n",
      "1083/1083 [==============================] - 35s 33ms/step - loss: 0.3203 - acc: 0.8711 - val_loss: 0.3817 - val_acc: 0.8681\n",
      "\n",
      "Epoch 00121: val_acc did not improve from 0.87258\n",
      "Epoch 122/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1083/1083 [==============================] - 35s 33ms/step - loss: 0.3183 - acc: 0.8734 - val_loss: 0.3722 - val_acc: 0.8687\n",
      "\n",
      "Epoch 00122: val_acc did not improve from 0.87258\n",
      "Epoch 123/200\n",
      "1083/1083 [==============================] - 35s 33ms/step - loss: 0.3181 - acc: 0.8729 - val_loss: 0.3781 - val_acc: 0.8679\n",
      "\n",
      "Epoch 00123: val_acc did not improve from 0.87258\n",
      "Epoch 124/200\n",
      "1083/1083 [==============================] - 35s 33ms/step - loss: 0.3147 - acc: 0.8749 - val_loss: 0.3836 - val_acc: 0.8632\n",
      "\n",
      "Epoch 00124: val_acc did not improve from 0.87258\n",
      "Epoch 125/200\n",
      "1083/1083 [==============================] - 35s 33ms/step - loss: 0.3143 - acc: 0.8751 - val_loss: 0.3899 - val_acc: 0.8655\n",
      "\n",
      "Epoch 00125: val_acc did not improve from 0.87258\n",
      "Epoch 126/200\n",
      "1083/1083 [==============================] - 35s 33ms/step - loss: 0.3109 - acc: 0.8767 - val_loss: 0.3777 - val_acc: 0.8721\n",
      "\n",
      "Epoch 00126: val_acc did not improve from 0.87258\n",
      "Epoch 127/200\n",
      "1083/1083 [==============================] - 35s 33ms/step - loss: 0.3145 - acc: 0.8742 - val_loss: 0.4032 - val_acc: 0.8625\n",
      "\n",
      "Epoch 00127: val_acc did not improve from 0.87258\n",
      "Epoch 128/200\n",
      "1083/1083 [==============================] - 35s 33ms/step - loss: 0.3152 - acc: 0.8748 - val_loss: 0.3812 - val_acc: 0.8684\n",
      "\n",
      "Epoch 00128: val_acc did not improve from 0.87258\n",
      "Epoch 129/200\n",
      "1083/1083 [==============================] - 35s 33ms/step - loss: 0.3145 - acc: 0.8750 - val_loss: 0.4025 - val_acc: 0.8614\n",
      "\n",
      "Epoch 00129: val_acc did not improve from 0.87258\n",
      "Epoch 130/200\n",
      "1083/1083 [==============================] - 35s 33ms/step - loss: 0.3126 - acc: 0.8755 - val_loss: 0.3884 - val_acc: 0.8635\n",
      "\n",
      "Epoch 00130: val_acc did not improve from 0.87258\n",
      "Epoch 131/200\n",
      "1083/1083 [==============================] - 35s 33ms/step - loss: 0.3125 - acc: 0.8754 - val_loss: 0.3856 - val_acc: 0.8629\n",
      "\n",
      "Epoch 00131: val_acc did not improve from 0.87258\n",
      "Epoch 132/200\n",
      "1083/1083 [==============================] - 35s 33ms/step - loss: 0.3137 - acc: 0.8757 - val_loss: 0.3932 - val_acc: 0.8632\n",
      "\n",
      "Epoch 00132: val_acc did not improve from 0.87258\n",
      "Epoch 133/200\n",
      "1083/1083 [==============================] - 35s 33ms/step - loss: 0.3074 - acc: 0.8778 - val_loss: 0.3673 - val_acc: 0.8707\n",
      "\n",
      "Epoch 00133: val_acc did not improve from 0.87258\n",
      "Epoch 134/200\n",
      "1083/1083 [==============================] - 35s 33ms/step - loss: 0.3084 - acc: 0.8777 - val_loss: 0.3724 - val_acc: 0.8690\n",
      "\n",
      "Epoch 00134: val_acc did not improve from 0.87258\n",
      "Epoch 135/200\n",
      "1083/1083 [==============================] - 35s 33ms/step - loss: 0.3100 - acc: 0.8764 - val_loss: 0.3732 - val_acc: 0.8689\n",
      "\n",
      "Epoch 00135: val_acc did not improve from 0.87258\n",
      "Epoch 136/200\n",
      "1083/1083 [==============================] - 35s 33ms/step - loss: 0.3095 - acc: 0.8768 - val_loss: 0.3606 - val_acc: 0.8719\n",
      "\n",
      "Epoch 00136: val_acc did not improve from 0.87258\n",
      "Epoch 137/200\n",
      "1083/1083 [==============================] - 35s 33ms/step - loss: 0.3061 - acc: 0.8777 - val_loss: 0.3709 - val_acc: 0.8701\n",
      "\n",
      "Epoch 00137: val_acc did not improve from 0.87258\n",
      "Epoch 138/200\n",
      "1083/1083 [==============================] - 35s 33ms/step - loss: 0.3034 - acc: 0.8779 - val_loss: 0.3800 - val_acc: 0.8680\n",
      "\n",
      "Epoch 00138: val_acc did not improve from 0.87258\n",
      "Epoch 139/200\n",
      "1083/1083 [==============================] - 35s 33ms/step - loss: 0.3050 - acc: 0.8786 - val_loss: 0.3799 - val_acc: 0.8679\n",
      "\n",
      "Epoch 00139: val_acc did not improve from 0.87258\n",
      "Epoch 140/200\n",
      "1083/1083 [==============================] - 35s 33ms/step - loss: 0.3068 - acc: 0.8776 - val_loss: 0.3655 - val_acc: 0.8754\n",
      "\n",
      "Epoch 00140: val_acc improved from 0.87258 to 0.87540, saving model to best_model_g3.h5\n",
      "Epoch 141/200\n",
      "1083/1083 [==============================] - 35s 33ms/step - loss: 0.3041 - acc: 0.8795 - val_loss: 0.3837 - val_acc: 0.8658\n",
      "\n",
      "Epoch 00141: val_acc did not improve from 0.87540\n",
      "Epoch 142/200\n",
      "1083/1083 [==============================] - 36s 33ms/step - loss: 0.3033 - acc: 0.8804 - val_loss: 0.3783 - val_acc: 0.8701\n",
      "\n",
      "Epoch 00142: val_acc did not improve from 0.87540\n",
      "Epoch 143/200\n",
      "1083/1083 [==============================] - 35s 33ms/step - loss: 0.3026 - acc: 0.8788 - val_loss: 0.3731 - val_acc: 0.8740\n",
      "\n",
      "Epoch 00143: val_acc did not improve from 0.87540\n",
      "Epoch 144/200\n",
      "1083/1083 [==============================] - 35s 33ms/step - loss: 0.3019 - acc: 0.8800 - val_loss: 0.3728 - val_acc: 0.8689\n",
      "\n",
      "Epoch 00144: val_acc did not improve from 0.87540\n",
      "Epoch 145/200\n",
      "1083/1083 [==============================] - 35s 33ms/step - loss: 0.2999 - acc: 0.8812 - val_loss: 0.3652 - val_acc: 0.8682\n",
      "\n",
      "Epoch 00145: val_acc did not improve from 0.87540\n",
      "Epoch 146/200\n",
      "1083/1083 [==============================] - 35s 33ms/step - loss: 0.2987 - acc: 0.8814 - val_loss: 0.3953 - val_acc: 0.8660\n",
      "\n",
      "Epoch 00146: val_acc did not improve from 0.87540\n",
      "Epoch 147/200\n",
      "1083/1083 [==============================] - 35s 33ms/step - loss: 0.2992 - acc: 0.8807 - val_loss: 0.3631 - val_acc: 0.8743\n",
      "\n",
      "Epoch 00147: val_acc did not improve from 0.87540\n",
      "Epoch 148/200\n",
      "1083/1083 [==============================] - 35s 33ms/step - loss: 0.2982 - acc: 0.8815 - val_loss: 0.3866 - val_acc: 0.8662\n",
      "\n",
      "Epoch 00148: val_acc did not improve from 0.87540\n",
      "Epoch 149/200\n",
      "1083/1083 [==============================] - 35s 33ms/step - loss: 0.2997 - acc: 0.8806 - val_loss: 0.3829 - val_acc: 0.8687\n",
      "\n",
      "Epoch 00149: val_acc did not improve from 0.87540\n",
      "Epoch 150/200\n",
      "1083/1083 [==============================] - 35s 33ms/step - loss: 0.3002 - acc: 0.8806 - val_loss: 0.3908 - val_acc: 0.8658\n",
      "\n",
      "Epoch 00150: val_acc did not improve from 0.87540\n",
      "Epoch 151/200\n",
      "1083/1083 [==============================] - 35s 33ms/step - loss: 0.2967 - acc: 0.8824 - val_loss: 0.3761 - val_acc: 0.8744\n",
      "\n",
      "Epoch 00151: val_acc did not improve from 0.87540\n",
      "Epoch 152/200\n",
      "1083/1083 [==============================] - 35s 33ms/step - loss: 0.2964 - acc: 0.8817 - val_loss: 0.3669 - val_acc: 0.8732\n",
      "\n",
      "Epoch 00152: val_acc did not improve from 0.87540\n",
      "Epoch 153/200\n",
      "1083/1083 [==============================] - 35s 33ms/step - loss: 0.2960 - acc: 0.8820 - val_loss: 0.3654 - val_acc: 0.8747\n",
      "\n",
      "Epoch 00153: val_acc did not improve from 0.87540\n",
      "Epoch 154/200\n",
      "1083/1083 [==============================] - 35s 33ms/step - loss: 0.2946 - acc: 0.8818 - val_loss: 0.3954 - val_acc: 0.8666\n",
      "\n",
      "Epoch 00154: val_acc did not improve from 0.87540\n",
      "Epoch 155/200\n",
      "1083/1083 [==============================] - 35s 33ms/step - loss: 0.2940 - acc: 0.8843 - val_loss: 0.3703 - val_acc: 0.8695\n",
      "\n",
      "Epoch 00155: val_acc did not improve from 0.87540\n",
      "Epoch 156/200\n",
      "1083/1083 [==============================] - 35s 33ms/step - loss: 0.2964 - acc: 0.8827 - val_loss: 0.3632 - val_acc: 0.8759\n",
      "\n",
      "Epoch 00156: val_acc improved from 0.87540 to 0.87587, saving model to best_model_g3.h5\n",
      "Epoch 157/200\n",
      "1083/1083 [==============================] - 35s 33ms/step - loss: 0.2992 - acc: 0.8812 - val_loss: 0.3568 - val_acc: 0.8766\n",
      "\n",
      "Epoch 00157: val_acc improved from 0.87587 to 0.87656, saving model to best_model_g3.h5\n",
      "Epoch 158/200\n",
      "1083/1083 [==============================] - 35s 33ms/step - loss: 0.2896 - acc: 0.8859 - val_loss: 0.3774 - val_acc: 0.8728\n",
      "\n",
      "Epoch 00158: val_acc did not improve from 0.87656\n",
      "Epoch 159/200\n",
      "1083/1083 [==============================] - 35s 33ms/step - loss: 0.2915 - acc: 0.8863 - val_loss: 0.3646 - val_acc: 0.8770\n",
      "\n",
      "Epoch 00159: val_acc improved from 0.87656 to 0.87696, saving model to best_model_g3.h5\n",
      "Epoch 160/200\n",
      "1083/1083 [==============================] - 35s 33ms/step - loss: 0.2935 - acc: 0.8842 - val_loss: 0.3828 - val_acc: 0.8713\n",
      "\n",
      "Epoch 00160: val_acc did not improve from 0.87696\n",
      "Epoch 161/200\n",
      "1083/1083 [==============================] - 35s 33ms/step - loss: 0.2899 - acc: 0.8856 - val_loss: 0.3559 - val_acc: 0.8776\n",
      "\n",
      "Epoch 00161: val_acc improved from 0.87696 to 0.87760, saving model to best_model_g3.h5\n",
      "Epoch 162/200\n",
      "1083/1083 [==============================] - 35s 33ms/step - loss: 0.2890 - acc: 0.8853 - val_loss: 0.3723 - val_acc: 0.8703\n",
      "\n",
      "Epoch 00162: val_acc did not improve from 0.87760\n",
      "Epoch 163/200\n",
      "1083/1083 [==============================] - 35s 33ms/step - loss: 0.2905 - acc: 0.8843 - val_loss: 0.3574 - val_acc: 0.8797\n",
      "\n",
      "Epoch 00163: val_acc improved from 0.87760 to 0.87968, saving model to best_model_g3.h5\n",
      "Epoch 164/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1083/1083 [==============================] - 35s 33ms/step - loss: 0.2889 - acc: 0.8849 - val_loss: 0.3952 - val_acc: 0.8659\n",
      "\n",
      "Epoch 00164: val_acc did not improve from 0.87968\n",
      "Epoch 165/200\n",
      "1083/1083 [==============================] - 35s 33ms/step - loss: 0.2885 - acc: 0.8863 - val_loss: 0.3992 - val_acc: 0.8663\n",
      "\n",
      "Epoch 00165: val_acc did not improve from 0.87968\n",
      "Epoch 166/200\n",
      "1083/1083 [==============================] - 35s 33ms/step - loss: 0.2857 - acc: 0.8874 - val_loss: 0.3930 - val_acc: 0.8690\n",
      "\n",
      "Epoch 00166: val_acc did not improve from 0.87968\n",
      "Epoch 167/200\n",
      "1083/1083 [==============================] - 35s 33ms/step - loss: 0.2913 - acc: 0.8853 - val_loss: 0.3699 - val_acc: 0.8749\n",
      "\n",
      "Epoch 00167: val_acc did not improve from 0.87968\n",
      "Epoch 168/200\n",
      "1083/1083 [==============================] - 35s 33ms/step - loss: 0.2863 - acc: 0.8867 - val_loss: 0.3740 - val_acc: 0.8754\n",
      "\n",
      "Epoch 00168: val_acc did not improve from 0.87968\n",
      "Epoch 169/200\n",
      "1083/1083 [==============================] - 35s 33ms/step - loss: 0.2848 - acc: 0.8880 - val_loss: 0.3957 - val_acc: 0.8685\n",
      "\n",
      "Epoch 00169: val_acc did not improve from 0.87968\n",
      "Epoch 170/200\n",
      "1083/1083 [==============================] - 35s 33ms/step - loss: 0.2871 - acc: 0.8856 - val_loss: 0.3659 - val_acc: 0.8721\n",
      "\n",
      "Epoch 00170: val_acc did not improve from 0.87968\n",
      "Epoch 171/200\n",
      "1083/1083 [==============================] - 35s 33ms/step - loss: 0.2836 - acc: 0.8879 - val_loss: 0.3913 - val_acc: 0.8704\n",
      "\n",
      "Epoch 00171: val_acc did not improve from 0.87968\n",
      "Epoch 172/200\n",
      "1083/1083 [==============================] - 35s 33ms/step - loss: 0.2830 - acc: 0.8891 - val_loss: 0.3758 - val_acc: 0.8748\n",
      "\n",
      "Epoch 00172: val_acc did not improve from 0.87968\n",
      "Epoch 173/200\n",
      "1083/1083 [==============================] - 35s 33ms/step - loss: 0.2842 - acc: 0.8873 - val_loss: 0.3549 - val_acc: 0.8789\n",
      "\n",
      "Epoch 00173: val_acc did not improve from 0.87968\n",
      "Epoch 174/200\n",
      "1083/1083 [==============================] - 35s 33ms/step - loss: 0.2822 - acc: 0.8887 - val_loss: 0.3827 - val_acc: 0.8672\n",
      "\n",
      "Epoch 00174: val_acc did not improve from 0.87968\n",
      "Epoch 175/200\n",
      "1083/1083 [==============================] - 35s 33ms/step - loss: 0.2822 - acc: 0.8892 - val_loss: 0.3610 - val_acc: 0.8771\n",
      "\n",
      "Epoch 00175: val_acc did not improve from 0.87968\n",
      "Epoch 176/200\n",
      "1083/1083 [==============================] - 35s 33ms/step - loss: 0.2799 - acc: 0.8895 - val_loss: 0.3631 - val_acc: 0.8760\n",
      "\n",
      "Epoch 00176: val_acc did not improve from 0.87968\n",
      "Epoch 177/200\n",
      "1083/1083 [==============================] - 35s 33ms/step - loss: 0.2778 - acc: 0.8889 - val_loss: 0.3729 - val_acc: 0.8736\n",
      "\n",
      "Epoch 00177: val_acc did not improve from 0.87968\n",
      "Epoch 178/200\n",
      "1083/1083 [==============================] - 35s 33ms/step - loss: 0.2828 - acc: 0.8887 - val_loss: 0.3554 - val_acc: 0.8793\n",
      "\n",
      "Epoch 00178: val_acc did not improve from 0.87968\n",
      "Epoch 179/200\n",
      "1083/1083 [==============================] - 35s 33ms/step - loss: 0.2794 - acc: 0.8887 - val_loss: 0.3586 - val_acc: 0.8780\n",
      "\n",
      "Epoch 00179: val_acc did not improve from 0.87968\n",
      "Epoch 180/200\n",
      "1083/1083 [==============================] - 35s 33ms/step - loss: 0.2821 - acc: 0.8880 - val_loss: 0.3643 - val_acc: 0.8785\n",
      "\n",
      "Epoch 00180: val_acc did not improve from 0.87968\n",
      "Epoch 181/200\n",
      "1083/1083 [==============================] - 35s 33ms/step - loss: 0.2811 - acc: 0.8905 - val_loss: 0.3655 - val_acc: 0.8774\n",
      "\n",
      "Epoch 00181: val_acc did not improve from 0.87968\n",
      "Epoch 182/200\n",
      "1083/1083 [==============================] - 35s 33ms/step - loss: 0.2775 - acc: 0.8916 - val_loss: 0.3758 - val_acc: 0.8707\n",
      "\n",
      "Epoch 00182: val_acc did not improve from 0.87968\n",
      "Epoch 183/200\n",
      "1083/1083 [==============================] - 35s 33ms/step - loss: 0.2811 - acc: 0.8892 - val_loss: 0.3743 - val_acc: 0.8727\n",
      "\n",
      "Epoch 00183: val_acc did not improve from 0.87968\n",
      "Epoch 184/200\n",
      "1083/1083 [==============================] - 35s 33ms/step - loss: 0.2825 - acc: 0.8888 - val_loss: 0.3673 - val_acc: 0.8751\n",
      "\n",
      "Epoch 00184: val_acc did not improve from 0.87968\n",
      "Epoch 185/200\n",
      "1083/1083 [==============================] - 35s 33ms/step - loss: 0.2777 - acc: 0.8906 - val_loss: 0.3769 - val_acc: 0.8753\n",
      "\n",
      "Epoch 00185: val_acc did not improve from 0.87968\n",
      "Epoch 186/200\n",
      "1083/1083 [==============================] - 35s 33ms/step - loss: 0.2768 - acc: 0.8907 - val_loss: 0.3776 - val_acc: 0.8732\n",
      "\n",
      "Epoch 00186: val_acc did not improve from 0.87968\n",
      "Epoch 187/200\n",
      "1083/1083 [==============================] - 35s 33ms/step - loss: 0.2789 - acc: 0.8902 - val_loss: 0.3691 - val_acc: 0.8765\n",
      "\n",
      "Epoch 00187: val_acc did not improve from 0.87968\n",
      "Epoch 188/200\n",
      "1083/1083 [==============================] - 35s 33ms/step - loss: 0.2753 - acc: 0.8925 - val_loss: 0.3572 - val_acc: 0.8805\n",
      "\n",
      "Epoch 00188: val_acc improved from 0.87968 to 0.88048, saving model to best_model_g3.h5\n",
      "Epoch 189/200\n",
      "1083/1083 [==============================] - 35s 33ms/step - loss: 0.2776 - acc: 0.8894 - val_loss: 0.3603 - val_acc: 0.8812\n",
      "\n",
      "Epoch 00189: val_acc improved from 0.88048 to 0.88124, saving model to best_model_g3.h5\n",
      "Epoch 190/200\n",
      "1083/1083 [==============================] - 35s 33ms/step - loss: 0.2731 - acc: 0.8918 - val_loss: 0.3855 - val_acc: 0.8734\n",
      "\n",
      "Epoch 00190: val_acc did not improve from 0.88124\n",
      "Epoch 191/200\n",
      "1083/1083 [==============================] - 35s 33ms/step - loss: 0.2733 - acc: 0.8918 - val_loss: 0.3791 - val_acc: 0.8747\n",
      "\n",
      "Epoch 00191: val_acc did not improve from 0.88124\n",
      "Epoch 192/200\n",
      "1083/1083 [==============================] - 35s 33ms/step - loss: 0.2750 - acc: 0.8917 - val_loss: 0.3832 - val_acc: 0.8732\n",
      "\n",
      "Epoch 00192: val_acc did not improve from 0.88124\n",
      "Epoch 193/200\n",
      "1083/1083 [==============================] - 35s 33ms/step - loss: 0.2728 - acc: 0.8933 - val_loss: 0.3648 - val_acc: 0.8790\n",
      "\n",
      "Epoch 00193: val_acc did not improve from 0.88124\n",
      "Epoch 194/200\n",
      "1083/1083 [==============================] - 35s 33ms/step - loss: 0.2712 - acc: 0.8940 - val_loss: 0.3884 - val_acc: 0.8714\n",
      "\n",
      "Epoch 00194: val_acc did not improve from 0.88124\n",
      "Epoch 195/200\n",
      "1083/1083 [==============================] - 35s 33ms/step - loss: 0.2741 - acc: 0.8929 - val_loss: 0.3574 - val_acc: 0.8809\n",
      "\n",
      "Epoch 00195: val_acc did not improve from 0.88124\n",
      "Epoch 196/200\n",
      "1083/1083 [==============================] - 35s 33ms/step - loss: 0.2728 - acc: 0.8904 - val_loss: 0.3554 - val_acc: 0.8796\n",
      "\n",
      "Epoch 00196: val_acc did not improve from 0.88124\n",
      "Epoch 197/200\n",
      "1083/1083 [==============================] - 35s 33ms/step - loss: 0.2714 - acc: 0.8926 - val_loss: 0.3689 - val_acc: 0.8785\n",
      "\n",
      "Epoch 00197: val_acc did not improve from 0.88124\n",
      "Epoch 198/200\n",
      "1083/1083 [==============================] - 35s 33ms/step - loss: 0.2719 - acc: 0.8930 - val_loss: 0.3933 - val_acc: 0.8720\n",
      "\n",
      "Epoch 00198: val_acc did not improve from 0.88124\n",
      "Epoch 199/200\n",
      "1083/1083 [==============================] - 35s 32ms/step - loss: 0.2707 - acc: 0.8939 - val_loss: 0.3776 - val_acc: 0.8757\n",
      "\n",
      "Epoch 00199: val_acc did not improve from 0.88124\n",
      "Epoch 200/200\n",
      "1083/1083 [==============================] - 27s 25ms/step - loss: 0.2710 - acc: 0.8924 - val_loss: 0.3634 - val_acc: 0.8787\n",
      "\n",
      "Epoch 00200: val_acc did not improve from 0.88124\n",
      "CPU times: user 7h 26min 2s, sys: 52min 20s, total: 8h 18min 22s\n",
      "Wall time: 1h 57min 48s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "mc3 = ModelCheckpoint('best_model_g3.h5', monitor='val_acc', mode='max', save_best_only=True,verbose=1)  \n",
    "history3 = model3.fit(X_train, y_train, batch_size=64, epochs=200, validation_split=0.2, verbose=1, callbacks=[mc3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "b3f2865d",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('history_g3.json', 'w') as f:\n",
    "    json.dump(history3.history, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "21a83eb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model3.save('themodel_g3.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "280c5456",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
